1
0:0:1,4 --> 0:0:6,953
I want to talk a little bit
about robots and human behavior


2
0:0:6,953 --> 0:0:13,15
the major difference between
cybernated organisms


3
0:0:13,15 --> 0:0:15,794
and human systems.


4
0:0:15,794 --> 0:0:19,162
A lot of people think
that programming


5
0:0:19,162 --> 0:0:24,715
is exactly the same in
people and robotics.


6
0:0:24,715 --> 0:0:26,665
It is not.


7
0:0:26,665 --> 0:0:31,514
The major difference is
that you can design a robot


8
0:0:31,514 --> 0:0:35,768
to walk over, pick up an object
and put it in another place


9
0:0:35,768 --> 0:0:39,37
but before the robot moves


10
0:0:39,37 --> 0:0:42,834
if you put the object in a place
the robot was going to put it in


11
0:0:42,834 --> 0:0:47,423
it will still walk over and
grab nothing in particular.


12
0:0:47,423 --> 0:0:50,916
Do you understand that?
That's programmed.


13
0:0:50,916 --> 0:0:54,79
The difference between
human systems and robots


14
0:0:54,79 --> 0:0:57,341
is that it's not linear.


15
0:0:57,341 --> 0:1:2,947
That means that the robot can do certain
things that you program into it


16
0:1:2,947 --> 0:1:5,752
and if you look at that
under a microscope


17
0:1:5,752 --> 0:1:10,319
you can see magnetic domains that
will make the robot walk over


18
0:1:10,319 --> 0:1:13,669
to a given area and
sit in a chair.


19
0:1:13,669 --> 0:1:15,721
If you pull the chair away


20
0:1:15,721 --> 0:1:19,354
the robot will walk over and
sit on nothing and fall over.


21
0:1:19,354 --> 0:1:25,795
That's programmed.
The human system differs considerably.


22
0:1:25,795 --> 0:1:28,416
When you work on a human being


23
0:1:28,416 --> 0:1:34,438
or a chimpanzee or any animal....


24
0:1:34,438 --> 0:1:37,709
(I'll work with the
chimp this time)


25
0:1:37,709 --> 0:1:41,479
Put the chimp in a big box


26
0:1:41,479 --> 0:1:45,201
and in that box are rods sticking
out at different lengths


27
0:1:45,201 --> 0:1:50,3
with a cue (a circle, a
triangle, different patterns)


28
0:1:50,3 --> 0:1:53,328
and you don't have to teach it anything.
It'll walk in


29
0:1:53,328 --> 0:1:57,269
and sooner or later, it'll
touch those things.


30
0:1:57,269 --> 0:1:59,761
When it touches one of them


31
0:1:59,761 --> 0:2:3,559
water will come forth,
touches another one, food.


32
0:2:3,559 --> 0:2:7,43
It touches another one and a
soft bed comes out of the wall.


33
0:2:7,43 --> 0:2:11,25
If the animal is put there
for a long enough time


34
0:2:11,25 --> 0:2:15,94
it will use those
rods appropriately.


35
0:2:15,94 --> 0:2:18,284
Any animal has a
range of behavior.


36
0:2:18,284 --> 0:2:22,626
When put in an environment, it
doesn't respond like a robot.


37
0:2:22,626 --> 0:2:27,372
It looks at the environment and
seeks reinforcement: food.


38
0:2:27,372 --> 0:2:30,628
If the leaves are circular
where the food is


39
0:2:30,628 --> 0:2:33,359
it will go to the
circular leaves.


40
0:2:33,359 --> 0:2:36,562
That's called
'associative memory'.


41
0:2:36,562 --> 0:2:40,304
Programmed computers have
no associative memory.


42
0:2:40,304 --> 0:2:43,76
They follow a pattern.


43
0:2:43,76 --> 0:2:46,895
If you look at a
phonograph record


44
0:2:46,895 --> 0:2:50,423
with a microscope,
you'll see zigzags


45
0:2:50,423 --> 0:2:54,64
cut in the vinyl record.


46
0:2:54,64 --> 0:2:59,813
Those zigzags are representations
of the voice of a person.


47
0:2:59,813 --> 0:3:2,235
While the record is playing


48
0:3:2,235 --> 0:3:6,539
if it's somebody
singing 'Caruso'


49
0:3:6,539 --> 0:3:10,286
it can't deviate
from those patterns.


50
0:3:10,286 --> 0:3:14,831
Robots that are programmed can't
deviate from those programs


51
0:3:14,831 --> 0:3:20,77
unless you have
path alongside it


52
0:3:20,77 --> 0:3:25,626
and you show variations, instead
of a circle a slight ellipse.


53
0:3:25,626 --> 0:3:29,631
The animal will touch that thing


54
0:3:29,631 --> 0:3:32,812
thinking it's a circle because
they're not that critical


55
0:3:32,812 --> 0:3:35,311
and it gets burned slightly


56
0:3:35,311 --> 0:3:38,99
so it will never touch
that one again.


57
0:3:38,99 --> 0:3:41,912
That's what the animal has
that the robot doesn't have.


58
0:3:41,912 --> 0:3:46,886
If the robot touches something
and it doesn't reinforce it...


59
0:3:46,886 --> 0:3:49,513
How do you reinforce a robot?


60
0:3:49,513 --> 0:3:53,748
If he gets stung, that
wouldn't bother him at all


61
0:3:53,748 --> 0:3:58,31
but a robot can learn to
respond to different figures.


62
0:3:58,31 --> 0:4:3,492
When he sees a triangle, presses
a button, he gets lubricated


63
0:4:3,492 --> 0:4:6,63
but he doesn't feel good
when he gets lubricated


64
0:4:6,63 --> 0:4:10,647
so there's no reason
to retain that action.


65
0:4:10,647 --> 0:4:13,425
It's only when a human
touches something


66
0:4:13,425 --> 0:4:17,375
and they feel good touching
it, that they repeat it.


67
0:4:17,375 --> 0:4:22,93
A robot cannot touch something
and say "Hey, that feels good."


68
0:4:22,93 --> 0:4:25,703
They can reach out,
do that and pull back


69
0:4:25,703 --> 0:4:30,117
but they can't make anything of it.
Do you understand that?


70
0:4:30,117 --> 0:4:33,232
The reason I say "Do
you understand that?"


71
0:4:33,232 --> 0:4:36,4
is because there's so
much conflict today


72
0:4:36,4 --> 0:4:40,99
about robots and people:
Will robots take over?


73
0:4:40,99 --> 0:4:44,328
Not if they're programmed
not to take over.


74
0:4:44,328 --> 0:4:47,931
If they're programmed to take
over, they can only shoot


75
0:4:47,931 --> 0:4:50,586
a guy in a certain uniform.


76
0:4:50,586 --> 0:4:54,33
If the guy stays put
in a given area


77
0:4:54,33 --> 0:4:58,647
the robot can walk over,
unless you condition the robot


78
0:4:58,647 --> 0:5:4,215
with the eyes to follow anything
that moves and shoot it.


79
0:5:4,215 --> 0:5:9,336
Is a robot an assassin?
No, it's programmed to shoot.


80
0:5:9,336 --> 0:5:12,956
That's quite different.
Human beings have


81
0:5:12,956 --> 0:5:17,803
some people believe, 10
to 15 billion neurons.


82
0:5:17,803 --> 0:5:23,669
A robot has hundreds of thousands
of associative sets, not billions.


83
0:5:23,669 --> 0:5:27,432
If you learn that a
cup gives you water


84
0:5:27,432 --> 0:5:31,298
anything that looks like a
cup might support water.


85
0:5:31,298 --> 0:5:35,258
We can deviate from
our programming.


86
0:5:35,258 --> 0:5:39,299
Our programming appears
rigid, but alongside of it


87
0:5:39,299 --> 0:5:43,622
is associative memory: I
touched that and I felt pain.


88
0:5:43,622 --> 0:5:49,14
I touched the other thing and I
didn't feel pain. I got something.


89
0:5:49,14 --> 0:5:54,652
A robot never looks at a thing
and says "That's interesting!"


90
0:5:54,652 --> 0:5:57,649
If you were to float in
midair in front of a robot


91
0:5:57,649 --> 0:6:0,846
it wouldn't say "Now
that is interesting!"


92
0:6:0,846 --> 0:6:4,766
It can't do that, it can only
do what it's programmed to do.


93
0:6:4,766 --> 0:6:8,576
A man can see things


94
0:6:8,576 --> 0:6:13,531
and be programmed and compare
it to something else.


95
0:6:13,531 --> 0:6:20,219
Is that very clear, or do you
want to question anything there?


96
0:6:20,219 --> 0:6:23,92
That's a major difference
between programmed behavior


97
0:6:23,92 --> 0:6:26,188
and human programming.


98
0:6:26,188 --> 0:6:31,43
Humans have a lot of associations
prior to programming


99
0:6:31,43 --> 0:6:34,93
so the other associations, if
it reminds him of the other


100
0:6:34,93 --> 0:6:37,306
he can deviate.


101
0:6:37,306 --> 0:6:40,2
That's why people walk
out of here when I speak


102
0:6:40,2 --> 0:6:42,914
with different interpretations.


103
0:6:42,914 --> 0:6:48,667
(Roxanne) Kurzweil talks about
using nanotechnology and


104
0:6:48,667 --> 0:6:52,831
implanting something in the head


105
0:6:52,831 --> 0:6:57,561
like a second brain
that may be so fast


106
0:6:57,561 --> 0:7:2,428
that it could take over the
other brain in the person.


107
0:7:2,428 --> 0:7:7,621
This is something he's raised.
- You can do that


108
0:7:7,621 --> 0:7:14,124
but it doesn't give them
leverage to wonder about that.


109
0:7:14,124 --> 0:7:17,774
I've never seen that happen.
A man could say that.


110
0:7:17,774 --> 0:7:20,142
A man could look at
an event, and say


111
0:7:20,142 --> 0:7:23,623
"That's strange, the way that
paper holds up that speaker."


112
0:7:23,623 --> 0:7:27,321
A robot does not do that.
It looks at the speaker.


113
0:7:27,321 --> 0:7:31,415
It doesn't even look at it and
say "That looks like a speaker."


114
0:7:31,415 --> 0:7:35,814
Unless you put a speaker in
front of the robot and say


115
0:7:35,814 --> 0:7:39,753
"That's a speaker" so when its eye
sees it, it says "That's a speaker."


116
0:7:39,753 --> 0:7:43,231
When you turn it sideways, it
doesn't know what that is.


117
0:7:43,231 --> 0:7:46,627
When you turn it sideways and
say "That's also a speaker"


118
0:7:46,627 --> 0:7:49,252
and you rotate the speaker
in many positions


119
0:7:49,252 --> 0:7:52,621
so the robot has
associations with the shape


120
0:7:52,621 --> 0:7:56,196
in different positions,
he can call it a speaker.


121
0:7:56,196 --> 0:8:1,29
If you call an orange an orange,
but if you cut it in half


122
0:8:1,29 --> 0:8:3,92
it can't call it an orange.


123
0:8:3,92 --> 0:8:9,332
It doesn't say "It looks like half an orange.
" Do you understand that?


124
0:8:9,332 --> 0:8:13,1
(Roxanne) This thing that Kurzweil
is putting out like 'singularity'


125
0:8:13,1 --> 0:8:16,4
is when you start to implant
things in people's heads


126
0:8:16,4 --> 0:8:19,739
that have so many more
calculating ability, or...


127
0:8:19,739 --> 0:8:22,742
- If it is not connected
to the other neurons


128
0:8:22,742 --> 0:8:26,33
it won't do anything.
-It couldn't take over? -No


129
0:8:26,33 --> 0:8:28,873
unless it's connected.


130
0:8:28,873 --> 0:8:32,279
(Joel) He's proposing that
it is connected somehow.


131
0:8:32,279 --> 0:8:36,454
There is some interface between...
-If there is an interface


132
0:8:36,454 --> 0:8:40,796
organic neurons respond
to certain rate of speed.


133
0:8:40,796 --> 0:8:45,482
Anything beyond that
rate, it can't respond.


134
0:8:45,482 --> 0:8:50,102
Electronic systems travel
almost at the speed of light.


135
0:8:50,102 --> 0:8:55,93
Neural associations
are relatively slow.


136
0:8:55,93 --> 0:9:0,751
If you try to speed up
digestion of food in a human


137
0:9:0,751 --> 0:9:4,47
the digestive acids
flow at a certain rate.


138
0:9:4,47 --> 0:9:8,287
If you were to triple the
rate, it might digest


139
0:9:8,287 --> 0:9:11,565
portions of the intestines.


140
0:9:11,565 --> 0:9:15,191
Do you understand what I mean?


141
0:9:15,191 --> 0:9:19,379
For instance, let's take a bear
and put it in a room this size


142
0:9:19,379 --> 0:9:23,408
with a bunch of objects sticking
out (they have to stick out)


143
0:9:23,408 --> 0:9:27,932
40 of them.
A bear might learn how to use


144
0:9:27,932 --> 0:9:31,682
12 of them but not 40.


145
0:9:31,682 --> 0:9:37,21
It won't remember 40.
It doesn't have the neuronal


146
0:9:37,21 --> 0:9:41,258
amount to remember...
A bear could remember


147
0:9:41,258 --> 0:9:45,625
because when a bear walks through an
environment "This bush has berries."


148
0:9:45,625 --> 0:9:48,71
He remembers where the bush is


149
0:9:48,71 --> 0:9:51,512
"This area has animals
that I can eat."


150
0:9:51,512 --> 0:9:56,392
A bear can build up maybe
thousands of associations


151
0:9:56,392 --> 0:9:59,974
but first you have to study
the range of the animal.


152
0:9:59,974 --> 0:10:3,42
How many levers an
animal can remember


153
0:10:3,42 --> 0:10:7,121
will tell you what its
outside response will be.


154
0:10:7,121 --> 0:10:12,214
If you find a bear that can
learn to work 47 levers


155
0:10:12,214 --> 0:10:17,529
(a little beyond that or a
little less if that's true)


156
0:10:17,529 --> 0:10:21,17
then you know what the bear can
respond to in the environment:


157
0:10:21,17 --> 0:10:23,923
40 different systems.


158
0:10:23,923 --> 0:10:27,715
A human can generate
associations


159
0:10:27,715 --> 0:10:32,882
with thousands of things
in the environment.


160
0:10:32,882 --> 0:10:36,474
If a human learns
to eat certain food


161
0:10:36,474 --> 0:10:39,39
and he has to climb
a tree to get it


162
0:10:39,39 --> 0:10:42,955
if you put that food at the base of
the tree he won't climb the tree.


163
0:10:42,955 --> 0:10:46,571
A robot will.
Do you understand that?


164
0:10:46,571 --> 0:10:50,368
If you program a robot to
climb a tree to get the apple


165
0:10:50,368 --> 0:10:52,221
it'll do that.


166
0:10:52,221 --> 0:10:55,84
If you put the apple on the
ground, the robot goes "Ha!


167
0:10:55,84 --> 0:10:57,355
That simplifies things."


168
0:10:57,355 --> 0:11:1,587
No, unless you build in
something special in the robot


169
0:11:1,587 --> 0:11:4,597
to handle unforeseen variables


170
0:11:4,597 --> 0:11:9,199
and that's what people
don't know how to do yet.


171
0:11:9,199 --> 0:11:15,196
They don't know how to program a
robot to say "What have we here?"


172
0:11:15,196 --> 0:11:21,55
because the words "What have we here?
" don't mean anything to a robot.


173
0:11:21,55 --> 0:11:25,522
It means something
to a human being.


174
0:11:25,522 --> 0:11:29,93
(Roxanne) The roboticists and
Kurzweil are bringing up


175
0:11:29,93 --> 0:11:34,65
when the robot does become
connected to the environment


176
0:11:34,65 --> 0:11:36,76
and does have enough
information that it would


177
0:11:36,76 --> 0:11:39,523
surpass and overtake people.


178
0:11:39,523 --> 0:11:42,489
- No, a robot does not


179
0:11:42,489 --> 0:11:45,814
ask questions.
A robot does not say


180
0:11:45,814 --> 0:11:48,404
"I've been here before.
I've seen that before."


181
0:11:48,404 --> 0:11:51,995
They don't have enough
neurons to build


182
0:11:51,995 --> 0:11:54,663
all kinds of associations.


183
0:11:54,663 --> 0:11:57,73
(Roxanne) Do you think it's
possible that they can do that


184
0:11:57,73 --> 0:12:2,391
if they use biological....
-If it's programmed, no.


185
0:12:2,391 --> 0:12:6,689
But if a robot is
self-programming


186
0:12:6,689 --> 0:12:10,545
then the reason for
a robot's actions


187
0:12:10,545 --> 0:12:13,513
are very different
than human systems.


188
0:12:13,513 --> 0:12:17,251
When a human puts something
into his mouth, it tastes good


189
0:12:17,251 --> 0:12:20,999
while if a robot does it, nothing.
There's no reward.


190
0:12:20,999 --> 0:12:24,208
What's a reward to a robot?


191
0:12:24,208 --> 0:12:28,638
Sitting down does it say
"Whew, I'm so tired


192
0:12:28,638 --> 0:12:31,775
and now I feel better.
" He doesn't feel.


193
0:12:31,775 --> 0:12:34,184
When he sits down,
he doesn't say


194
0:12:34,184 --> 0:12:37,531
"It's good to have a
chair in my area."


195
0:12:37,531 --> 0:12:41,961
He doesn't give a shit about those things.
If the light gets so bright


196
0:12:41,961 --> 0:12:46,481
that the eyes of the robot turn
off, he says "I can't see"


197
0:12:46,481 --> 0:12:50,685
(if you wire him that way) but
he doesn't turn down the light


198
0:12:50,685 --> 0:12:53,71
unless you wire it that way.


199
0:12:53,71 --> 0:12:56,457
He turns down the light
when it gets bright


200
0:12:56,457 --> 0:12:58,681
not because it's bright, but


201
0:12:58,681 --> 0:13:2,3
because he has senses
that turn off the light.


202
0:13:2,3 --> 0:13:4,646
Do you understand
that difference?


203
0:13:4,646 --> 0:13:8,638
(Roxanne) You were explaining
this last night in terms of


204
0:13:8,638 --> 0:13:11,184
humans have to have
experience to react...


205
0:13:11,184 --> 0:13:16,931
Yes, that means a robot
doesn't seek experience.


206
0:13:16,931 --> 0:13:22,289
A robot doesn't want to know why some
tires wear out faster than others.


207
0:13:22,289 --> 0:13:24,998
He doesn't take a microscope
and look at the rubber


208
0:13:24,998 --> 0:13:30,44
under a microscope.
A robot is not equipped that way.


209
0:13:30,44 --> 0:13:33,747
They don't have
pleasure and pain.


210
0:13:33,747 --> 0:13:36,725
If they had pleasure and pain


211
0:13:36,725 --> 0:13:40,742
they would have preferences.


212
0:13:40,742 --> 0:13:44,136
Do you understand?
If a robot cuts


213
0:13:44,136 --> 0:13:46,73
wood with a rotary saw:


214
0:13:46,73 --> 0:13:50,243
All the wood is shoved in there
automatically; he cuts it.


215
0:13:50,243 --> 0:13:52,82
If you put a human in
there, he'll cut him too.


216
0:13:52,82 --> 0:13:56,636
He doesn't think "That's a person,
I don't want to cut that."


217
0:13:56,636 --> 0:14:1,144
The robot cannot do anything
unless it's programmed to do it.


218
0:14:1,144 --> 0:14:4,41
It could be programmed to cut wood
but it will cut anything else


219
0:14:4,41 --> 0:14:8,557
shoved in there.
If you interfere with its programming


220
0:14:8,557 --> 0:14:12,856
it doesn't say "Wait a while, you're
interfering with the programming!"


221
0:14:12,856 --> 0:14:16,147
If radar picks up fog
in San Francisco


222
0:14:16,147 --> 0:14:19,462
the airplane might fly
above the weather.


223
0:14:19,462 --> 0:14:22,452
The airplane moves up based
on what's out there.


224
0:14:22,452 --> 0:14:27,29
If it's fog, it moves up, but it
doesn't move up to avoid the fog!


225
0:14:27,29 --> 0:14:30,711
That's human projection.


226
0:14:30,711 --> 0:14:34,96
A robot moves up because
there was fog ahead.


227
0:14:34,96 --> 0:14:37,994
Its senses bounce back
and give it a thing


228
0:14:37,994 --> 0:14:42,429
that controls the elevators
and makes it move up.


229
0:14:42,429 --> 0:14:46,11
If it's raining, the robot
may open an umbrella


230
0:14:46,11 --> 0:14:50,222
above itself.
But when the raindrops hit the umbrella


231
0:14:50,222 --> 0:14:52,984
they make contact
with two terminals


232
0:14:52,984 --> 0:14:56,159
so there's a flow across.
That opens the umbrella.


233
0:14:56,159 --> 0:14:59,492
But the robot says "It's raining.
I'm going to get wet. I'll open it."


234
0:14:59,492 --> 0:15:2,948
No, none of that.
Do you understand that?


235
0:15:2,948 --> 0:15:5,816
I'm talking about
robotics today.


236
0:15:5,816 --> 0:15:9,392
When people say "Do you think
robots will take over?"


237
0:15:9,392 --> 0:17:9,392
There's no basis for it if they're
programmed a certain way.



###1 I want to talk a little bit about robots and human behavior
###6 the major difference between cybernated organisms
###13 and human systems.
###15 A lot of people think that programming
###19 is exactly the same in people and robotics.
###24 It is not.
###26 The major difference is that you can design a robot
###31 to walk over, pick up an object and put it in another place
###35 but before the robot moves
###39 if you put the object in a place the robot was going to put it in
###42 it will still walk over and grab nothing in particular.
###47 Do you understand that? That's programmed.
###50 The difference between human systems and robots
###54 is that it's not linear.
###57 That means that the robot can do certain things that you program into it
###62 and if you look at that under a microscope
###65 you can see magnetic domains that will make the robot walk over
###70 to a given area and sit in a chair.
###73 If you pull the chair away
###75 the robot will walk over and sit on nothing and fall over.
###79 That's programmed. The human system differs considerably.
###85 When you work on a human being
###88 or a chimpanzee or any animal....
###94 (I'll work with the chimp this time)
###97 Put the chimp in a big box
###101 and in that box are rods sticking out at different lengths
###105 with a cue (a circle, a triangle, different patterns)
###110 and you don't have to teach it anything. It'll walk in
###113 and sooner or later, it'll touch those things.
###117 When it touches one of them
###119 water will come forth, touches another one, food.
###123 It touches another one and a soft bed comes out of the wall.
###127 If the animal is put there for a long enough time
###131 it will use those rods appropriately.
###135 Any animal has a range of behavior.
###138 When put in an environment, it doesn't respond like a robot.
###142 It looks at the environment and seeks reinforcement: food.
###147 If the leaves are circular where the food is
###150 it will go to the circular leaves.
###153 That's called 'associative memory'.
###156 Programmed computers have no associative memory.
###160 They follow a pattern.
###163 If you look at a phonograph record
###166 with a microscope, you'll see zigzags
###170 cut in the vinyl record.
###174 Those zigzags are representations of the voice of a person.
###179 While the record is playing
###182 if it's somebody singing 'Caruso'
###186 it can't deviate from those patterns.
###190 Robots that are programmed can't deviate from those programs
###194 unless you have path alongside it
###200 and you show variations, instead of a circle a slight ellipse.
###205 The animal will touch that thing
###209 thinking it's a circle because they're not that critical
###212 and it gets burned slightly
###215 so it will never touch that one again.
###218 That's what the animal has that the robot doesn't have.
###221 If the robot touches something and it doesn't reinforce it...
###226 How do you reinforce a robot?
###229 If he gets stung, that wouldn't bother him at all
###233 but a robot can learn to respond to different figures.
###238 When he sees a triangle, presses a button, he gets lubricated
###243 but he doesn't feel good when he gets lubricated
###246 so there's no reason to retain that action.
###250 It's only when a human touches something
###253 and they feel good touching it, that they repeat it.
###257 A robot cannot touch something and say "Hey, that feels good."
###262 They can reach out, do that and pull back
###265 but they can't make anything of it. Do you understand that?
###270 The reason I say "Do you understand that?"
###273 is because there's so much conflict today
###276 about robots and people: Will robots take over?
###280 Not if they're programmed not to take over.
###284 If they're programmed to take over, they can only shoot
###287 a guy in a certain uniform.
###290 If the guy stays put in a given area
###294 the robot can walk over, unless you condition the robot
###298 with the eyes to follow anything that moves and shoot it.
###304 Is a robot an assassin? No, it's programmed to shoot.
###309 That's quite different. Human beings have
###312 some people believe, 10 to 15 billion neurons.
###317 A robot has hundreds of thousands of associative sets, not billions.
###323 If you learn that a cup gives you water
###327 anything that looks like a cup might support water.
###331 We can deviate from our programming.
###335 Our programming appears rigid, but alongside of it
###339 is associative memory: I touched that and I felt pain.
###343 I touched the other thing and I didn't feel pain. I got something.
###349 A robot never looks at a thing and says "That's interesting!"
###354 If you were to float in midair in front of a robot
###357 it wouldn't say "Now that is interesting!"
###360 It can't do that, it can only do what it's programmed to do.
###364 A man can see things
###368 and be programmed and compare it to something else.
###373 Is that very clear, or do you want to question anything there?
###380 That's a major difference between programmed behavior
###383 and human programming.
###386 Humans have a lot of associations prior to programming
###391 so the other associations, if it reminds him of the other
###394 he can deviate.
###397 That's why people walk out of here when I speak
###400 with different interpretations.
###402 (Roxanne) Kurzweil talks about using nanotechnology and
###408 implanting something in the head
###412 like a second brain that may be so fast
###417 that it could take over the other brain in the person.
###422 This is something he's raised. - You can do that
###427 but it doesn't give them leverage to wonder about that.
###434 I've never seen that happen. A man could say that.
###437 A man could look at an event, and say
###440 "That's strange, the way that paper holds up that speaker."
###443 A robot does not do that. It looks at the speaker.
###447 It doesn't even look at it and say "That looks like a speaker."
###451 Unless you put a speaker in front of the robot and say
###455 "That's a speaker" so when its eye sees it, it says "That's a speaker."
###459 When you turn it sideways, it doesn't know what that is.
###463 When you turn it sideways and say "That's also a speaker"
###466 and you rotate the speaker in many positions
###469 so the robot has associations with the shape
###472 in different positions, he can call it a speaker.
###476 If you call an orange an orange, but if you cut it in half
###481 it can't call it an orange.
###483 It doesn't say "It looks like half an orange. " Do you understand that?
###489 (Roxanne) This thing that Kurzweil is putting out like 'singularity'
###493 is when you start to implant things in people's heads
###496 that have so many more calculating ability, or...
###499 - If it is not connected to the other neurons
###502 it won't do anything. -It couldn't take over? -No
###506 unless it's connected.
###508 (Joel) He's proposing that it is connected somehow.
###512 There is some interface between... -If there is an interface
###516 organic neurons respond to certain rate of speed.
###520 Anything beyond that rate, it can't respond.
###525 Electronic systems travel almost at the speed of light.
###530 Neural associations are relatively slow.
###535 If you try to speed up digestion of food in a human
###540 the digestive acids flow at a certain rate.
###544 If you were to triple the rate, it might digest
###548 portions of the intestines.
###551 Do you understand what I mean?
###555 For instance, let's take a bear and put it in a room this size
###559 with a bunch of objects sticking out (they have to stick out)
###563 40 of them. A bear might learn how to use
###567 12 of them but not 40.
###571 It won't remember 40. It doesn't have the neuronal
###577 amount to remember... A bear could remember
###581 because when a bear walks through an environment "This bush has berries."
###585 He remembers where the bush is
###588 "This area has animals that I can eat."
###591 A bear can build up maybe thousands of associations
###596 but first you have to study the range of the animal.
###599 How many levers an animal can remember
###603 will tell you what its outside response will be.
###607 If you find a bear that can learn to work 47 levers
###612 (a little beyond that or a little less if that's true)
###617 then you know what the bear can respond to in the environment:
###621 40 different systems.
###623 A human can generate associations
###627 with thousands of things in the environment.
###632 If a human learns to eat certain food
###636 and he has to climb a tree to get it
###639 if you put that food at the base of the tree he won't climb the tree.
###642 A robot will. Do you understand that?
###646 If you program a robot to climb a tree to get the apple
###650 it'll do that.
###652 If you put the apple on the ground, the robot goes "Ha!
###655 That simplifies things."
###657 No, unless you build in something special in the robot
###661 to handle unforeseen variables
###664 and that's what people don't know how to do yet.
###669 They don't know how to program a robot to say "What have we here?"
###675 because the words "What have we here? " don't mean anything to a robot.
###681 It means something to a human being.
###685 (Roxanne) The roboticists and Kurzweil are bringing up
###689 when the robot does become connected to the environment
###694 and does have enough information that it would
###696 surpass and overtake people.
###699 - No, a robot does not
###702 ask questions. A robot does not say
###705 "I've been here before. I've seen that before."
###708 They don't have enough neurons to build
###711 all kinds of associations.
###714 (Roxanne) Do you think it's possible that they can do that
###717 if they use biological.... -If it's programmed, no.
###722 But if a robot is self-programming
###726 then the reason for a robot's actions
###730 are very different than human systems.
###733 When a human puts something into his mouth, it tastes good
###737 while if a robot does it, nothing. There's no reward.
###740 What's a reward to a robot?
###744 Sitting down does it say "Whew, I'm so tired
###748 and now I feel better. " He doesn't feel.
###751 When he sits down, he doesn't say
###754 "It's good to have a chair in my area."
###757 He doesn't give a shit about those things. If the light gets so bright
###761 that the eyes of the robot turn off, he says "I can't see"
###766 (if you wire him that way) but he doesn't turn down the light
###770 unless you wire it that way.
###773 He turns down the light when it gets bright
###776 not because it's bright, but
###778 because he has senses that turn off the light.
###782 Do you understand that difference?
###784 (Roxanne) You were explaining this last night in terms of
###788 humans have to have experience to react...
###791 Yes, that means a robot doesn't seek experience.
###796 A robot doesn't want to know why some tires wear out faster than others.
###802 He doesn't take a microscope and look at the rubber
###804 under a microscope. A robot is not equipped that way.
###810 They don't have pleasure and pain.
###813 If they had pleasure and pain
###816 they would have preferences.
###820 Do you understand? If a robot cuts
###824 wood with a rotary saw:
###826 All the wood is shoved in there automatically; he cuts it.
###830 If you put a human in there, he'll cut him too.
###832 He doesn't think "That's a person, I don't want to cut that."
###836 The robot cannot do anything unless it's programmed to do it.
###841 It could be programmed to cut wood but it will cut anything else
###844 shoved in there. If you interfere with its programming
###848 it doesn't say "Wait a while, you're interfering with the programming!"
###852 If radar picks up fog in San Francisco
###856 the airplane might fly above the weather.
###859 The airplane moves up based on what's out there.
###862 If it's fog, it moves up, but it doesn't move up to avoid the fog!
###867 That's human projection.
###870 A robot moves up because there was fog ahead.
###874 Its senses bounce back and give it a thing
###877 that controls the elevators and makes it move up.
###882 If it's raining, the robot may open an umbrella
###886 above itself. But when the raindrops hit the umbrella
###890 they make contact with two terminals
###892 so there's a flow across. That opens the umbrella.
###896 But the robot says "It's raining. I'm going to get wet. I'll open it."
###899 No, none of that. Do you understand that?
###902 I'm talking about robotics today.
###905 When people say "Do you think robots will take over?"
###909 There's no basis for it if they're programmed a certain way.

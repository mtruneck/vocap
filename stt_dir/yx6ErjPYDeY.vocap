###0 [MUSIC PLAYING]
###355 TONY VOELLM: Hello.
###356 Good morning.
###356 Good morning.
###360 Welcome to GTAC 2013.
###364 Focus on mobile and media.
###366 Welcome.
###367 
###369 I'm Tony Voellm.
###370 I'll be your host the next two days up here.
###373 So feel free-- you can check me out anywhere as I'm walking
###376 around-- and ask questions.
###379 I'll be taking you through some of the fit and finish
###382 here in the beginning about what we need to do, and how
###383 we're all going to participate.
###386 So with that, I would like to start out with a thank you to
###390 our sponsor.
###391 Some of the unsung heroes are often the people that actually
###394 write the checks.
###394 So here, if you see Asim hanging around, he's pretty
###398 awesome because he actually has helped us fund this.
###400 So thank you, Asim.
###402 
###409 This conference is being streamed live.
###412 So welcome to all the participants
###414 all around the world.
###416 We hope you're enjoying your coffee shops, couches, beds.
###419 For everybody here, just a reminder.
###422 This is being recorded.
###424 Your pictures may show up anywhere at any time.
###426 I believe everybody here signed a form on your way in.
###429 If you did not, please do that.
###433 We would love to be able to use pictures from here, so
###435 just a reminder.
###438 OK, agenda.
###439 I'm going to go through the agenda pretty fast so we can
###441 get into our talks.
###443 If you like to tweet or g+ about your experience
###447 here, please do.
###449 One note is, this area, I think, it's
###451 fine to take pictures.
###453 The doors out the side, please do not go out of those.
###456 Please do not take pictures through the portal.
###458 And if you see anything that you're not supposed to see,
###460 please instantly forget it, and don't take a picture.
###462 Everything else is fair game.
###464 
###467 You have to wear your badges at all times.
###470 You should have two badges.
###471 One is your visitor badge here.
###473 And then you have an official building badge.
###476 Tomorrow, to speed things up, please keep
###478 your Day One badge.
###479 That way we don't have to recheck your ID and everything
###481 on the way in.
###482 So you'll have to grab a second day badge here.
###484 
###487 We are hosting tours.
###489 At this point, probably all the tickets
###490 are gone for today.
###491 I'm not sure about tomorrow, but you can certainly check in
###494 the lobby during the break times to get a tour of the
###496 office here.
###497 It is a super cool office.
###498 And I'll tell you some details about it in a minute.
###500 
###504 Each talk, we will be doing a set of questions.
###507 So we have a Dory set up.
###509 Here is the link to jump on the Dory.
###511 You can vote up or vote down questions.
###514 Feel free to add new questions.
###515 We'll also try to take some live questions as time allows.
###519 Here's the link here.
###520 So go ahead, and you can grab this, and sort of jump in, and
###523 take a look at the Moderator.
###525 
###527 Attendees, at lunch time, we are going to do some
###533 roundtable discussions.
###534 These are all of you.
###536 Many of you have asked to host a topic, or a topic table, or
###540 have discussion.
###541 We have very intentionally offered to bring in all the
###545 smartest people we know.
###546 That would be all of you.
###548 So please join in to the topic tables.
###552 These are sort of participatory.
###553 If you jump in a table, it's not interesting to you, it's
###556 certainly fine to get up and go to another table.
###558 Nobody will be upset.
###559 It's just everybody is trying optimize for things that
###562 they're interested in.
###563 
###566 Lunch.
###567 I guess dinner is going to be on the fifth floor today,
###570 which is up in the Water Tower Cafe.
###572 It's a very cool cafe.
###574 It actually has a water tower that came from
###575 New York City here.
###576 You can actually sit in a Water Tower, if
###577 you've never done that.
###579 
###581 Any time you are anywhere in the building, even going up
###584 and down the elevators, please make sure you have a
###586 Googler with you.
###587 Somebody in one of these brightly colored shirts, or
###589 maybe you'll see like a Google badge on them.
###593 This is a workspace for Google, and so we just need to
###597 make sure that everybody has a host at all times.
###600 
###602 A little bit about the New York City office here.
###605 This office started in 2000.
###607 It actually started in a coffee shop, much like many of
###610 the offices for Google.
###612 So thanks to Starbucks for, I guess, having all these great
###615 places that we can all go work.
###617 This is the second largest office internationally.
###620 And a shout out to my own office,
###621 which is Seattle Kirkland.
###623 I believe we are either the third or the fourth.
###626 This is a fantastic office.
###627 It encompasses the whole Port Authority building here.
###630 One thing I wanted to mention to all of you.
###633 If you hear a giant bang sometime today--
###637 I highlighted this on the slide--
###639 there is a elevator that can fit an 18-wheeler, literally,
###642 in this building.
###643 This building was designed to drive trucks around it.
###647 Now we just run scooters all around this building, but
###649 there are trucks right behind me.
###651 It's actually the elevator for the 18-wheeler.
###653 Every now and then, you'll hear the bang.
###655 I just didn't want you to be surprised if you hear this.
###657 And sometimes, it can even vibrate the floor.
###659 So just heads up.
###661 It's probably nothing, if you hear the bang
###662 coming from this direction.
###666 We do take up an entire city block here.
###668 In fact, we actually have two parts.
###669 We have this office.
###670 We also have a section across over towards the Chelsea
###673 Market area.
###675 As you go looking around, you go out, you can go into the
###678 Chelsea Market.
###678 The whole bottom part is actually still a market.
###680 That's a fun place to go visit.
###683 There are lots of different products here in this office.
###686 Everything from Ads to Google Drive to Maps and Finance.
###690 Google Cloud is here.
###692 Really, engineers that are working on the products that
###694 you know and love are all here in this building.
###697 We also have Marketing, and Sales, and
###699 Engineering, and Support.
###701 It really takes a big team to deliver fantastic products.
###705 
###707 A little bit about the New York City culture here.
###710 We have many different themed cafeterias.
###714 I guess we serve like somewhere around a million
###716 plus meals a year here in this office.
###718 It just gives you an idea of the scope.
###721 We have these great scooters that we can run up
###723 and down the halls.
###724 Sorry, unless you go on the tour, you won't
###726 be able to do this.
###726 But I guess if you're on the tour, you can grab one.
###729 We tried this last night.
###730 I duly impressed my friend.
###733 I took my luggage, and my bag, and everything.
###735 I dropped it on a scooter, and we raced across the building,
###738 I think, in about 45 seconds.
###740 The scooters really get us around this building fast.
###743 We have game rooms and break rooms all over the place.
###745 You'll see this on the tour, which is great.
###748 We are definitely a very diverse company.
###750 We support diversity in all of its glory.
###755 And so we have lots internal groups to sort of communicate
###758 and share our thoughts with everybody, which is fantastic.
###761 I love this a lot about Google.
###763 
###766 A little bit about what we've done in the
###768 greater New York area.
###769 One of the things we do at Google is we try to be great
###771 corporate citizens.
###772 And great citizens of the areas in which we are.
###775 And in this area here, just late last year, we lit up,
###779 literally, the Chelsea neighborhood.
###780 I think it's like six city blocks that we get free Wi-Fi.
###784 So if you're enjoying the free Wi-Fi when you're out and
###786 about, that's from Google here.
###789 It should say Google Wi-Fi, or something like that.
###791 Almost everybody has access.
###793 Internal to the office here, Google Guest.
###795 But we've done this, and it was really important to us to
###799 do this around here, to give the access.
###801 It just wasn't quite ubiquitous.
###802 
###807 In terms of other interesting things about Google, I think I
###810 lost like 60 cholesterol points, or something, when I
###813 joined Google.
###815 Previous companies didn't take my health as
###817 seriously as Google.
###820 When I'm walking around the office, I have lots of healthy
###822 choices of things to eat.
###824 I still have a lot more work to do on that front.
###827 Some fun facts about New York.
###828 This is a fantastic city.
###830 If you have not had a chance to explore, hopefully you've
###834 booked time.
###834 Whether you've lived here your whole life, whether you just
###837 came in last night-- and I heard some people
###839 flew in this morning--
###840 this is definitely a great area.
###842 New York is rich in history.
###844 It has many different markets.
###846 This is the Chelsea neighborhood.
###847 This was where a lot of the sort of import-export into the
###852 city happened for a long time.
###853 That's why this building was called the
###854 Port Authority building.
###855 It was attached to the port.
###858 Some of the fun facts you'll find around the city.
###861 The Empire State Building, is an amazing building.
###864 What's interesting about this is this is the most expensive
###867 elevator ride I've ever had in my life.
###871 I did not know an elevator could cost that much, and it
###873 was only like 60 seconds.
###875 But if you get to the top, and you're brave enough to walk to
###878 the edge, it's a very interesting experience.
###881 Both the Empire State Building and the Rockefeller Center
###885 have these spectacular views from the top of the building.
###887 And you can see all around the whole city.
###889 It's fantastic.
###890 The Empire State Building was the world's tallest building
###894 for 40 years.
###896 And then everybody started to figure out that if you put an
###899 antenna on your building, you could
###900 get the tallest building.
###901 I don't know if that's sort of cheating, or not.
###904 A little known fact.
###905 The Oreo cookie was actually invented
###907 here in New York City.
###909 It was actually invented right across the street in the
###911 Chelsea Market.
###912 And the ode to the Oreo cookie is a small plaque that says
###915 the Oreo cookie was invented here.
###917 So if you do get a chance to walk across the street today
###920 or tomorrow, you can go find out where the
###922 Oreo cookie was invented.
###924 It was invented here in 1912.
###926 And I guess they had a bunch of cream and a bunch of
###928 biscuits, and they were trying to figure out
###929 what to do with them.
###930 So they mashed them together, and came up with this iconic
###933 cookie that pretty much, I think, everybody around the
###935 world knows.
###937 With that, I'm going to hand this off to Ari Shamash, who's
###943 going to kick us off with the keynote.
###946 Immediately after the keynote, we're going to go
###948 into the next talk.
###949 One of things I'm going to do is between each talk, after
###953 the speaker is finished, I'm going to come on stage.
###956 As time allows, we'll take the questions from the Moderator
###961 that you saw there, the link earlier.
###963 And I will sort of host the questions.
###966 As we run out of time, we'll just sort of move on.
###968 But the speakers, I believe, are all very excited to talk
###971 to all of you.
###972 You can grab them at lunch.
###973 You can grab them at breaks.
###975 They'll generally be around.
###976 Most of them will be around for the two days.
###979 Some will only be around for the day that they're here.
###981 So if you do want to grab them, make sure you try to
###982 grab them on the same day that they speak.
###984 With that, I'd like to kick it off, and hand it off to Ari.
###988 All right.
###989 Thank you.
###990 [APPLAUSE]
###994 ARI SHAMASH: Thanks very much, Tony, for the introduction.
###998 We are four minutes ahead of schedule.
###1000 I am going to do my best to fix that.
###1002 
###1006 I want to welcome all of you guys to New York,
###1009 to Google New York.
###1010 I am from the New York office here.
###1012 I'm part of the test engineering organization,
###1015 specifically with Ads.
###1016 But before I get started, I really want to give a shout
###1019 out to our folks from Boston.
###1021 Any of you from Boston?
###1024 Our prayers and thoughts are with you guys as you go
###1026 through this.
###1027 As the city, and me personally, as the city that
###1030 went through 9/11, we completely understand the pain
###1033 that everybody is going through, and has to endure.
###1038 We are right there with you.
###1038 Our thoughts are with you.
###1040 
###1042 I'd like to start by telling you guys a story.
###1045 I hope you'll bear with me.
###1046 There's quite a few stories in my presentation.
###1049 My story starts in the mid 1990s.
###1052 Just to give you some context about the mid 1990s, here's
###1055 what they look like.
###1056 Music was distributed on disks.
###1059 You literally had to carry a pile of disks around.
###1062 Wi-Fi didn't exist.
###1064 If you wanted to connect to the internet, you
###1066 had to find a cable.
###1067 If you were lucky, you found one of those blue ones,
###1069 because they might actually give you reasonable
###1071 connectivity.
###1072 If you were unlucky, you had one of those beasts over there
###1074 called a modem that connected you to the internet.
###1078 You actually had to dial up to the internet.
###1079 You had to wait 45 seconds before you had conductivity.
###1083 If you were even luckier, you had a cellphone.
###1086 You might actually have to get straps, and strap it onto your
###1088 back, because that's what that thing looked like.
###1090 You had to carry it around, right?
###1094 That's what a laptop looked like.
###1095 They had tiny, little screens, and they had these bricks.
###1098 I guess they still have bricks today.
###1099 But they had tiny, little screens.
###1100 If you were lucky, they might actually be color.
###1103 Google, at the time, was just a figment of imagination in a
###1106 couple of grad students.
###1109 Here is actually what they looked like way back when.
###1112 For me, I was a software developer.
###1114 I've been a software developer my entire career.
###1116 When I graduated from school, software
###1118 development was quite simple.
###1120 You spent a couple of months collecting requirements from
###1122 your customer.
###1123 You write them down in books this big.
###1126 Then you spend a couple more months banging out software.
###1130 Then you take all that software, you take the
###1132 requirements, you give it to some other group, and that
###1134 group then spends a few months validating whether the
###1137 software that you built matches the requirements that
###1141 were written, oh, many months ago.
###1143 The fact that something might have actually changed in those
###1145 few months is completely irrelevant.
###1147 You got the requirements.
###1149 You built some software.
###1150 And if it matches, it matches.
###1152 If it doesn't match, it doesn't match.
###1154 We had a customer, financial services, that wanted to build
###1157 a web-based application--
###1159 pretty advanced at the time--
###1162 in order to take some data that they had.
###1164 Now, this particular company invested about 100 years
###1167 building up their intellectual property.
###1169 Much of it sat on 3" by 5" index cards.
###1172 So the project was to take data off of 3" by 5" index
###1175 cards, stick it onto a database, and then distribute
###1177 it to the world over the web.
###1179 They were--
###1180 I don't want to say risk averse, because they were
###1182 building an application that was meant to be
###1184 deployed on the web--
###1185 but they didn't understand what sort of application they
###1188 wanted to build.
###1189 We went up to them and asked them, OK, what do
###1191 you want us to build?
###1192 We're happy to build it for you.
###1193 Tell us your requirements.
###1195 They turned around and said, we don't really know.
###1197 So we had a project manager at the time who said, maybe we
###1201 should try this thing called rapid iterations to try to
###1204 help the customer understand.
###1206 We asked him, what you mean by that?
###1207 What are rapid iterations?
###1209 He said, well, let's build the application.
###1212 Let's do a build, and deploy to some sort of QA, or a user
###1216 acceptance environment, on a weekly basis.
###1219 We'll show it to the customer on a weekly basis.
###1222 The customer will tell us whether they think it's
###1224 reasonable or not reasonable, and then we'll make
###1227 adjustments along the way.
###1229 This literally blew our minds.
###1231 Right?
###1232 What are you talking about?
###1233 How is it that we're going to possibly start writing
###1235 software without volumes of documentation?
###1238 How are we going to do quality assurance?
###1240 How are we going to know that we're doing the right thing?
###1242 The guy said, don't worry about it.
###1244 Let's just try it, and we'll see what happens.
###1246 All of us thought this was a pretty neat idea.
###1248 So we decided to go for it.
###1250 We decided that Thursday night would be build night.
###1253 Nobody leaves the office until the build is
###1255 done on Thursday night.
###1258 Friday morning, QA group comes in, validates it.
###1261 Monday, we show it to the customer.
###1263 Customer tells us we're on the right track, or not.
###1266 Repeat.
###1267 Sounded pretty easy, right?
###1269 So we started.
###1270 We banged some code out for a week.
###1272 We get there on Thursday afternoon.
###1274 4:00 or 5:00 o'clock, he said, OK, let's just
###1276 start doing a build.
###1277 Let's see what happens.
###1278 To make a long story short, we were there until Friday
###1280 morning trying to get the environment working.
###1283 It was a long night.
###1286 It took us a couple hours just to get the code to compile.
###1288 It was the first time we actually built the thing.
###1291 Then it took us a couple more hours to get it working in the
###1293 environment.
###1295 The environment that we wanted to deploy into didn't match
###1298 the environment that we were developing against.
###1300 All sorts of crazy stuff.
###1302 Finally, Friday we sleep.
###1304 Monday, we show it to the customer.
###1306 The customer was happy.
###1306 All the application did was log in, log out.
###1309 How much could we actually get done in a week?
###1311 The customer was able to log in.
###1312 The customer was able to log out.
###1313 Thumbs up.
###1314 We're all good to go.
###1316 Right?
###1317 The second Monday morning, we, as an engineering group, got
###1320 together and said, look, if we're going to go through this
###1322 every single week, we're never going to get done.
###1325 Actually, the main motivation is that we all wanted to go
###1326 out on Thursday nights.
###1327 Like, we had lives, and this thing was getting in the way
###1330 of our lives.
###1332 We wanted to go out Thursday night.
###1333 What are we going to do to make sure that this week is
###1335 not going to be a disaster?
###1338 We thought, OK, maybe we do a trial run on Wednesday.
###1342 We did a trial run on Wednesday.
###1344 We didn't go out on Wednesday night.
###1345 We were there until midnight getting the thing to run.
###1347 But Thursday night we had a good time.
###1350 Wasn't so bad.
###1350 We only had to clean up the mess that we made on Thursday
###1353 rather than cleaning up a week's worth of mess.
###1356 So you can see where this is going, right?
###1357 All of you guys understand what software development
###1361 looks like today.
###1362 Rapid iterations, continuous builds, all that good stuff.
###1365 But at the time, it really felt like we were pioneers in
###1370 a brand new industry.
###1372 We ended up--
###1373 and you guys see the end story behind all of this--
###1377 we ended up launching the product.
###1379 Amazingly, the product is still there are today.
###1383 Hopefully, all the code that I wrote is long gone, four or
###1386 five times over.
###1386 That's what it's going to take to weed the thing out.
###1389 But the product is still there today.
###1391 The customer's extremely happy.
###1393 But as importantly, by the end of the project, we ended up
###1397 with an extremely high development velocity.
###1400 From a test perspective, because we ended up automating
###1403 the tests, we ended up automating the builds.
###1405 We ended up automating the environment creation that was
###1409 necessary to deploy our code.
###1412 We ended up with an extremely high development velocity.
###1415 At the end, the only quality we had to worry about was for
###1418 the features that we developed in that particular cycle,
###1420 because all of our regression made sure that we didn't break
###1424 anything in the past.
###1426 And we also ended up with a whole bunch of artifacts.
###1427 Lots of small tests, a collection of medium-sized
###1430 tests, a handful of manual large tests that we had to
###1434 run, because browser automation this early
###1437 environment virtualization didn't exist at the time to
###1439 enable us to automate browsers.
###1441 But we learned a couple of things.
###1443 First of all, making testing easy so we, as developers,
###1448 could do it was really, really, really important.
###1451 Because then we can build a feature, write a test for it,
###1453 and be done.
###1455 We didn't have to wait for somebody to come along at a
###1457 later time to test it for us.
###1459 Also what we learned is if you hold us developers accountable
###1462 for the pain associated with building, deploying, and
###1465 testing, we would do the right thing from the beginning
###1469 rather than waiting for somebody else to come and
###1471 clean up our mess.
###1474 Fortunately, all the stuff that we built for this were
###1479 skunkworks, shell scripts, and stuff like that.
###1481 All of the artifacts are long gone.
###1483 The artifacts that we built were unique for that
###1485 particular environment.
###1486 There was only really one kind of browser
###1488 available at the time.
###1489 Really, one kind of operating system that this
###1491 was deployed onto.
###1492 So the artifacts that we built weren't really
###1496 useful in the long term.
###1497 They were useful for that particular project.
###1499 But the thought process that went into my mind, something
###1504 clicked, right?
###1505 Just like it clicked with many of you guys.
###1507 This is the right way to develop software.
###1508 
###1512 So we really felt like we were pioneers at the time.
###1515 And it's a feeling that I think I share with many of you
###1518 guys that are here in the audience.
###1520 And many of you guys that are watching this presentation.
###1522 We're at the cusp, all of us, we're at the cusp of something
###1526 that was pretty cool.
###1528 The industry changed.
###1529 A whole new discipline within computer science evolved.
###1532 Something that we, within Google, call test engineering,
###1535 and it proliferated.
###1537 It really proliferated over the last 15 years.
###1539 I wasn't the only one.
###1541 I wasn't the only one.
###1543 Many of you guys went through the same exact evolution at
###1546 the same time.
###1548 Luckily for me, and for all of us, many of you also built
###1552 artifacts that could be reused by other projects.
###1555 Think of all the technologies that exist today that we have
###1558 available to us to make all of this stuff work.
###1562 Continuous build engine.
###1564 Unit test frameworks.
###1565 All sorts of desktop and browser automation
###1567 technologies.
###1569 Virtualization, which enables us to build really cheap
###1572 environments, and have those environments be--
###1575 you can bring up an instantiate environment.
###1576 You can instantiate an environment.
###1577 You can hydrate it with data.
###1579 You can run some tests against it, then you can destroy that
###1582 environment at a relatively low cost.
###1585 Think about all the different processes that are available
###1588 to us today.
###1588 Best practices.
###1589 Agile.
###1591 Dogfooding, something that we do extensively within Google.
###1593 We have the opportunity today to take an application, deploy
###1598 it to production, and make that new version available to
###1601 a small subset of our audience.
###1602 Maybe trusted users.
###1604 Maybe 1%.
###1605 Maybe only users that are internal to your company that
###1608 can tolerate issues.
###1611 Within Google, we call that dogfooding.
###1613 We open up our application, at least new features in the
###1615 application, to a subset of our audience before we turn
###1619 around and expose it to the to the external world.
###1622 That way, if there are issues, we know about them.
###1625 And we expose them only to a limited audience.
###1627 There are also all sorts of knowledge
###1629 and information sharing.
###1630 All of you guys are here at this conference to learn.
###1634 The conferences exist about this particular topic.
###1636 That's great.
###1637 This is not the only conference.
###1638 There is lots of them.
###1640 Lots of mechanisms for information sharing today.
###1643 Books, videos, all sorts of other things.
###1648 Industry.
###1649 Many companies like Google, many of your companies, have
###1653 dedicated organizations that focus on test engineering, and
###1657 also focus on moving that industry forward.
###1661 But probably something that I'm most proud of, and we're
###1665 going to hear from some of these folks today, there's
###1668 also an entire realm within academia that's focused on
###1674 test engineering today.
###1675 So not only are we, as members of the industry, focusing on
###1680 this particular topic, there's now a fountain of information,
###1683 a fountain of research, a fountain of students, that are
###1687 coming out of universities having worked on test
###1690 engineering full time.
###1692 And we've invited several members of the academia to
###1696 come and talk at GTAC this year to help us understand the
###1699 kind of research, the kind of groundbreaking research that's
###1702 happening in universities and other institutions like that,
###1706 that enable the next generation, the next wave of
###1709 information, the next wave of test engineering to happen.
###1715 So just like I felt like a pioneer many, many years ago,
###1719 oh, so last century, right?
###1722 We've evolved.
###1724 Many of you guys have felt the same exact thing.
###1726 Many of you guys were at the forefront of
###1728 this particular industry.
###1729 We've evolved as an industry.
###1732 I thank myself that all the tools that I created for that
###1734 particular project are long gone.
###1736 If we had to deal with only the tools that we built for
###1740 that particular project, we'd never be here today.
###1742 So I want to thank the many of you that also participated in
###1745 this particular industry to take the knowledge, to take
###1747 the learnings and build the tools.
###1749 We've really evolved.
###1751 We've gone from pioneers to a well-defined industry that
###1755 we're all proud to be members of today.
###1757 
###1761 So GTAC is a little bit about sharing as well.
###1765 What I'd like to do is share about how Google goes about
###1768 doing test engineering.
###1770 We're also going to hear-- there's several talks,
###1772 including the one immediately after mine where you guys get
###1775 the opportunity to share about what test engineering looks
###1777 like about your particular companies.
###1779 I'd love to hear that, but I'll go first.
###1781 I'll share what Google is doing about test engineering,
###1784 some of the best practices that we have in place today,
###1788 and some of the challenges that we face today that I'd
###1790 love to see solved.
###1791 
###1794 First, a little bit of background about what Google
###1795 looks like as a company.
###1797 Google speed, Google scale--
###1799 we have roughly 15,000 engineers in roughly 40
###1802 different offices around the world at any given time, so
###1806 about 5,000 projects under active development.
###1809 We have a single monolithic source code tree with all
###1813 sorts of mixed language, mixed code, mixed stuff.
###1817 100 million lines of code, roughly 50% of which-- roughly
###1821 half of it changes on a monthly basis.
###1824 So it's very active great.
###1825 We spent a lot of time actually
###1826 curating the source code.
###1829 We do a lot of deletes within Google.
###1831 We don't let things rot.
###1833 Development happens at one branch.
###1835 There's head, and there's head.
###1838 That's it.
###1839 That's all we got.
###1840 All submissions are done at head.
###1843 All releases are done at head.
###1844 All builds are done at head.
###1846 All tests are run at head.
###1847 Everything runs at head.
###1850 As a result, one of the benefits is that we don't have
###1853 to support 1,000 different versions of libraries for
###1855 different applications.
###1856 Everything runs at head.
###1858 And I'll talk about the consequences of that in a
###1860 little while.
###1861 All the builds are done from source.
###1863 We actually do not pull in any binary
###1866 artifacts into our binaries.
###1867 Every single build, straight to the source.
###1870 So even a small build-- actually in my first day at
###1873 Google, or first week at Google, I built a simple web
###1876 server that just responded through to a request.
###1878 I built the thing.
###1879 I was expecting the thing to build--
###1880 have a couple of data files, a couple of .class files done.
###1884 Next thing I know, there's 100,000 files that go into
###1888 building this thing.
###1889 So even the smallest build, as a result of me building that
###1893 web server--
###1893 I just want to give a little bit of context to that.
###1895 I picked up advanced monitoring.
###1896 I picked up advanced instrumentation.
###1898 I picked up advancement metrics.
###1900 A lot of infrastructure that went into that little web
###1902 server just to respond to a simple request, but that means
###1906 that even the smallest builds can have roughly 100,000
###1910 artifacts associated with them.
###1912 It's pretty complicated.
###1914 On a given day, we have about 5,500 submissions to the
###1917 source code repository, roughly averaged out.
###1920 That's roughly 20 per second, if we were doing at average
###1927 development across a 24-hour period, which we're not.
###1929 So at peak, which roughly corresponds to about three
###1933 minutes before people go home, we have 60
###1935 plus submits per second--
###1938 per minute, roughly one per second.
###1940 That translates to about 100 million test
###1942 cases run per day.
###1945 So that's what Google looks like.
###1946 So I'd like to spend a couple of minutes talking about what
###1947 test engineering at Google looks like.
###1949 There's really two parts to that.
###1950 There are the tools and the people, but first a little bit
###1953 of context.
###1954 Google's focus is really about engineering
###1956 productivity as a whole.
###1958 The test engineering group or the discipline is part of this
###1962 greater discipline.
###1963 So as part of engineering productivity, we focus on
###1965 three things--
###1967 developer infrastructure, which is really about building
###1970 tools that every single developer within Google uses.
###1973 It's about test engineering, which primarily focuses on
###1976 test automation, but also is involved in lots of different
###1979 areas, and I'll show you examples along the way--
###1982 and also release engineering, which focuses on building
###1984 tools and optimized processes--
###1987 repeatable processes--
###1988 for getting information out the door.
###1989 But our mission is pretty simple.
###1990 We want to develop it, build it, test it, release it, and
###1993 measure it--
###1994 better, faster, stronger.
###1996 Throw in all your favorites superlatives there.
###2001 So first let me start with the build system itself.
###2004 The longer, the better--
###2006 that's kind of a bad thing if you look at things from a
###2009 developer productivity.
###2010 We want to avoid this scenario.
###2012 So Google's build system is really optimized for a whole
###2014 bunch of different things, but primarily performance.
###2016 
###2019 So what we do for performance is parallelize as much as we
###2023 can all the builds.
###2025 First thing we do when somebody does a build is
###2027 analyze all the dependencies, what can run in parallel.
###2029 Then we send those requests off to our cloud, which has
###2033 not thousands and thousands and thousands of machines just
###2036 standing by waiting to receive orders to build information--
###2040 massive performance.
###2041 We can get to roughly 60 files, we average about 57
###2046 actions every second on a 24-hour
###2048 basis through our cloud.
###2052 We also optimize for correctness.
###2054 Make clean is a bug.
###2057 You should never have to make clean.
###2058 If you have to make clean, there's a bug
###2060 in the build system.
###2061 There's something that's not defined.
###2063 There's something that's not declared.
###2064 There's something that's incorrect.
###2066 Our build system imposes that correctness on on everything
###2070 that we do.
###2071 Incrementality also fits in.
###2073 We want to do the least amount of work.
###2075 That has two consequences.
###2077 First, we want to figure out the least amount of work that
###2079 needs to be done for that particular developer.
###2082 That's pretty well understood, and all the build systems
###2084 around the industry do that.
###2085 But we also want to make sure that across Google as an
###2089 enterprise, we do the least amount of work.
###2092 That means if my colleagues over in the other side of the
###2095 world-- let's say Mountain View--
###2096 have done a built at a particular revision.
###2099 And I then do a build of that same revision, and the same
###2103 file, same target here in New York.
###2105 I should not have to repeat the compilation.
###2109 They built it.
###2110 I should be able to reuse it.
###2112 So our cloud actually caches the output of all the builds,
###2116 and I benefit from somebody else's build of the same
###2119 target at that same revision.
###2122 We also want to simplify use by developers, so our build
###2124 system is multi-functional.
###2126 I can build a file.
###2127 I can run that particular target.
###2129 I can test that target.
###2131 I can run source code coverage for that particular target.
###2134 And then I can do a dependency analysis on that particular
###2137 target, all using the same commands, just by changing
###2140 arguments-- the same basic command.
###2143 I don't have to go and do crazy things.
###2145 The same applies for multi-language.
###2147 I, as a builder, don't have to know whether it's a Java
###2150 target, a Python target, a shell target, a C++ target, a
###2153 JavaScript target.
###2155 I want to just run the test against it, I run that target
###2158 and I run the tests against it--
###2159 pretty simple, pretty powerful.
###2163 There's lots of talks, and I've provided these URLs that
###2166 go into a lot more detail about our build system.
###2168 Feel free to go check them out.
###2171 Some performance numbers about our build system--
###2174 this talks about incrementality.
###2176 About 90% of our builds run less than 20 seconds.
###2180 It's only when you get in the 90th percentile and higher do
###2183 our builds take a lot longer than that, because the caching
###2185 doesn't kick in.
###2186 You're building something from scratch
###2187 that nobody else built.
###2190 Our cache--
###2192 anywhere from 89% to 98% effective, depending on what
###2196 you want to do.
###2198 There are actually two levels of caches, one on my local
###2200 workstation--
###2201 so if I run two builds in a row, my second build leverages
###2205 the first build.
###2205 I don't have to go back to the cloud to download all that
###2208 information.
###2209 But let's say the first time around, I run my build.
###2212 89% of the time, I will be leveraging off of somebody
###2215 else's build.
###2216 The great part-- and I'll talk about the continuous build
###2219 engine-- our continuous engine is sitting there building
###2221 stuff at every single change.
###2223 I as an individual developer can take advantage of the
###2226 cache that's been primed by our continuous build system.
###2228 
###2232 Build performance over time has also decreased, even
###2235 though the amount of code we've typically have to build
###2237 has increased.
###2238 This is a direct result of test engineering--
###2241 or just straight up engineering--
###2242 against the build system to make it more efficient, better
###2245 analysis of dependencies, better analysis of
###2247 parallelization, but also just plain old faster computers
###2251 that we can run our builds against.
###2254 We talk a little bit about test execution.
###2257 Just like builds, tests also happen in extreme parallel.
###2260 So if a particular test suite has four test cases-- as this
###2263 one does, this example does--
###2265 we'll run all four of them in parallel.
###2267 More so, we'll actually start the execution of tests as soon
###2271 as the build for that particular test is done.
###2273 So if test one, test two, test three, and test four need to
###2276 be built, if test four--
###2278 the build for test four gets done first, the execution for
###2281 test four will start first.
###2284 If test four fails, we don't even bother waiting for the
###2287 other three to report in.
###2289 Test four fails, therefore the entire test suite fails.
###2292 We report that right away so the developer can
###2295 start taking action.
###2296 And this might actually happen before test one, test two, and
###2298 test three even finish building.
###2301 Our continuous build system ties these two tools together.
###2304 Widely adopted within Google, there's one continuous build
###2308 system that accounts for the vast majority of all the
###2310 builds that we have within Google.
###2313 This is what its user interface looks like.
###2315 There's two key components of this continuous build system
###2317 that I'd like to talk about.
###2320 First is the before and after submit test abilities, and the
###2324 second one is about flaky tests and the
###2326 consequences thereof.
###2327 The first one is actually really key.
###2330 Like I learned in my first project, if you make it really
###2333 easy for developers to run tests, and hold them
###2337 accountable to that, they will run tests and check code
###2341 that's actually correct into the repository.
###2343 You don't have to find out about after.
###2345 So our continuous build system has
###2348 what's known as a presubmit.
###2349 I can take some code that I'm sitting and editing on my
###2352 workstation, hand it over to the continuous build
###2354 environment and say, take this, merge it in with the
###2357 last known green, and tell me whether I'm going to break the
###2360 build or not.
###2361 That's great.
###2363 I don't have to set up my workstation in any special way
###2367 to make test running possible.
###2369 It's just a generic workstation.
###2371 It's going to be running my code, and changes are going to
###2374 be running in the same exact environment that the
###2377 continuous build engine uses to determine whether tests are
###2379 correct or not correct.
###2380 So that's fantastic.
###2382 We actually take that to an even more extreme level.
###2386 As soon as code is submitted for a code review within
###2388 Google, the code review process not only sends it to a
###2391 human being-- another human being to go take a look at,
###2394 but it also sends it to the continuous
###2396 built system to evaluate.
###2398 We don't wait for the developer to ask the
###2401 continuous build system whether the code's OK.
###2402 We just do it proactively.
###2404 So roughly the same amount of time, likely maybe even
###2407 faster, they'll hear from their peer in
###2409 terms of a code review.
###2410 Your code looks good.
###2412 Your code is horrible, throw it out, start from scratch.
###2414 Or anywhere in between.
###2415 You'd also hear back from the continuous build system--
###2418 your tests pass, your tests fail, anywhere in between.
###2421 What tests fail, what the logs are--
###2424 they'll get notification.
###2425 They'll also get a great email, and this was a tool
###2427 that was built by my colleagues over in Zurich.
###2431 They'll get an email that says, your incremental code
###2434 that you just added only has 23% test coverage.
###2437 For example, I picked 23% out of a hat.
###2440 So we do incremental test coverage--
###2443 source code coverage right there dynamically on behalf of
###2446 the user in an attempt--
###2449 and I'll be nice-- in an attempt to notify the
###2451 developer about what level of coverage their
###2454 incremental code has.
###2456 OK, I'll stop being nice.
###2457 It's really about shaming them into believing that they
###2459 should be writing more tests for stuff
###2461 that they're writing.
###2462 But they get this stuff all proactively.
###2463 It's right there.
###2465 And the code reviewer also sees it.
###2467 So here's an incentive for the developers, right off the bat,
###2470 to do the right thing.
###2473 Our continuous build system also handles fine grade
###2477 dependencies.
###2477 That's one way of lowering compute costs for us.
###2481 Like I said, 100 million tests a day.
###2482 That's pretty expensive to run all of them.
###2484 We only run the tests that are actually necessary.
###2486 We know all the dependencies through the build system.
###2488 We know what test is impacted by what particular change.
###2491 We'll only run the tests that are appropriate for that
###2494 particular change.
###2496 Flaky tests--
###2498 endless pain for us, flaky tests.
###2502 Flaky test is defined as a test that is
###2504 non-deterministic.
###2506 Given a fixed environment, particular revision of code,
###2509 particular set of changes, you run the test numerous times,
###2513 and the test gives you different results.
###2516 There are lots of possibilities for what causes
###2518 flaky tests--
###2519 environmental issues, code issues, test code issues
###2523 itself, et cetera.
###2525 You can imagine if there's a routine that returns a random
###2528 number, and the unit test that tests it tries to check that
###2532 the number is below a particular threshold.
###2534 Well, maybe if it's testing a 50-50, it will pass half the
###2538 time and fail half the time.
###2540 So, non-deterministic flaky tests are shown in this
###2545 particular display by the scattering of reds.
###2547 By the way, the solid line of red, that's a failure that was
###2551 submitted by a particular user.
###2553 That's the second to last row from the bottom.
###2555 But the miscellaneous reds that you see there are all
###2557 flaky tests.
###2558 They're tests that are non-deterministic.
###2560 Why is this a problem?
###2562 Well, first of all, if the developer's making a change,
###2565 and they submit their change into the presubmit queue and
###2569 the presubmit queue fails, the developer does not know
###2572 whether it was the change that they introduced, or if it was
###2576 a flaky test that caused that particular failure.
###2579 Worst case, they go and they start trying to find out
###2581 what's going on within their code that caused this
###2585 particular problem.
###2588 We would love to be 100% correct around tests passing
###2592 and failing, because that would enable us to go to the
###2594 next level of automation.
###2595 If we detect a failure, we reject.
###2598 We roll back the submit.
###2600 That would be fantastic.
###2602 But we can't do that, because of flaky tests.
###2603 So we do three things.
###2605 Our build system keeps track of flaky information.
###2608 And that particular tool was built by my colleagues over in
###2610 London to measure, understand, and present back to the
###2615 developers the level of flakiness associated with a
###2617 particular test.
###2618 It's pretty easy to see the different patterns with flaky
###2622 tests as opposed to real failures.
###2623 So we do statistical analysis and try to come up with some
###2626 particular numbers.
###2628 We try to get the developers to fix them.
###2630 So by letting them know their tests are flaky, by shaming
###2632 them into letting them know that they're tests are flaky,
###2635 we get the developers to fix them.
###2638 If we can't, we do the least popular thing, and we just
###2642 retry tests over and over and over again until we determine
###2648 that the test is flaky, or we determined
###2652 that the test is OK.
###2655 We look for a pass.
###2657 As you can imagine, as I showed before, our submits
###2659 into the source code repository are not uniform
###2661 over a 24-hour period.
###2663 So we can take advantage of the overnight hours to do
###2666 incremental source code computation
###2669 for all of our projects.
###2670 We also do extra analysis of flaky tests overnight.
###2674 So that's our continuous build system.
###2675 Some statistics about it--
###2677 number of submits per day.
###2679 A CL within Google is called a changelist.
###2680 It corresponds to a particular change that was committed into
###2684 our repository.
###2685 Linear growth over time--
###2687 that's fantastic.
###2688 We hire more developers.
###2690 More developers write more code.
###2691 We have more submits over time.
###2692 
###2695 The good news is that those developers are not only
###2697 writing code.
###2697 They're writing tests.
###2698 So the number of seconds that we need to use to compute code
###2703 test runs for every single submit is also
###2706 going up over time.
###2707 That's fantastic.
###2708 Developers are writing more tests.
###2710 For any given change, we run more tests.
###2712 We're happy to do that.
###2713 But I have kids that are going through geometry today, so I
###2716 understand this.
###2717 When you take a straight line, multiply it by a straight
###2718 line, you end up with a quadratic.
###2721 Quadratics are bad.
###2723 There is no way-- even with all the data centers that
###2727 Google has, there is no way that we at Google can keep up
###2730 quadratic growth across all of our test cases.
###2734 I remember we actually had a conversation.
###2736 Our developer tools group had a conversation with our data
###2739 center people.
###2740 They went up to them and they said, we need more
###2742 machines to run tests.
###2744 The data center people, being data center
###2746 people, were quite blunt.
###2747 They said, you have a choice to make.
###2749 You can run your tests.
###2750 We have enough computers to run your tests.
###2753 We'll have to shut down all the production applications.
###2756 You guys OK with that?
###2758 Tests or production?
###2759 What do you guys want to do?
###2761 AUDIENCE: [INAUDIBLE]
###2762 ARI SHAMASH: Yeah.
###2763 
###2765 So that's where we are today.
###2767 We are heavily applying engineering to solve a brute
###2771 force problem.
###2771 This is a theme that comes up over and over and over again,
###2774 and I've seen this over the last 15 or 20 years.
###2777 When you can apply brute force, the easiest thing to do
###2780 is apply brute force.
###2781 But brute force times out after a
###2782 certain amount of time.
###2783 You just can't scale.
###2785 You have to start thinking about better ways of doing
###2787 things, and that's what we're doing today.
###2789 So maybe we don't run the tests at every single change.
###2791 We run them periodically, and then we'll run all sorts of
###2793 interesting culprit finding to try to figure out where in
###2796 between that the breakage was.
###2798 There's actually a talk tomorrow about culprit finding
###2801 within Google.
###2802 
###2804 So let me talk a little bit about the people, the people
###2806 that make this all happen within Google.
###2807 There are two roles--
###2809 SETs and TEs--
###2810 within the test engineering group at Google.
###2812 We within testing engineering do a handful of things.
###2815 We create processes and plans that would help test a
###2818 particular product.
###2819 We think of best ways to maximize coverage.
###2822 But we also are highly involved in building a lot of
###2825 the tools that I talked about.
###2826 In fact, many of the tools that I demonstrated were built
###2829 by the test engineering folks here at Google.
###2831 I'll show you guys some examples.
###2833 There are some links that you can go to to
###2835 read more about this.
###2838 First one, probably making up roughly 50% of what we do, is
###2842 really focused on flaky tests.
###2844 I described earlier the problems with flaky tests.
###2848 They're a huge cost, and they're a huge time sink.
###2851 How do you eliminate flaky tests?
###2853 You build hermetic environments you can
###2855 run your tests in.
###2856 Hermetic environments are self-isolated environments.
###2860 Instantiated tests are run against
###2862 them, and then deleted.
###2864 The more hermetic they are, the less external dependencies
###2867 they are, the better.
###2871 The cheaper it is to create that environment, the faster
###2874 the tests will run.
###2877 So a lot of the engineering that we do is about building
###2879 consistent, reproducible, hermetic environments, so we
###2883 can run multiple of those environments and run tests at
###2885 the same time.
###2886 For a typical application, we might be running 5, 10, 15, 20
###2890 instances of that application at any given time in parallel
###2894 with different revisions of source code being tested
###2896 against that application.
###2897 That's pretty common.
###2899 We need separate environments that don't interact with one
###2901 another and don't interfere with all the testing
###2903 that goes on there.
###2904 So that's roughly 50% of the time what we do, and there's a
###2906 link over there that has more information.
###2910 Another one is metrics.
###2911 If you can't measure it, you can't really understand it or
###2914 control it.
###2914 So we try to measure lots of interesting things.
###2917 We're Google.
###2917 We love data.
###2919 We collect lots of interesting data and present it to
###2922 developers as a way, again, to get the engineering groups to
###2925 the right thing.
###2926 And when I talk about developers, I actually mean
###2927 us, because we're developers as well.
###2929 So we collect metrics for test engineering, in addition to
###2932 collecting metrics on the developer engineers--
###2936 or the product engineers, the developers on products.
###2939 First one-- and I'll kind of go around the slide, starting
###2942 with the upper left hand corner.
###2944 This is positive reinforcement about
###2946 incremental source code coverage.
###2947 This was built by my colleagues in London.
###2950 They had this idea that for every single submit, we'd
###2953 measure the incremental source code coverage.
###2956 And if it's good source good coverage, we'd give credit to
###2959 the person who submitted it.
###2961 So here it is.
###2962 We have these lookout displays scattered
###2964 all around the offices.
###2964 If any of you guys are going on tours, look around.
###2968 There's a whole a handful of them around the
###2970 fourth floor here.
###2971 They're constantly being refreshed with update metrics.
###2974 So that's an example of econometrics
###2976 that we put up there.
###2977 These lookout displays scroll through lots of different
###2979 information.
###2980 If a person does a great job with incremental source code
###2983 coverage and they submit a change that's got high
###2985 coverage, they get their picture up there.
###2988 It's right there in the middle, nice and big with lots
###2991 of green around it.
###2992 The group that this was deployed into started a
###2995 friendly competition of who can get the highest green,
###2998 most number of greens, get their face up there as often
###3002 as possible.
###3003 Fantastic.
###3004 Loving it.
###3005 This utility alone raised source code coverage for
###3008 applications by a significant amount.
###3012 Bottom left hand corner is latency metrics.
###3015 So we measure constant performance of application,
###3017 make that information available.
###3018 We don't wait until the application is in production
###3020 to find out that significant performance problems
###3024 are about to hit.
###3026 We measure.
###3026 We show it.
###3027 We move on.
###3028 We also show build status, and that's that green Project X
###3032 status that passed today, last timestamp, whatnot.
###3035 There are some groups, who shall remain nameless, that
###3040 don't adhere to the--
###3042 or don't respond to the positive reinforcement that's
###3045 on the top left hand corner.
###3048 We had a problem with a particular group where non
###3050 high priority bugs, like the P3s and P4s were piling up.
###3054 And the group was just not motivated to go and fix them.
###3058 So we brainstormed about this.
###3059 We tried all the positive reinforcement--
###3061 giving them kudos for fixing bugs, rewarding them,
###3065 recognizing them, doing all the good things.
###3067 Didn't make a difference.
###3069 So we went the other way--
###3070 public shame, humiliation.
###3075 We put this utility together.
###3076 We need it black on purpose-- black is ugly--
###3080 with lots of red around it-- accusatory, put
###3084 up the worst offender.
###3086 We were sitting there in the morning.
###3087 A bunch of us were sitting there.
###3088 It was nice and quiet.
###3089 We were sitting there typing away.
###3090 The next thing we know, somebody comes in.
###3093 And I'll give you the G rated version, because GTAC is a
###3097 family-friendly sort of of conference.
###3099 Why is my picture up there?
###3103 Comes up to us-- why is my picture up there?
###3106 It was a lot more colorful.
###3107 
###3110 You had a lot of bugs.
###3111 What do I do to get my picture out from there?
###3114 Go fix your bugs.
###3116 The entire day, we hear furious typing, lots of
###3118 banging, lots of other choice words.
###3121 Picture disappears by late afternoon.
###3125 Next thing we know, why is my picture up there, from the
###3127 second person who's up.
###3129 You have lot of bugs.
###3131 Go fix them.
###3133 Needless to say, a few weeks after that, problem solved.
###3138 So in the summary, for test engineering, we really look
###3142 for creative ways to introduce cultural change so things are
###3146 done correctly right up front with our developing groups.
###3150 So the impact of test engineering--
###3152 and you know we're not in with every single
###3154 product within Google.
###3154 There's only about 800, 900 of us or so against a population
###3158 of 15,000 engineers.
###3160 So we're not engaged with every single group.
###3162 But the groups that we do engage with, first of all, are
###3165 really happy to have test engineering support.
###3168 But we also have demonstrable impact.
###3170 For example, Google+--
###3171 100 new features released in the first 90 days.
###3174 That's roughly, on average, more than a release a day.
###3179 Search, we can go from an idea to production in 48 hours--
###3184 less than 48 hours.
###3185 And Chrome-- the browser--
###3186 six weeks, regular schedule, [INAUDIBLE].
###3189 That's the impact of test engineering.
###3192 I also want to pause at this point.
###3194 I know Tony addressed this.
###3195 But really, it's test engineering, the discipline of
###3197 test engineering within Google, that sponsors this
###3200 conference year in and year out.
###3202 There's lots of volunteers from the test engineering
###3204 discipline that help put it together this year.
###3206 And the test engineering discipline funds
###3208 it year over year.
###3209 So I want to say thank you to the various members that
###3212 organized this conference, and the various individuals and
###3215 executives that form test engineering, but also made
###3220 this particular conference happen.
###3221 
###3224 So now it's your turn.
###3226 Over the next couple of days, we're going to hear many of
###3228 your presentations about what test engineering at your
###3231 particular companies looks like.
###3233 Maybe you call it something different.
###3234 Love to hear the names.
###3235 We'd love to hear your best practices.
###3237 We'd love to hear your challenges.
###3238 What can we learn from each other to
###3241 improve all of our practices?
###3244 So I have a question.
###3246 Are we done?
###3248 Are we done with test engineering?
###3251 Here we were 15, 20 years ago.
###3254 We clearly had a lot of work to do.
###3255 We were all pioneers in a brand new space.
###3257 Are we done?
###3259 We kind of have awesome tools.
###3261 All this stuff works.
###3262 We're able to develop software.
###3266 So the question that I have--
###3267 are we about coffee?
###3270 Do we need to hunker down and drink more coffee, and
###3273 continue engineering [INAUDIBLE]
###3274 test engineering?
###3275 
###3279 Or is it about beer?
###3280 Do we pick up some beer now?
###3282 Samuel Adams-- again, a shout out to my
###3284 friends over in Boston.
###3285 Fantastic beer.
###3288 Should we grab some beer and go celebrate, be done?
###3291 Are we done with this particular discipline?
###3295 I think the answer is no.
###3297 As much as I would love to get together and drink some
###3299 beers-- it's only about 10 o'clock in the morning.
###3300 It's a little early.
###3302 We're not in Ireland.
###3303 
###3306 Coffee is still good.
###3307 But we have a lot of work to do, because the world is
###3309 changing underneath us.
###3310 And that's really why many of us are here today.
###3313 Let's take some statistics from YouTube.
###3315 72 hours of video are uploaded every
###3317 single minute to YouTube.
###3319 Four billion hours of videos are watched
###3321 every single month.
###3323 While developers are sitting there watching videos while
###3325 they're waiting for their build systems.
###3328 2011--
###3329 more than one trillion views--
###3331 140 views for every single person on the earth.
###3334 That's even assuming that every single person on the
###3336 earth has internet access.
###3338 Most interestingly, 70% of the traffic comes from outside the
###3342 United States.
###3344 That's on the media side.
###3344 On the mobile side, 25% of traffic to YouTube comes from
###3349 mobile devices.
###3352 So I started thinking about this and said, is this is
###3355 really a problem?
###3357 That's great.
###3357 That's great that YouTube has all these fantastic statistics
###3360 showing the change.
###3362 Is this a problem?
###3364 So I looked at various different sources on the web.
###3367 The source for this particular graph is up there.
###3370 Mobile versus desktop traffic--
###3372 desktop is that 85%.
###3374 Mobile is at 15%.
###3375 We all apply the 80-20 rule.
###3378 I don't know.
###3379 This looks to me like we're kind of done.
###3380 We figured out the desktop.
###3382 We figured out how all of its issues with the desktop.
###3385 We know how to mock out all of its inputs.
###3387 We know how to mock out all of its output.
###3388 We know how to analyze the output.
###3390 We have image comparison.
###3391 We have great tools for understanding of applications
###3393 that are working well.
###3394 It looks like we're done.
###3397 Then Eric Schmidt--
###3399 former CEO, current chairman of Google--
###3403 and his buddy Jared Cohen wrote a book-- it was actually
###3407 just published today.
###3410 I got my copy yesterday.
###3411 Fortunately I got a chance to read through some of it--
###3413 called "The New Digital Age," that talks about some of the
###3416 changes that are under foot.
###3418 And I'd like to tell you a little bit about it.
###3419 And the first thing he says is that there's only about two
###3421 billion people that are on the internet today.
###3424 But he predicts that in the next few years, five billion
###3427 more-- the incremental--
###3428 will come online.
###3430 And he's seeing some early indicators that this is true.
###3435 First, he visited Iraq in 2009.
###3438 The first thing he noticed in this war ravaged country,
###3442 trash wasn't picked up.
###3444 Reliable water was not evenly available across the country.
###3449 The first thing that they got up and running, one of the
###3452 highest priority items in Iraq, was getting a mobile
###3455 network so they can exchange information from one another.
###3460 One of the first things that they got up and running.
###3462 Like to tell you about another story in Africa, again, as he
###3469 was traveling the world.
###3470 In the Congo fishermen--
###3473 actually, fisherwomen--
###3476 fish.
###3476 They used to take their fish to the market.
###3479 If they were lucky, they sold them.
###3480 If they were unlucky, the fish went bad, they threw them out.
###3483 Using mobile devices, they actually leave
###3487 the fist in the river.
###3488 They catch the fish, but they leave them in the river until
###3491 they have a customer ready to pick them up.
###3493 They receive notification on their mobile device.
###3496 They take a fish out of the water.
###3497 They give it straight to the customer.
###3499 No loss in inventory, maximize their opportunity.
###3502 And this actually created a semi-economy there, if
###3505 somebody has fish that another fisher person wants, they can
###3509 now exchange it among themselves using mobile
###3511 technology.
###3513 Lots of interesting stories.
###3516 So are we done?
###3516 Again, is Eric right?
###3519 So I started looking to more data, and this one, again, the
###3523 source is on the bottom.
###3524 74% of the developed world is already using the net, but
###3529 only 26% of the developing world is using the net.
###3533 And if you average it out relative to population, the
###3536 average is 35%.
###3537 Much closer to the developing world line than the developed
###3542 world because there's a lot more people in the developing
###3545 world that still have to get connected.
###3550 So let's revisit these graphs again looking at them from
###3552 different geographical perspectives.
###3554 Let's take South Korea.
###3556 South Korea is highly advanced, but the story there,
###3559 desktop versus mobile, tells a very different story.
###3562 Much closer to 60-40 than it is worldwide.
###3568 Let's take another step and look at India.
###3571 The story in India is radically different.
###3573 There's a lot more mobile stuff going on than there is
###3576 desktop stuff, and this trend is only
###3579 going to continue growing.
###3580 So mobile's already here today.
###3582 It's something that we have to address today.
###3584 
###3587 There's lots of challenges with media and mobile, and
###3589 I'll run through them.
###3591 Platforms.
###3592 Tremendous amount of variability in platforms.
###3594 Lots of hardware, lots of different operating systems.
###3600 The operating systems themselves may not be as
###3602 stable as you would love them to be.
###3604 And unlike on the web where I as an application developer
###3608 had complete control of the stack, top to bottom, in my
###3611 production environment, that's no longer true
###3613 on the mobile side.
###3615 If I'm an app developer, I now have to deal with other
###3618 applications that are on the device-- my application, the
###3620 operating system, all sorts of different combinations and
###3623 permutations that are going on.
###3625 The hardware is different, the platforms are different.
###3627 Input.
###3630 There's no longer just a keyboard and mouse.
###3632 There's tremendous amount of variability in input these
###3634 days across all the different devices.
###3638 There are cameras.
###3640 There are GPS receivers.
###3642 There's touchscreen.
###3643 There's gestures.
###3645 There's physical buttons.
###3646 There's voice recognition.
###3647 You can tell the device what to do.
###3650 On the output side, there's all sorts of devices.
###3654 Resolutions, languages, all sorts of issues around that.
###3661 Also the network is no longer consistent.
###3663 The same application that's running on the web, at least
###3665 you can assume that if the application is running, you
###3667 can talk back home.
###3669 It managed to get downloaded somehow.
###3671 Offline is getting better and better every single day.
###3674 But really, how many desktops are offline?
###3677 Mobile is no longer true.
###3678 The same application that's running can experience, within
###3681 minutes, lots of network, no network, medium network,
###3685 network bandwidth, network latency, all sorts of the
###3687 variability on the network side that have to be dealt
###3690 with in some sort of interesting way.
###3692 On the media side, the variability in
###3694 quality is as high.
###3695 Codex, will this media work on this particular device?
###3698 Will it work well?
###3699 Will it stream?
###3700 Will it be real time?
###3701 How do I understand video quality?
###3704 Any of you have taken compressed videos and looked
###3707 at them image by image, you'll see that the images are
###3708 radically not good.
###3710 
###3715 But that's OK, because our brain does a great job of
###3716 taking a sequence of them and putting them together.
###3720 Sound.
###3721 Our ears are not as forgiving.
###3723 If there's a pop in the noise, instantly our brains will
###3727 determine that this is bad.
###3729 Software delivery mechanisms have changed.
###3731 We now have to, again, go back to the world where we're
###3733 downloading software.
###3735 We're allowing the user to download software, and if we
###3739 want to release a new version, we no longer can do it
###3741 instantaneously and give access to all of our
###3743 developers.
###3745 We have to wait for the developer to download it.
###3747 So again, we have to deal with multiple, different versions
###3749 at the same time.
###3750 Worse, there's now an intermediary between
###3752 our users and us.
###3753 The app stores are there.
###3755 Security, privacy.
###3757 We have to go back to a world where malware, and viruses,
###3760 and all these other things are at play.
###3762 Also device sharing is at play.
###3767 So these are all the challenges.
###3769 And again, I feel like we're pioneers again, coming back to
###3771 be same feeling that I had when I started my little
###3774 adventure in the 1990s.
###3776 I feel like we're about to begin
###3778 on a brand new adventure.
###3780 We're all pioneers in this brand new industry, having to
###3783 solve roughly similar problems that we solved many, many,
###3787 many moons ago.
###3789 All of us collectively have to solve them, but
###3791 in a brand new space.
###3792 
###3796 And if we think mobile and media are it today, the next
###3803 generation of devices is upon us.
###3805 You got one of these guys.
###3808 We have to worry, how do you test this?
###3810 It's a whole new challenge.
###3812 The number of inputs that are available to this particular
###3814 device are enormous.
###3815 Cars.
###3816 How do you test cars with all their inputs and outputs and
###3818 all the decisions that they get to make?
###3820 And all the other devices?
###3824 So I'd like to close by saying all of us are pioneers.
###3830 All of us are in this adventure together.
###3835 Let's put on our thinking caps.
###3837 Let's share, let's collaborate.
###3840 Coffee.
###3841 Beer later, but coffee now, and figure out what the next
###3847 wave of test engineering is going to look like for these
###3849 new devices, both for the media and for the mobile
###3853 devices today, and for the next
###3856 generation devices tomorrow.
###3857 Same sort of adventure that many of us have gone through
###3860 starting on the desktop.
###3862 Let's take all of our thinking for the desktop and apply it
###3865 for all this new world.
###3867 Thank you very much.
###3868 I hope you enjoy this conference.
###3869 [APPLAUSE]
###3876 TONY VOELLM: Wow.
###3878 That was a fantastic, Ari.
###3881 Thank you for that.
###3882 I learned some really important things in this talk.
###3884 One is Ari is going around taking pictures of people
###3888 sleeping at their desk.
###3889 You're see that.
###3891 So watch out.
###3892 If you're sleeping, he may take your picture.
###3893 ARI SHAMASH: But not me.
###3895 I never sleep at my desk.
###3896 TONY VOELLM: And the other thing I noticed in his graphs
###3900 is there's a quadratic decrease in productivity at
###3902 Google right around January.
###3904 2 Who would figure this?
###3906 End of December, January.
###3908 So hopefully, all you've got some really good notes.
###3911 I joke around about these things, but there are a lot of
###3913 great thoughts in here, and a lot about the challenges that
###3917 are going to be there going forward and all the problems
###3920 that we need to solve.
###3921 That's what all of you are here.
###3923 If you're not spending time during the breaks talking to
###3926 each other, you're not getting the most out of this
###3928 opportunity.
###3929 So we really want everybody here to be talking to
###3931 everybody else, so please do that.
###3934 Two quick things.
###3935 We have transcribers that are over in this corner.
###3937 Everybody's done a great job not standing between where I
###3940 am and over there.
###3942 Just be cognizant, please don't do that.
###3944 Otherwise they can't get the transcription correct.
###3947 And we also have somebody signing over
###3949 here, which is great.
###3950 So thank you.
###3951 Hopefully I just didn't have some bad word or
###3954 something like that.
###3954 I think that's thank you.
###3955 I grew up near Gallaudet College, so I
###3956 picked up a few things.
###3958 And with that, we're going to move on into our next speaker.
###3964 So we have James Waldrop here from Twitter.
###3967 He tells me that he is an avid kayaker.
###3970 He likes to kayak at night mostly because his kids are
###3974 sleeping then, which I can very much appreciate.
###3977 I get to walk the dog somewhere around midnight, so
###3979 that's something that we definitely share in common.
###3982 And even though I'm not going to explain to you why, if you
###3985 want to go out to moderator, you should put this question
###3987 in there about why is his product labeled "Lago?"
###3992 Because he loves this question, that's what I heard.
###3994 So with that, James, come on up, and we're excited to hear
###3999 about your talk, Testing Systems At Scale.
###4001 JAMES WALDROP: Thank you.
###4003 [APPLAUSE]
###4008 JAMES WALDROP: Thanks, Tony.
###4010 Let's see, yes, the product.
###4015 It's really an open source library.
###4016 I try not to basically say too much about it, except clearly
###4024 at presentations like this.
###4026 It's actually called Iago, with an I. The font used for
###4031 these presentations is sans serif, so please keep that in
###4034 mind as you look at the name of it, because I constantly
###4039 get questions about Lago, and people who are clearly using
###4043 sans serif fonts are looking at this going, OK, that's an
###4047 L. It's not an
###4048 L. It's an I. Anyway.
###4051 So, I joined Twitter about two years ago, a little more.
###4056 And when I joined Twitter, my first week we had an outage
###4060 where the site was not available to users.
###4064 And the experience for the users was this.
###4067 And this is not a great experience for your user if
###4069 you care about actually keeping your service up,
###4072 although it's an amusing picture.
###4075 People love to make fun of it.
###4077 Clearly, if you're an engineer who works at Twitter, this is
###4080 a very sad face image.
###4082 You do not want to have this showing up, and your mother
###4084 calling you and saying, hey, your system's down.
###4088 So how do we get rid of the Fail Whale?
###4093 In the last couple years, we've gone a long way towards
###4095 getting rid of it, and I'm basically going to talk about
###4097 how we do that at Twitter.
###4099 Specifically, if anybody really wants to know the
###4103 meaning of it, Fail Whale is a 502 HTTP response code.
###4110 If it takes more than five seconds to render your request
###4113 or to respond to your request, then we will serve you a Fail
###4116 Whale instead.
###4117 And so that gives you an idea of exactly what's going on
###4121 behind the scenes when you see that.
###4122 It's not a great story.
###4124 So why the Fail Whale?
###4126 
###4130 I'm sure there are quite a lot of Ruby advocates in the world
###4133 and in this room, and a lot of the systems at Twitter
###4138 famously were built on top of Ruby on Rails.
###4141 I'm not going to say anything bad about Ruby.
###4144 I will say, though, that when you have a monolithic
###4148 architecture that has all been written in one big blob of
###4153 code, effectively, then it becomes very hard to
###4156 effectively manage that code, both in terms of its
###4160 performance and in terms of its ability to
###4163 make changes to it.
###4164 So the Ruby world has a lot of interesting ways to achieve
###4167 performance these days at the scale that we care about, and
###4171 unfortunately, we really couldn't do any of them
###4173 because of our monolithic body of code that wasn't able to be
###4177 iterated on in a reasonable way.
###4179 
###4182 The answer to that, of course, was to decompose it.
###4185 And so at this point, I think we have something along the
###4189 order of about 120 services in production.
###4191 So we've taken this monolithic body of code over the course
###4194 of the last two years and turned it into a lot of little
###4197 services which are written in many different languages,
###4200 including many on the Java Virtual Machine, Java Scala,
###4205 Closure, and then also some written in things like Python,
###4209 C++, and still Ruby.
###4211 But now that it's decomposed, we can make
###4216 changes to it more quickly.
###4217 Our engineering organization of, hey, I'm going to build
###4220 this particular area of the product, and you're going to
###4223 build this area over here, actually is able to work that
###4226 way because they have their own services that they can
###4229 deploy, and this guy over here has his own services that he
###4231 can deploy.
###4232 And so they can work relatively independently of
###4235 each other.
###4236 The problem with this, as anybody who's maybe gone
###4239 through this or if you think really fast, you might realize
###4243 that there's an issue here, which is that as you move from
###4248 this monolithic world to a service-oriented world,
###4252 testing becomes a huge problem.
###4254 Because in order to test any given piece of software to
###4258 find out if it can handle production load, you need to
###4261 be able to stand up that whole environment.
###4262 And in the case of Twitter and in the case of, for instance,
###4265 the previous Talk Google, that's probably close to if
###4267 not impossible.
###4269 And so how do we test in this new world?
###4273 How do you test systems at scale when any one service
###4277 might depend on 20 downstream services, and they in turn
###4279 depend on another 20 downstream services.
###4283 In told, if you want to stand up any front end environment,
###4286 you're probably going to have to stand up 80 of those 120 or
###4288 whatever number of services we have in production.
###4291 
###4300 The rest of this talk will be about
###4302 synthetic, artificial load.
###4304 Clearly, I wanted to give kind of a front page shout out to
###4309 all the other ways that we have to test performance, but
###4313 I will say that all of them are in production.
###4315 And I don't know about people in this room, but personally,
###4318 I feel like if I'm testing it in production, and my users
###4320 can experience pain or I can take the system down, let's
###4323 say, in production, then that's probably too late to be
###4326 testing it.
###4327 And I really want to test it before any of that can happen.
###4331 But the techniques that we have to test in production, as
###4334 far as performance goes, are canaries.
###4337 Canary, if you're not familiar with the concept, you have a
###4339 cluster of systems that are handling requests,
###4342 maybe 1,000 of them.
###4343 You deploy your new version of software to one of them, and
###4346 now it's taking 1% of the traffic, and you get to see,
###4349 hey, is it getting better or worse as
###4352 compared to the old system?
###4354 Clearly, though, it's taking production traffic.
###4357 There's dark traffic.
###4358 This is a little safer.
###4360 It is basically a system-- and we use
###4362 this heavily at Twitter--
###4363 
###4366 we have a front end called TFE.
###4368 Funny name, right?
###4369 TFE will take traffic, and then if it's configured in
###4373 such a way as to do this, it will send all of the traffic
###4379 to the normal production systems, and it will copy,
###4382 send a second request, to a system that's not stood up yet
###4385 and whose response it's going to throw away.
###4389 But now users aren't affected unless, for instance-- this
###4391 has happened, sadly--
###4393 the system that it's sending the traffic to doesn't respond
###4398 in a reasonable amount of time, and TFE isn't
###4400 necessarily configured correctly in
###4402 order to handle that.
###4403 Let's say, pretend that this might not have happened six
###4405 months ago.
###4408 And lo and behold, you have an outage caused by dark traffic.
###4413 And then the final one is more interesting to people who are
###4416 doing functional testing.
###4418 Tap compare is the ability to do a dark traffic read or a
###4423 dark traffic write, like I just described, but compare
###4425 the results and make sure that the software you're about to
###4428 stand up actually sends the same content as the software
###4432 that you have in production today.
###4434 And with that said, I'm not going to talk anymore about
###4436 testing in production.
###4437 Well, I will, but only in a scary, inappropriate
###4442 way, but it's fun.
###4443 
###4445 So what did I do?
###4447 I joined, like I said, two years ago.
###4451 I was in the Performance Engineering Group at
###4453 Salesforce.
###4454 I came to Twitter specifically to try to solve this problem
###4457 as far as performance goes, and I wrote a load generator.
###4460 A load generator internally is called Parrot.
###4463 It turns out, though, that there are any number of
###4466 trademarks associated with Parrot, including most
###4469 unfortunately the Parrot VM that Perl
###4471 6 will run on someday.
###4473 
###4476 When we open sourced it, I couldn't call it Parrot, so
###4478 it's called Iago.
###4480 I actually had no idea that Iago was this bird that you
###4483 see up here.
###4484 I'm too old to have seen "Aladdin." I
###4488 crowd sourced the name.
###4489 I said I can't call it Parrot, guys.
###4490 What should I call it?
###4492 A bunch of people wrote back, and the one that got the most
###4495 votes was Iago.
###4495 I'm like, Shakespeare?
###4497 I don't get it, but OK.
###4499 Sure, it got a lot of votes, and then I found out it was
###4501 "Aladdin."
###4503 
###4505 So why did I need to write a load generator?
###4507 There are a lot of load generators out here.
###4508 I've used most of--
###4510 I'm not going to say all of them, but I've used a lot of
###4512 load generators in my lifetime.
###4514 I've used JMeter.
###4515 I've used LoadRunner.
###4516 I've used ab.
###4517 I've used Flood.
###4520 I'm not going to go through the full list, but I've used a
###4521 lot of them.
###4522 So why did I feel like I needed to
###4524 write a new load generator?
###4526 First of all, a lot of coded Twitter is written in Scala.
###4530 I wanted learn Scala.
###4531 I had written some toy projects in it.
###4534 And so I was like, hey, wait.
###4535 What's the best way to learn a language?
###4537 You write some piece of code that you already know how to
###4540 write in this new language.
###4541 That'll be great.
###4542 Sure, that's an awesome reason to invent a new load
###4544 generator, right?
###4547 Another reason is that, you know, do you ever get this
###4549 sort of thing like if I'm not actually doing engineering
###4552 that the other engineers won't respect me.
###4554 So it's like if I just bring in JMeter or I bring in
###4556 LoadRunner, and I start running load against their
###4558 system, I'm not going to get nearly as much credit or
###4561 respect in the organization as if I wrote my own, right?
###4564 [LAUGHTER]
###4564 JAMES WALDROP: So, yeah.
###4567 Another reason.
###4568 Hey, all those other load generators,
###4569 sorry, guys, you suck.
###4572 There's really no reason to use any of them.
###4576 They're all bad, clearly.
###4581 I hope the answer is obvious.
###4582 None of the above.
###4585 But when it comes to load generators, I have done this
###4591 three times before I got to Twitter,
###4593 and then did a fourth.
###4593 And I open sourced it, so hopefully I never
###4595 have to do it again.
###4597 But I really want load generation to be simple, and I
###4602 have a lot of experience when it's not
###4604 simple of what happens.
###4606 And what happens is that you end up with very large
###4609 performance engineering teams, and they're very
###4611 hard to hire onto.
###4612 It's a very specialized skill.
###4614 And so you're sitting there constantly trying to scramble
###4616 and figure out is it going to scale?
###4618 Is it going to scale?
###4619 And you don't have people to answer the question
###4620 why or if it will.
###4622 And you don't have enough people to answer the question
###4624 why won't it when it doesn't.
###4627 So if you're an engineer, as I've been, and you want to
###4631 answer this question, will my new service, new whatever,
###4635 feature, gizmo that I'm about to ship to production, is it
###4638 going to scale?
###4639 Can it handle a million QPS?
###4642 How do you go out and do that?
###4643 You sit down in front of your computer.
###4646 You're an engineer, and guess what?
###4648 You write a for loop.
###4650 Right?
###4651 So a for loop-- if anybody's not ever written one, I really
###4654 hope that all of you have--
###4656 sits there.
###4658 You write a for loop.
###4659 Let's see, I think I have a piece of it.
###4660 Yep, there we go.
###4662 So that's a for loop.
###4663 We're going to start up 100 threads, and we're going to
###4665 make requests as fast as we can against whatever service
###4669 it is that we have stood up.
###4670 And apologies, this was not code reviewed, so it may not
###4673 be actually compiling, but it's my sort of theoretical,
###4678 abstract for loop.
###4680 And any load generator that you're going to use had
###4684 probably better be able to be better than this.
###4687 If it's not better than this, then the engineer is just
###4689 going to sit down, and they're going to do it themselves,
###4691 because this takes five minutes to write, if that.
###4694 So that is if you're writing a load generator or you're in
###4699 that business, you had better outperform the for loop.
###4704 Unfortunately, though, at least if you're an engineer,
###4707 the for loop is really appealing.
###4709 And if you're, say, JMeter, and all of your configuration
###4715 is either via XML if you want to do it that way, which most
###4718 people don't, or it's a GUI that looks like it beamed in
###4721 from the late '80s, and if your load runner is a GUI that
###4727 happens to be really unstable and can't do automated testing
###4730 at all, or if you're ab, it's something that's completely
###4733 not configurable at all.
###4737 I'm sorry to bash on Jamie here.
###4739 I'm sure a lot of people here have used it.
###4741 It takes forever to actually write a load test in JMeter.
###4744 And if you want to do anything interesting at all, you're
###4746 going to be writing a plug-in.
###4747 And I have done that, and let me tell you, I do not wish it
###4750 on anybody.
###4751 And so it would be really nice if whatever this load
###4755 generator was was really easy to write new things in, it has
###4757 to be extensible.
###4759 A for loop actually satisfies all of those constraints.
###4764 But the for loop has a problem.
###4766 It turns out that it's actually quite wrong as far as
###4769 testing performance of your code.
###4772 It will give you nice, warm, fuzzy answers of I can handle
###4776 40,000 QPS.
###4777 Woo hoo, look at me and my product and my service.
###4779 It scales really well.
###4781 But it turns out that that has nothing to do with what's
###4783 actually going to happen to it when you get into production.
###4787 Why is that?
###4788 So let me talk about some systems theory.
###4790 Sorry to be academic for a second.
###4793 Does anybody here know Little's Law?
###4794 Raise your hand if you know Little's Law.
###4797 Awesome.
###4797 Nobody here knows Little's Law.
###4799 I'm glad I put this slide in.
###4801 Little's Law is a really awesome mathematical result in
###4804 queuing theory that says that if you have a service and
###4808 requests are arriving at a particular rate, the number of
###4811 concurrent users or concurrent requests that that service
###4814 will be able to handle can be found by saying what is the
###4817 request rate, and what is the latency or what is the time it
###4820 takes to service that particular request?
###4822 And that it might sound intuitive, and it is if you
###4826 think about it.
###4827 Like, hey, if I have 100 requests a second, and it
###4829 takes a second to satisfy that request, then I will have 100
###4834 requests concurrently, right?
###4835 It's simple math.
###4836 But it turns out that the math behind that is actually pretty
###4841 hard to derive, and it's awesome that it's such a
###4844 simple result.
###4846 But really, it's just math, so why do we care?
###4849 What does Little's Law have to with a for loop?
###4852 Well, if you are a performance engineer, you very much want
###4856 to change one thing at a time about your system so that you
###4859 can know for sure that the performance impact that you
###4863 are experiencing is because of that change.
###4866 Flaky tests were mentioned earlier.
###4868 Flaky tests are the bane of performance engineers because
###4870 you never get one answer.
###4871 You always get a range of answers whenever
###4873 you run these tests.
###4874 And so it's really important that you be able to change
###4877 something, try it again, change something, try it
###4879 again, and get results you can count on.
###4882 But Little's Law actually makes that very hard to do
###4886 that on a system which is specified in terms of
###4888 concurrent users.
###4890 So open versus closed systems.
###4893 
###4896 Basically, an open system--
###4899 and again, I'm not talking about open source, like APIs
###4905 or anything like, that this is systems theory--
###4907 an open system is a system where requests and arrive
###4909 independent of your ability to service them.
###4912 So in other words, an open systems is what you get when
###4914 you put your service on the internet where your users, as
###4918 much as you wish they would, do not care that you're slow
###4921 right now, or that there's a big spike, or the Michael
###4924 Jackson just died.
###4925 They're going to send you requests, whether that's
###4927 tweets or trying to retweet, regardless of your ability to
###4931 actually handled them.
###4932 A closed system is much nicer to model.
###4935 If you can imagine, probably the best example I can think
###4938 of is a call center where you sit there on the phone with
###4942 the poor person who's sitting in front of the computer.
###4944 There are only 500 agents, so that's the concurrency right
###4948 there, 500.
###4949 And they sit there and say, I'm sorry, the system
###4951 is slow right now.
###4952 I'm waiting for your data the load.
###4954 That's a closed system.
###4955 It's awesome because you can just say, all right, I need to
###4958 be able to send 500 threads.
###4959 JMeter can model that quite well.
###4960 But in a in the real world, we model things with
###4963 requests per second.
###4965 And that concurrency is equal to latency times request rate.
###4968 We need to model request rate, not concurrency.
###4971 
###4975 One more thing.
###4977 JMeter and almost every other load generator I've used by
###4980 default will speak HTTP, which is fine if
###4984 you have a web service.
###4985 Clearly, Twitter is a web service, so why isn't that
###4987 sufficient?
###4988 Well, it turns out that when you build a big
###4991 service-oriented architecture, you're probably not speaking
###4993 HTTP on the back end.
###4995 At Twitter, we're talking thrift.
###4997 Thrift is a wire format that is similar protobuf, which
###5000 many of you are probably familiar with if you're not
###5002 familiar with thrift.
###5004 And you have to be able to talk thrift if you're going to
###5007 be able to test systems in isolation, because like I
###5011 said, you can't stand up the whole service of Twitter, all
###5014 120 of them, and then send some HTTP requests in order to
###5017 make something happen way down 10 systems deep so that you
###5022 can find out whether or not you can handle the load.
###5025 So you need to really be able to test components, not just
###5027 the whole system.
###5030 Supporting thrift is really, really tricky.
###5033 It turns out that in thrift, you codegen your protocol, and
###5041 you typically do that at compile time.
###5043 So when you're building your system, you have bound it to a
###5046 particular RPC by the act of building it.
###5050 And that means, then, that all of your data objects are there
###5055 at compile time, and if your imagining a world like JMeter,
###5060 then it means that my load generator is suddenly going to
###5063 have to know not only your protocol, which is tricky in
###5067 and of itself, but also going to have to have all of your
###5070 codegen stuff.
###5071 Which means that if you think about it, there's 120 systems
###5074 at Twitter, so that means that now my load generator code is
###5078 dependent on all 120 thrift interfaces that they expose.
###5082 And I've open sourced it, so now it's dependent on anything
###5085 anybody can ever do, which is clearly impossible.
###5088 So I had to change the mental model of how this works in
###5093 order to satisfy that need to support thrift.
###5096 HTTP, you don't have any of those problems.
###5098 HTTP is a very well-defined protocol--
###5100 cookies, headers, post, different kinds of requests--
###5104 but very well-specified, and other than HTTP 2.0, nobody's
###5110 going to invent a new kind of HTTP that you need to support
###5114 in order to make your load generator work.
###5116 But thrift is a lot harder.
###5119 So I had to flip the model in terms of the load generator.
###5124 So in the JMeter and any other system-- you might use world--
###5128 the dependency is on the system.
###5131 Instead, I flipped that, and the dependency now goes from
###5135 the system to the load generation library.
###5138 And so when I got up here, I talked about the fact that
###5142 Iago is a library.
###5144 It's not a product per se.
###5147 It is a load generating library.
###5148 You depend on it just like you depend on any artifact, and
###5152 what it gives you is enough stuff that allows you to write
###5157 to an interface, which allows you to implement your
###5159 particular load test.
###5160 And I'll show you some examples here in a minute.
###5163 And you write to that interface.
###5164 And then you launch it, and it ships.
###5167 With that dependency comes enough--
###5171 like, jar, blah, blah, blah--
###5173 comes along and then allows you to launch it.
###5175 It comes with, effectively, an execution
###5177 environment along with it.
###5180 Secondly, so not only is Iago different in that it flips the
###5185 dependency model on its head, it also uses Finagle.
###5188 If anybody has used Finagle, then you're probably like yay,
###5191 cool, Finagle's awesome.
###5193 I'm assuming that's not most of you.
###5196 Finagle is a Scala library that we
###5198 use heavily at Twitter.
###5199 It's open sourced.
###5200 We wrote it.
###5201 And a lot of people are using it.
###5203 And it allows us to do asynchronous RPCs
###5207 over Thrift or HTTP.
###5208 Really, name your protocol.
###5210 MySQL was recently added.
###5211 And we have a Google Summer of Code-- shout out to the folks
###5214 who organized that--
###5215 Google Summer of Code project this year for adding Zookeeper
###5218 support, for instance.
###5219 So chances are that if it doesn't support what you need
###5223 to do it, it probably will be there or is easy to write.
###5228 Finagle, because it's asynchronous, solves our open
###5231 system versus closed system conundrum
###5232 that I described earlier.
###5234 
###5237 It's based on Netty, which in turn is based on Java NIO.
###5242 So if you have an asynch world like that, you can basically
###5244 say hey, I needed a request to arrive every millisecond.
###5247 Let's say that my arrival rate is 1,000 RPS.
###5251 So I need a request to arrive roughly, if I had a uniform
###5254 distribution, every millisecond.
###5257 OK, great.
###5257 I'm going to send a request every millisecond.
###5259 I'm not going to have a thread per request.
###5261 I'm not going to care how slow or fast your system is.
###5264 A request will be sent and will arrive every millisecond.
###5267 If your system is down, then I'm going to get
###5269 a connection refused.
###5270 If your system is up but slow, then there's going to be a
###5272 socket held open for certain amount of time.
###5274 But the resource constraints on my test system are not
###5277 going to interact with the resource constraints or the
###5280 problems that you might have on your service.
###5282 That kind of coupling is death to a performance test.
###5285 If you get your system under test coupled with your Load
###5289 Generator, then you've created a closed system, and you're no
###5292 longer modeling reality, at least modeling reality for
###5295 most of us here.
###5297 Clearly, I described a case where somebody could create a
###5301 closed system.
###5302 But for the most part, I believe everybody here
###5303 probably works at internet scale.
###5305 And therefore you are all needing a model open systems.
###5308 And so you need something where it's going to generate
###5311 those requests regardless of how slow or fast the service
###5314 is at this particular build.
###5315 
###5318 So that's all cool.
###5321 But what's it mean?
###5323 So I mentioned that I'm going to get some code.
###5325 I'm actually moving faster than I expected.
###5327 Maybe I should slow down.
###5329 So we'll have a lot of time to look at the code.
###5331 But there are some implications about this model
###5335 of hey, here's a library, you depend on it.
###5338 You write your load test using this library.
###5340 And then you just launch it, and it runs,
###5342 and it's all good.
###5344 For me, the most important thing--
###5348 I came from a team at my last company where, when I left, I
###5354 think there were 15 performance engineers.
###5357 And now I've heard over the last two years and change, the
###5361 team is now something like 50 performance engineers.
###5364 And their job is to write performance tests.
###5368 And that's what they do.
###5371 And as the engineering team grows there, they have to hire
###5375 more performance engineers in order to performance
###5378 test all the stuff.
###5380 I think that that model is very hard to make successful.
###5384 Especially when I started at Twitter, the company was quite
###5387 a bit smaller.
###5387 I think there were roughly 200 engineers at
###5391 Twitter when I started.
###5393 I wasn't going to be able to go and performance test every
###5396 single person's thing.
###5397 They were all moving really fast.
###5398 Way faster than I could move just by myself.
###5401 And I wasn't going to go out and hire another 19
###5404 performance engineers really quick and say, OK, great, now
###5408 we're going to be able to test your stuff.
###5410 And oh by the way, today we're something like 900 engineers,
###5412 which is the size of actually just Google's testing, but
###5415 never mind.
###5418 So now I would need 90 performance engineers, or
###5421 whatever the ratio is.
###5422 Let's say it's 5%, and I'd need 45 or so.
###5425 And you can project out to infinity and realize that, in
###5428 fact, this is probably not going to scale, because there
###5431 aren't that many performance engineers on the planet.
###5434 And so it's really important to me that if you're an
###5436 engineer and you're building a service, that you be able to
###5438 write your own performance test.
###5440 Not that you can go and learn JMeter or not that to force
###5443 you to go and, God forbid, and use LoadRunner.
###5446 But that you actually can just write some code, like you
###5448 would write your for loop, and write your
###5450 own performance test.
###5451 So that's a clear implication of this dependency model
###5454 switch is that you're no longer working in a world
###5457 where most of the domain expertise is something that's
###5461 unfamiliar to you.
###5462 You're working in a world where it's your service.
###5464 You probably already wrote a sample client when you wrote
###5467 your service, and you just use that same code to
###5469 generate the load test.
###5470 It's very simple.
###5471 Similar to how the for loop is very simple.
###5475 Like I've said, I've been at Twitter for two years.
###5477 I've written two load tests the entire time
###5479 that I was at Twitter.
###5480 I spent the first six months writing the Load Generator.
###5483 I wrote a couple sample load tests that were
###5484 actually never run.
###5485 People looked at it and said, oh, this is easy, I'll just do
###5488 this myself.
###5488 And I never actually ran those.
###5491 And there were two instances where I had to do a load test,
###5494 because they were testing some aspect of the system where
###5497 either in one case, no team existed that was maintaining
###5501 that system, and yet we were expecting to get a large burst
###5505 in traffic.
###5506 And in another case, it was crossing so many
###5509 organizational groups--
###5511 this was the most recent example.
###5512 I had to test for New Year's Eve.
###5515 And so I wrote that test of what happens when 30,000
###5518 Japanese people all tweet at midnight exactly.
###5522 It's the best distributed denial of service attack
###5524 you've ever seen.
###5525 [LAUGHTER]
###5526 And so those are the two load tests that I had to write.
###5530 I'm going to show you one of them.
###5531 I don't think I have time to show you both.
###5533 But I'll show you the most complicated one, so you get
###5536 some sense of exactly how hairy can it get.
###5539 And I'll talk about that in a second.
###5542 There are some unintentional things that happened as a
###5545 result of doing it in this way.
###5548 I mentioned that you have sample code already written.
###5550 It turns out that you actually have to write a lot less code.
###5554 When I write a JMeter plug-in, there is a ton of boilerplate
###5557 that I have to implement.
###5558 In other systems, I have to write a whole bunch of stuff
###5561 just to get it to do what I want.
###5564 Iago, the code you're writing is the code you already have.
###5568 So you probably are just copying and pasting it, in the
###5571 worst case, or pulling it in as a
###5573 dependency, in a better case.
###5576 And so you just don't have to write as much code.
###5578 It really takes people, literally--
###5580 you might think I'm exaggerating--
###5581 but it typically takes an engineer at Twitter who has
###5584 never been exposed to the Load Generator before and everybody
###5587 now at this point, I believe-- well, except the 50 or so we
###5591 hire every month--
###5592 will have been exposed to it.
###5595 But it takes them about 30 minutes typically from I don't
###5599 have anything, my manager just told me I should probably find
###5601 out if this is going to scale to all right, here I've got a
###5605 load test and I've run it, and I found out that, in fact, it
###5607 doesn't scale at all.
###5608 Oh shoot.
###5609 I have to go back to the drawing board.
###5611 Or better case, it's awesome.
###5614 It also has another really fascinating application that
###5619 I'm going to get to here in more detail in a second.
###5621 But Finagle makes it really easy for you to think in terms
###5626 of asynchronous operations.
###5629 It has this concept of the future.
###5631 Hopefully many of you are familiar with that from the
###5633 Java world.
###5635 The future signature in Scala is a little nicer and easier
###5637 to work with than it is in Java.
###5640 And it allows you to compose RPCs in a way that let's you
###5643 say things like, first, I need to authenticate this user.
###5647 Then I need to check and see if they have the right access.
###5650 Then I need to run this request against
###5652 this backend service.
###5653 And I'm going to scatter gather.
###5655 I'm going to run this request out to 100 different services.
###5658 And I'm going to compile the results.
###5659 And I'm going to throw away the ones that didn't come back
###5661 in a certain amount of time.
###5662 And then I'm going to collate that into a response that I
###5665 send to the user.
###5666 I can do all of that in about three lines of code.
###5668 So Finagle makes it really easy to compose really
###5672 complicated RPCs.
###5673 Using that in the Load Generator, in turn, means that
###5675 you can write really complicated load
###5676 tests really easily.
###5678 And I didn't expect that at all, because I had never been
###5680 exposed to Finagle.
###5681 And that was a really nice result.
###5684 The thing that that means is that, as you're going to see,
###5687 it means that you can write very complicated functional
###5691 test scenarios.
###5694 Before I had a tool like this, the way that I would do
###5696 performance testing and make sure that the service is
###5699 behaving correctly at the same time, let me describe a
###5701 scenario where this isn't done.
###5704 Let's say that you have a load test and you're running it and
###5706 your service is performing really well.
###5710 And then later, somebody has the bright idea to go and look
###5712 and see what's actually happening.
###5713 And what's happening is hey, it's amazing.
###5716 The performance is awesome.
###5718 It's really, really good.
###5719 It's serving a 404.
###5721 Or it's really, really good.
###5722 It's serving a 500, because there's an exception.
###5724 And it turns out that an HTTP 200 with a nice graphic, like
###5729 a fail whale, might, to your Load
###5731 Generator, look like success.
###5733 But in fact, the right thing isn't happening at all.
###5737 Well, how do you solve that problem.
###5738 Well, of course, then your Load Generator needs to
###5741 hopefully pay attention to more than just the response
###5744 code, but also you might think that--
###5746 this is the way I solved it in my last gig.
###5749 You run your load and you're running a
###5750 functional test beside it.
###5752 And you're like, OK, under this amount of load, these
###5754 scenarios still operate correctly.
###5758 And so here I've got JMeter, let's say, running against the
###5761 service, and I've got a Selenium test or a web driver
###5763 test running simultaneously.
###5766 And that's fine as far as it goes.
###5768 But wouldn't it be nice if you could actually say 100,000
###5772 users can all do this at the same time.
###5774 Where they can do these 50 different things
###5777 all at the same time.
###5778 
###5781 Honestly, I don't know of any way to do that other than this
###5784 Load Generator Iago.
###5785 
###5790 I didn't have to load test 100 services, so I had lot of time
###5793 to dedicate to making Iago great.
###5795 It's still not as great as it could be.
###5796 We are in the process of syncing out a bunch of stuff
###5799 to the open source repo--
###5801 bug fixes and such.
###5802 But if people are inspired by this talk, feel free to come
###5807 and make contributions.
###5809 Unintentionally, the idea of having a service which is
###5814 really solid became the model for how we do all of what I
###5819 call developer productivity.
###5821 Or probably a lot of you.
###5823 It's not a realization I had alone.
###5826 But we basically are focused--
###5827 I manage a team now focused on developer productivity.
###5830 And our build system works this way.
###5834 The test frameworks that we support works this way.
###5836 Our test infrastructure set up works this way.
###5839 Our deployment tool works this way.
###5842 And so it became a model for how things should work is that
###5846 give engineers great tools that are really easy to use,
###5849 where the default, it's almost easier to use
###5853 than to not use them.
###5855 And they will do the right thing.
###5857 And so that's how we're doing things at Twitter, which
###5859 hopefully is no surprise to anybody.
###5862 All right, now we get into the meat.
###5865 Hopefully you can all read that.
###5866 I actually don't care if you can't read that too much,
###5868 because it turns out that this is just an example of how to
###5872 write an echo service in Finagle using Thrift.
###5878 So you can imagine that you would have a service like.
###5881 It takes a method.
###5883 Or it has an RPC that says echo.
###5885 And then it's going to reply back with what you wrote.
###5888 I'm trying to be relatively open kimono here.
###5893 There's no hidden dependencies, other than on
###5897 Finagle and things like that.
###5898 But there's no hidden code here.
###5900 That's really how the service is written.
###5901 I cut it off at the end, because below that is all the
###5904 Zookeeper discovery business.
###5906 And I figured people don't care.
###5909 Here's a client.
###5912 I hope anybody who's writing a service is probably also
###5915 written a client for it.
###5916 If you haven't, then you should probably think about
###5918 doing that.
###5919 Because you learn a lot of interesting things when you
###5921 behave like your customer, whoever that is.
###5924 But here is a client that is going to
###5927 send the message hello.
###5929 And when it gets the response back, it's going to print
###5931 something out and say, all right, I got a hello back.
###5935 And that's how you write that code using Finagle talking to
###5939 my echo service.
###5940 And it's not a lot of code.
###5942 There's a lot of noise in there about types.
###5944 But other than that, it's pretty self explanatory.
###5947 And by the way, if anybody here doesn't know Scala and
###5948 you're totally confused, my apologies.
###5953 Here is a load test.
###5954 
###5957 Take a look at that for a second.
###5958 Notice that it's calling client.echo.
###5962 I'm going to go back, client.echo.
###5965 So if you see that, it's actually the same code.
###5969 And in fact, it turns out it's less code.
###5972 How's that possible?
###5973 How could it be less code?
###5974 Well, it turns out that Iago takes care of some of the
###5977 boilerplate as far as connecting to a service goes.
###5979 So this load test actually does a little more than the
###5984 sample client.
###5985 If it gets a hello back, then it sends another
###5987 message and logs it.
###5991 So that's a really simple example.
###5995 I'm going to get into a more complicated
###5996 example here in a second.
###5998 It turns out that if I wanted to write a for loop that just
###6001 sent echo requests asynchronously, as long as I
###6004 knew enough about Java NIO or Netty or some other library
###6007 like that, it would be really simple for me to do that
###6010 without too much effort.
###6014 So great, what have I gotten?
###6018 How can I do better?
###6020 So we have more complicated problems than that, it turns
###6023 out, at Twitter and hopefully most of you as well.
###6026 So load testing direct messages.
###6029 Direct messages are a feature in Twitter where you can send
###6031 a private message from one user to another as long as
###6034 there's a following relationship between them,
###6036 with some exceptions that I'm not going to go into related
###6039 to brands where you can direct message them without them
###6042 following you.
###6044 
###6048 I didn't put any of this in the slides, because I was
###6049 worried that comms would come after me.
###6052 So I will talk about this rather than--
###6055 I have to get slides approved.
###6058 So nothing I'm going to tell you is confidential, per se.
###6061 But at any rate, we had a TV show, one of these reality
###6065 game shows similar to, say, "American Idol" where people
###6071 are singing.
###6072 They get up on stage.
###6073 They sing.
###6073 You vote.
###6074 And then America picks the winner.
###6076 They go home with hopefully a nice recording contract that
###6079 doesn't take too much of their money.
###6081 And one of these such shows wanted to use Twitter to do
###6086 the voting.
###6087 And this show had a $5 million prize at the end.
###6090 And they were going to do the voting every single live show
###6093 over Twitter and include those votes along
###6095 with everything else.
###6096 But voting online has to be private, at least, without
###6102 some major exceptions.
###6104 And so they were going to use DMs.
###6105 And at the time--
###6108 in order to not get myself in trouble, I'm not talking about
###6110 when this was--
###6112 but at the time, we were getting roughly 400 DMs a
###6116 second over our system.
###6118 So 400 messages a second back and forth that
###6120 were of this type.
###6123 And when you figure out that most of the TV showing happens
###6126 in the East Coast and Central together, which is most of the
###6130 population of the United States, and that all of this
###6133 voting would be happening at the same time, because the
###6135 polls open, as it were, at the end of the show.
###6136 And so everybody immediately goes and they do their voting.
###6139 So you get a flood of traffic.
###6140 We figured out that we were going to have roughly on the
###6142 order of 2,000 to 3,000 DMs per second.
###6145 And as I said, the production traffic at the time was 400.
###6150 And so clearly, we were going to have a large increase over
###6153 what we could handle.
###6154 So we needed to be able to test that.
###6157 This is a Direct Message.
###6158 Again, I'm going to show some code.
###6159 And actually, I'm going to go a little quickly, because I
###6161 have about four minutes.
###6162 But I'm not going to go super quickly.
###6165 That's just an underlying type that would
###6170 hold the Direct Message.
###6172 Here is my processor.
###6173 You might actually be able to figure out from the code what
###6175 the TV show is.
###6178 So we're actually going to show five, I think,
###6183 slides of code here.
###6184 So don't get too attached to any one piece of it.
###6188 This is happening up in the constructor.
###6190 There is an eval.
###6192 And then we pull in a config.
###6194 And then there's a couple URLs.
###6196 This is using our API 1.0 endpoint instead of our API
###6198 1.1 endpoint.
###6199 This code was written long enough ago that there wasn't a
###6202 1.1 endpoint.
###6202 And by the way, none of it has been code reviewed.
###6204 So please, my apologies.
###6207 I know it's not the highest quality code.
###6209 I wrote it in, literally, like a day.
###6212 So there you go.
###6214 Here's some stuff.
###6215 It turns out that if you're going to have $5 million
###6217 riding on the votes, that you had better get them right.
###6221 You better not drop any votes on the floor.
###6223 You better not have votes show up for
###6226 people you didn't expect.
###6227 And so the voting, like in my load test, when I talk about
###6231 being able to test correctness and load at the same time,
###6233 turns out to be critical in this case.
###6235 Because I need to be able to make sure that of those 3,000
###6238 DMs per second or whatever the number is that I'm going to
###6240 test at, that all of them show up for the right guy or girl
###6244 or whoever it is.
###6246 And that like I said, none of them get dropped on the floor
###6248 or arrive--
###6249 well, out of order is fine in this case.
###6251 So I need to track a bunch of stuff.
###6256 It also turns out that I don't have another system like
###6261 Twitter that's not Twitter.
###6263 I don't have a copy of Twitter in my back pocket that I can
###6265 just stand up and run a bunch of tests against, because that
###6268 would be expensive.
###6270 And it probably wouldn't fit.
###6272 So I need to use Twitter in order to run this test, which
###6276 means I run the risk of knocking over production, as
###6278 it turns out.
###6279 But anyway, that was a known risk.
###6282 But it also turns out that I don't have millions of users
###6285 in my back pocket.
###6286 And I can't go create millions of users, because it with
###6288 throw off our analytics and our growth team would get
###6290 really excited.
###6291 And I would have to break the news to them that
###6292 that was just me.
###6293 [LAUGHTER]
###6296 And so I don't have a million users in my back pocket.
###6298 So I decided, you know what?
###6300 It doesn't matter.
###6301 I did a lot of talking to other engineers.
###6303 This is pretty shortly after I arrived at Twitter.
###6306 I didn't know much of the system at that point.
###6308 So I talked to a lot of people, and they said, no, it
###6310 probably doesn't matter.
###6311 You can probably send all these DMs from one account.
###6314 So I sent all the DMs from myself, literally.
###6317 I used my own account.
###6318 But it turns out that we have rate limiting at Twitter.
###6321 And so if I need to send 3,000 DMs a second, if any of you
###6324 want to do this, you're going to get stopped almost
###6326 immediately.
###6328 But it turns out that my Load Generator is running in
###6331 production.
###6331 And so it has access to memcache, which means it has
###6334 access to the rate limit.
###6336 It has access to my rate limit token.
###6338 And I can go and reset it as part of my load test.
###6342 So the load test is sitting there DMing.
###6344 And meanwhile, it's also talking to memcache
###6346 saying, that guy?
###6347 No, we're going to zero out his rate limit
###6349 again all the time.
###6351 Over and over and over again quite rapidly.
###6354 And I mentioned that I want to make sure we don't drop these
###6356 on the floor.
###6356 Our customer was using our streaming API, which
###6359 internally we call Hosebird.
###6361 And so I wanted to make sure that I was getting the same
###6364 data that they would be.
###6366 So I make a connection to Hosebird.
###6367 So there's my connection to memcache.
###6369 There's my connection to Hosebird.
###6371 I highlighted the connect to Hosebird code, because it's
###6374 not that interesting.
###6376 And then here's my load test.
###6378 So I need to pick a particular host to hit.
###6381 I need to decide what I'm going to send, so I have a
###6383 vote randomizer function that I'm going to call.
###6386 I need to set up the request.
###6388 I'm going to make a URI out of that.
###6390 I'm going to set the OAuth header with all the right
###6392 correct authentication codes.
###6394 And I'm going to make a Iago slash Parrot request with all
###6398 of those parameters.
###6399 And then I'm going to map that onto my request, call my
###6402 service, which is that second line up there.
###6405 And when the response comes back, I'm going to decode it
###6409 and check to make sure that I haven't exceeded my DM limits.
###6412 And if so, reset them.
###6414 And then I'm going to look and see if I got a decent response
###6418 back, meaning it's some HTTP response as opposed to an
###6421 exception that I got on the wire.
###6423 Then I'm going to read that DM, and I'm going to do some
###6425 check for missing DMs at the end.
###6428 It's very simple logic.
###6431 It turns out that this logic actually had a bug.
###6433 It's kind of funny, I think, anyway.
###6435 You'll see.
###6437 So the way I wrote it originally was all right, I'm
###6441 going to send a message.
###6443 And when you send a DM or anything on Twitter and when
###6447 you create something, you get back an ID.
###6448 So I'm going to get back the ID in the response, and I'm
###6450 going to be waiting over here for the stream to give me a DM
###6453 with that ID.
###6455 And I found out that we were dropping tons and tons of DMs
###6458 on the floor.
###6459 This is horrible.
###6460 It's not working at all.
###6461 What's the problem?
###6462 It turns out that Hosebird was delivering the DM before I
###6465 actually got the response back.
###6467 So our streaming API is fast enough that it will send the
###6470 DM down before you even know what the ID was.
###6473 And so I had to create DMs that have unique text in them
###6478 just so that I could match them up.
###6479 Because I was going to get them on the streaming side
###6481 before I got the response.
###6482 It's an awesome bug.
###6485 So that's all the code.
###6487 That's it.
###6488 That's how you test DMs.
###6490 So what do I want you to take away from this?
###6495 So clearly, most of you, some of you--
###6499 I don't know how many people from Google are here.
###6500 Google clearly deals in more scale than we do, as does
###6503 Facebook and a number of other sites.
###6504 But in general, most of the world doesn't handle the
###6508 amount of test load that we have at Twitter.
###6511 Just to give you an example, when I went into this, one of
###6516 the things that I wanted to be able to do was to be able to
###6518 generate a lot of load.
###6520 I had run into scalability problems with JMeter and
###6522 systems like where they have very simple request response
###6527 patterns, meaning give me a counter.
###6529 Great.
###6529 I got a counter back.
###6530 And you can be very fast at that.
###6532 And 40,000 QPS was a lot for JMeter to handle.
###6536 And I knew that Twitter handled more than that when I
###6540 came to the company.
###6541 So I wanted something that could scale really well.
###6542 And I had in my head that oh, 100,000 RPS would be cool.
###6546 That would be awesome.
###6547 And one day, somebody needed that much, and we were able to
###6550 do it, and it was no big deal.
###6551 And then somebody else came along and they
###6552 wanted 500,000 QPS.
###6554 And I was like, ooh, wow, that's a large number.
###6556 OK, let's see.
###6557 I had to tune a couple things.
###6559 And then we did that.
###6560 And then I haven't touched the code,
###6562 honestly, in like six months.
###6565 And a month ago, I was idly sitting lunchtime
###6569 conversation, and I hear behind me two
###6572 million QPS we tested.
###6573 And I turn around.
###6574 I'm like what?
###6575 Two million?
###6576 Who?
###6577 What?
###6578 Really?
###6579 I was like, you didn't do that with our stuff.
###6580 So how did you generate two million QPS?
###6582 That's awesome.
###6582 I want to know what did that.
###6584 Turns out you can generate two million QPS.
###6587 That is almost an afterthought versus everything else that
###6591 you get to do with this.
###6594 So pretty interesting as far as Twitter's problems go.
###6598 It turns out that you probably all should want your engineers
###6604 to be writing their own load tests
###6605 instead of doing it yourself.
###6607 And you should also clearly want your load test to be
###6610 accurate and model the real world.
###6612 
###6615 There you go.
###6615 I have all of one minute for questions.
###6619 And I'll be available for lunch.
###6622 [APPLAUSE]
###6629 TONY VOELLM: Great.
###6630 Thank you, James.
###6632 I got my takeaways again this time.
###6634 One is I learned you are a optimism and not a pessimist.
###6637 All your for loops had starts but no ends.
###6639 JAMES WALDROP: Yep.
###6640 Thanks.
###6640 [LAUGHTER]
###6642 TONY VOELLM: And I also learned I
###6643 have to go learn Scala.
###6644 And somehow, somebody slipped in like a next generation list
###6648 somewhere in the world.
###6649 And so Scala is it.
###6650 I also know Foursquare does Scala.
###6653 So it's growing in popularity.
###6655 We're going to take a break here in a minute.
###6656 I think we have time for one question if we want
###6659 to go to the mic's.
###6659 So if you have a question, go to the mic.
###6662 Otherwise, we'll take one off the Moderator.
###6665 Then we're going to take a break.
###6666 Then we're going come back here exactly at 11:30.
###6671 And we're going to go into the next set of presentations that
###6674 will be done by Mozilla.
###6677 And right before this question, two things.
###6680 Some people have been asking if the slides will be posted.
###6683 Yes, they will be posted.
###6685 And so will the video and the content and all these
###6688 questions and everything after the talks.
###6691 So they will definitely be out there.
###6693 And number two, there's a lot of people standing up in the
###6695 back of the room, just some to stretch your legs.
###6697 But there's also people that would like a seat.
###6699 So when you come back from the break, kind of squish into the
###6701 middle as much as you can.
###6703 So with that, we'll go to a question.
###6705 JAMES WALDROP: I like the top one.
###6706 TONY VOELLM: All right, so here's the first question.
###6708 It says, does Iago allow clients in languages other
###6713 than Scala?
###6714 In other words, can developers port their clients in other
###6717 languages to write performance tests?
###6719 JAMES WALDROP: Yeah.
###6720 Sorry.
###6721 Can you hear me?
###6723 So Scala is a JVM language, which means that those
###6727 libraries are available to any other JVM language, which
###6730 means that as long as you have code written for the JVM--
###6735 and that can include things like Jython or
###6736 JRuby for that matter.
###6738 So really, anything that you write on the Java stack for,
###6742 you can use Iago.
###6745 Cool.
###6746 Thanks.
###6746 TONY VOELLM: All right, with that, let's go ahead
###6747 and take our break.
###6748 And we will be back at 11:30.
###6751 [APPLAUSE]
###6753 [MUSIC PLAYING]
###8403 TONY VOELLM: Hello.
###8404 Hello, welcome back.
###8407 True to word, here, we're going to start.
###8410 As a reminder, please do squish in as you can to make
###8414 room for others.
###8414 So if you can sort of move to the center to leave that
###8418 space, that'll be great.
###8419 If you are interested in the topic tables, we're going to
###8422 be selecting the topic tables for lunch
###8424 here in a few minutes.
###8426 You can go to g.co/gtac2013 and you can find a link to the
###8431 moderator to go and figure out what topics you want to vote
###8435 up or vote down, or even suggest a new topic.
###8437 So pleased go do that right now if you can.
###8441 And up next here we have David Burns and Malini
###8448 from Mozilla here.
###8450 They're going to talk about how do you test a Mobile OS?
###8454 And a little fact about Malini here, she told me that her dog
###8458 is named after a test subject in Portal.
###8462 So you can always go ask her about this from that.
###8466 So with that, I'll let them kick it off.
###8468 Thank you.
###8470 MALINI DAS: Thank you.
###8472 [APPLAUSE]
###8477 MALINI DAS: So can you all hear me OK?
###8479 Yeah?
###8479 Awesome.
###8480 So I'm Malini Das and this is David Burns.
###8482 And we work on automation frameworks over at Mozilla.
###8486 And we're here today to give you a rundown of the recent
###8489 challenges that Mozilla has been facing while automating a
###8492 new Mobile OS.
###8494 So how do you test a Mobile OS?
###8496 That's the question that first came into our heads when we
###8498 were tasked with supporting this new platform.
###8502 And we knew that answering this question wasn't going to
###8504 be as easy as just googling for an answer or just winging
###8508 it as we went along.
###8509 There's a depth of problems that need solving.
###8512 And solving them in a good and long lasting way would save us
###8517 lots of pain in the future.
###8518 So today David and I are going to talk to you about how we
###8521 solved this complex problem and share with you the pain
###8525 points and the victories we had along the way.
###8528 So let's see here-- great.
###8531 So what Mobile OS am I talking about?
###8534 As some of you might know, Mozilla has been working on
###8536 something called Firefox OS.
###8538 And this is an open web accessible device that's built
###8543 on top of what we know best which is the browser.
###8545 So we're using Gecko, which is our web rendering engine, to
###8548 drive the phone itself, allowing all the applications
###8551 running on our phone to be written in CSS,
###8553 JavaScript, and HTML5.
###8556 So now you might be wondering why would we
###8558 want that in a phone.
###8560 Well, we've seen a recent trend towards web technologies
###8562 in the mobile environment.
###8565 So around 60% of the apps right now in Google Play and
###8567 the app store have at least one part of the app
###8570 that's a web view.
###8571 So what this means is that on top of your operating system
###8574 that needs to run your native applications, you also need to
###8577 have a web rendering engine just to show this web view.
###8580 And this trend towards web views isn't going to go away
###8582 any time soon.
###8583 We're seeing a prevalence of frameworks like PhoneGap which
###8587 allow you to write an application once using web
###8589 technologies and deploy to multiple mobile platforms
###8592 instantaneously.
###8593 So what's the problem here?
###8596 The problem is that these operating systems are doing
###8600 extra work.
###8601 So not only are they running the applications, but they
###8604 also need to run a web rendering engine just to show
###8607 you parts of this application.
###8609 So is there a way to remove this extra work?
###8612 That's the goal of Firefox OS.
###8613 What we want to do is unite the concerns of the OS and the
###8618 browser so your phone is doing less work.
###8621 And what we want to do is optimize it so well that we
###8624 can run on low end devices.
###8626 So we get this benefit that, by optimizing our browser, we
###8628 get to optimize our phone.
###8630 And by targeting low end devices, we get to put this
###8633 phone out to emerging markets and put it in hands of people
###8636 who may not have a smartphone before or may not have had
###8638 access to the internet before.
###8641 So what this means is we now have to make
###8643 our browser a phone.
###8646 And what do we need to do for that?
###8649 That means that our browser has to do things like send
###8652 SMSes and make phone calls.
###8653 And on top of that, it has to act like a browser.
###8655 So it has to render web pages.
###8658 And that gave us, the automation and tools team, the
###8660 task of figuring out how we can instrument and test all
###8662 these new features in this platform.
###8666 So what exactly should we test?
###8669 Since Firefox OS is essentially a flavor of
###8671 Firefox but on the phone, we want to test
###8674 all the same parts.
###8675 So this means that we want to test things like rendering.
###8678 Now, rendering essentially means how the web page looks
###8682 like once it's loaded.
###8684 And the way that we test it is that we let the web page load,
###8687 and we compare the data with either a reference image or
###8690 reference data to make sure that they match.
###8692 If they don't match, then we're not giving new mobile
###8695 users an experience of the mobile web that they deserve.
###8699 We don't want to regress in any way in rendering.
###8701 
###8703 Another shared concern that we have with browsers is that we
###8707 want to make sure that we have a performant phone.
###8709 So we need to check performance.
###8711 If our phone takes too long to execute anything, then no
###8714 one's going to want to use this phone.
###8717 So this means that we need to test performance for simple
###8720 things like loading applications.
###8722 But we also want to do stress tests, so that we can make
###8724 sure that we don't provide a degraded experience over time
###8728 or that we can catch memory leaks and all that fun stuff.
###8733 But now on top of these concerns that we have with our
###8736 browser, we have new concerns since we're a smartphone.
###8739 We now have to worry about application, unit and
###8741 integration tests.
###8743 So smartphones have a number of base applications, like the
###8747 calendar or the dialer.
###8749 And you want to make sure that these applications work before
###8751 you send out this phone to people.
###8753 So to do that, you want to answer questions like, does my
###8756 application work?
###8757 Do the functional parts of this application work?
###8759 Does this application work with the system app.
###8761 Does it work while other applications are running in
###8763 the background?
###8764 Now this is important for us so that we can test our own
###8768 base applications.
###8769 But we also want to give this test for a framework to third
###8773 party developers so that when they write their apps, they
###8775 can have the confidence that it'll work in this new
###8777 environment.
###8780 So Firefox OS is not just going to run on any desktop.
###8783 It's going to run on phones.
###8785 So now we have to worry about testing the
###8786 phone environment itself.
###8788 This means things like gathering hardware metrics.
###8791 So one of the hardware metrics that we want to gather is
###8795 things like boot time.
###8796 So how long it takes the phone from an off state to go into a
###8799 usable state.
###8801 I'm sure we'll had phones at some point where you could
###8803 press the button to turn it on, and it's just not
###8805 responding.
###8805 So you go and you make a coffee.
###8807 And you come back, and you still see a boot screen.
###8809 That behavior is not acceptable for new users.
###8812 It might be OK for early adopters types.
###8814 But we're going to be giving the phone to people who may
###8816 never have had a phone before.
###8817 And we want to give them a good optimized experience.
###8820 So as we develop this phone, we want to make sure that we
###8823 can gather data like boot time and make sure
###8825 that we don't regress.
###8827 Another important thing that we need to worry about now
###8829 that we're running on a phone is hardware metrics as the
###8832 phone is running.
###8833 So things like battery life.
###8835 Back when we all had feature phones, you could turn our
###8837 phone, on it would run for a week without having to
###8840 recharge it.
###8841 But now with our energy guzzling smartphones, we're
###8843 lucky to get two days off a single charge.
###8845 So we want to be able to make sure that as we progress with
###8849 our phone and as we build it out, we maintain a good
###8852 battery life and other hardware metrics like this.
###8856 Now one of our most important and interesting new test
###8859 concerns is telephony.
###8861 So the smartphone has to be able to do things like send a
###8863 text message and check your network provider and make an
###8867 actual phone call.
###8868 And if you can't do this reliably, then it's nothing
###8871 more than a frustrating portable computer.
###8873 So we're going have to figure out how we can actually solve
###8876 for testing telephony.
###8878 So now that we know what we want to test in general, how
###8883 do we go about doing that?
###8884 Do we have any tech lying around that can help us run
###8887 tests with these concerns?
###8889 Well, since Firefox OS is similar to Firefox, then we
###8894 can use the tests that we run against Firefox against it.
###8897 We have many existing frameworks for Firefox.
###8899 But none of them tackle all of the issues that we need to
###8902 tackle here.
###8903 We have things for rendering the performance, but we don't
###8905 have things for telephony.
###8906 We don't have a way of communicating to multiple
###8909 instances at the same time, because we never had to deal
###8912 with cross-device communication.
###8914 So what all this pointed out to was that we
###8916 needed a new framework.
###8917 And us being good engineers, we were wondering, wait.
###8921 We shouldn't just let this be a band-aid solution.
###8923 We have the opportunity to build a framework that can
###8926 answer questions not only for now, but can
###8928 build for the future.
###8929 So that any future framework that we build can leverage the
###8932 work that we're doing now.
###8934 So now that we figured out, OK, we need a new framework,
###8937 what exactly should it solve?
###8940 So this framework has to support our existing test
###8943 frameworks.
###8944 So Mozilla has hundreds of thousands of tests running
###8947 against Firefox.
###8948 And we want to be able to seamlessly run them against
###8951 Firefox OS.
###8952 It makes no sense to go off and make your own framework
###8954 and then rewrite all the tests.
###8956 That's just madness and unnecessary work.
###8959 So the ideal framework will be able to uplift all these
###8961 frameworks into Firefox OS.
###8964 The next requirement is that it should be the foundation
###8967 for future frameworks.
###8968 What this means is that to run any tests on the phone, we
###8973 need to be able to communicate with their own.
###8974 So the test runner has to talk to the test device.
###8977 And this is the core driving mechanism behind all of our
###8980 frameworks.
###8981 And any future framework will need to solve for this
###8983 communication.
###8984 So our framework should be able to provide this core
###8986 pipework that's reusable across
###8988 frameworks today and tomorrow.
###8990 And the last requirement is that it should be reusable for
###8993 any Gecko environment.
###8995 So what that means is that whatever we create today
###8997 should work on Firefox for Android, Firefox for desktop,
###9000 and Firefox OS and any Gecko product in the future.
###9004 This'll help us write one test framework once and then run
###9010 them in any other environment later.
###9013 So let's get to the gritty details of these requirements.
###9018 So in order to uplift some of our existing frameworks, what
###9020 do we need to do?
###9022 Well, our existing frameworks currently rely on Firefox
###9026 add-ons to run.
###9027 They use add-ons so that they have access to the privileged
###9032 space of your test environment.
###9035 So they execute code against the Chrome of the environment.
###9039 And this is fine for a desktop, because it has the
###9042 ability to run Firefox add-ons.
###9044 But in the beginning days of Firefox OS, we didn't have the
###9047 ability to run add-ons.
###9049 we.
###9049 First started thinking about test solutions about four
###9053 months after the project was announced.
###9054 So we had very little to work with.
###9056 We didn't know what direction the product will
###9058 eventually go in.
###9059 But all we knew is that we're going to be building this on
###9062 top of Gecko.
###9063 So while we didn't have the ability to easily uplift these
###9068 frameworks using add-ons, that means that we have to somehow
###9071 integrate our framework with Gecko itself.
###9074 This was actually an opportunity, because instead
###9076 of running as an add-on, we now get to integrate directly
###9078 into the engine, and we would get a performance boost.
###9081 So whatever we select as our framework, we had to make sure
###9085 that we integrate the key parts for every framework so
###9087 that they'll be uplifted easily without any problems.
###9092 Another consideration that we needed to take into account is
###9095 that we're running on phones.
###9097 And we don't want to assume that the phone will always be
###9099 connected to computer via a USB.
###9101 We want to stick them in data centers and somehow talk to
###9104 them over the network.
###9105 So whatever framework we have, we want it to be able to work
###9110 in a networked environment so that we can remotely
###9112 communicate with other devices.
###9116 And the last but extremely important consideration is
###9118 what can we actually open up on the phone?
###9121 So we don't want to just test web views.
###9123 We want to be able to test things like setting the
###9125 battery and check if the web view has actually received
###9127 this new information.
###9129 We want to be able to get as much control of the of device
###9132 as possible from the get go.
###9134 So what can we actually control.
###9137 So what this all boils down to is we need a reusable and easy
###9141 way to control different phones and to control multiple
###9144 devices at the same time.
###9146 And all of this should be done in an easy and reusable manner
###9150 across frameworks.
###9152 We want to drive the phone at all layers.
###9154 And we want to have privileges across the device.
###9156 So what that means is that I want to be able to change file
###9159 permissions, but I also want to be able to do things like
###9161 change app permissions.
###9164 So the solution that we came up with is a framework that we
###9166 called Marionette, which is essentially WebDriver meets
###9169 Firefox OS.
###9171 So why WebDriver?
###9174 Well, the phone itself is a web device.
###9177 So WebDriver was written so that you can manipulate user
###9181 views from a user perspective.
###9183 So you can test web pages in an easy and supported matter.
###9189 The great thing about WebDriver is that it's the
###9191 protocol behind Selenium.
###9192 So by implementing WebDriver, we get to uplift our existing
###9198 Selenium tests for free.
###9199 And it's something that's already familiar to testers.
###9202 On top of that, WebDriver is being proposed as the W3C
###9205 standard for browser automation.
###9207 So by implementing WebDriver, we essentially get to kill two
###9210 birds with one stone.
###9211 Because we can implement open web standards and also solve
###9215 our testing needs.
###9217 Another great thing about WebDriver is that it solves
###9220 our remote access problem for free.
###9223 It's already built in with the idea of local and remote ends.
###9226 So you can communicate and create a session, a WebDriver
###9229 session with one device, and then also have another session
###9232 with another device within the same test.
###9235 So this will allow us to do things like
###9236 cross-device telephony.
###9240 And the other consideration is how will this help us with our
###9245 uplifting frameworks problem?
###9247 Well, WebDriver has this extremely helpful method
###9249 called Execute Script.
###9251 And what Execute Script does is that-- yeah, you
###9254 know what it does.
###9255 It's totally hacky.
###9256 But it's awesome, because it works exactly
###9257 what we need to do.
###9258 What it does is that it lets you execute any arbitrary
###9261 JavaScript that you want in the current application space.
###9267 And that's exactly what Firefox add-ons
###9268 were trying to do.
###9269 We use them only to execute code on the device itself.
###9274 But as I mentioned before, we needed to execute code in
###9277 privileged space.
###9278 That is the Chrome.
###9279 And WebDriver only cares about content, so
###9282 what the user sees.
###9283 So what we ended up doing is we didn't end up making
###9287 WebDriver itself.
###9288 We ended up doing WebDriver plus plus.
###9290 So we added a few extra things to it.
###9293 So we needed to access privileged space.
###9296 So we added a new method called Set Context.
###9299 And what Set Context does is that it allows you to set the
###9302 current executing context of your Selenium commands.
###9306 So you can do things like, I'm going to set
###9308 the context to content.
###9309 I'm going to navigate to a web page.
###9311 I'm going to check what privileges this web page has.
###9314 Then I'm going to set the context to Chrome, change the
###9316 application permissions, and then go back into the content
###9319 and check if my application has actually respected these
###9323 permission changes.
###9325 So this helps us write extremely robust tests.
###9328 But it also helps us uplift these frameworks for free,
###9330 because now they can easily execute whatever JavaScript
###9334 they want against the Chrome.
###9337 Another key difference that our WebDriver implementation
###9341 has is that the current WebDriver implementation
###9344 doesn't have a full specked out area on gestures.
###9348 And we're a phone.
###9350 And we have touch screens.
###9351 So that means that we want to automate user input, which is
###9353 multi-finger gestures.
###9355 So just to get our own work off the ground, we started
###9358 working on the WebDriver specification for gestures.
###9361 And what this means is that we added a bunch of gesture
###9364 commands into our implementation.
###9368 But the general way that we solved it is that we added the
###9371 ability for you to create any gesture you want by using
###9375 chains of action primitives.
###9378 That is, I can change one finger to do press, move and
###9381 release, but the other finger can just press and release.
###9384 And then you can change these things together to create any
###9387 gesture you need.
###9389 And the third difference that this implementation of
###9392 WebDriver has to other ones in Firefox is that it's built
###9395 directly into Gecko.
###9397 And that gave us a huge performance boost, because
###9398 you're no longer running as some secondary concern.
###9402 You're a primary concern.
###9403 So to explain the gritty details of its implementation
###9406 is David Burns.
###9407 Here you go.
###9408 
###9414 DAVID BURNS: So how does it all work?
###9417 As Malini said, Marionette gets kicked off every time
###9420 Gecko starts up.
###9422 And so Gecko starts up every time the browser starts up.
###9425 And we have this really nice server sitting there waiting
###9428 for us to now accept commands and execute them.
###9433 And because it's essentially just executing JavaScript, and
###9438 large portions of Firefox is written in JavaScript, we can
###9444 now call pretty much anything.
###9445 We can go all the way, as Malini said, from the browser
###9449 Chrome, which is where all the nice security areas are, down
###9454 to the very insecure parts which is a web page.
###9458 And we can execute anything in between.
###9461 So now we're essentially starting to drive a phone, an
###9466 operating system, with WebDriver.
###9468 A standards-based automation API just driving
###9472 an operating system.
###9474 It pretty much doesn't get any cooler than that.
###9477 So I'm going to now split out into kind
###9480 of how we did things.
###9481 We've done a number of things slightly different to the way
###9483 the WebDriver project does things.
###9486 And it's mainly because it's what fits better with us.
###9491 So we essentially have a dummy clients, which just kind of
###9495 sends arbitrary commands over to the device.
###9500 The WebDriver project kind of does things with HTTP.
###9504 Its protocol is kind of RESTish.
###9508 It's not proper REST, but it's close enough.
###9511 And it delivers a nice JSON payload into a browser.
###9515 The browser then knows what to do with it.
###9517 
###9520 And because we're doing things with JSON packets and we're
###9525 doing wall sockets into the device, we only allow one
###9528 connection.
###9530 And the reason why we're doing it with pure TCP is because
###9534 we're trying to utilize some of the other technologies that
###9537 are going into Gecko at the moment,
###9538 like the remote debugger.
###9540 We're using a similar technology.
###9541 But I'll get back to that in the server parts.
###9545 So I'll kind of show you how, from a simple point of view,
###9550 I'm just going to use the terminal.
###9554 We can easily just kind of Telnet into the device.
###9559 I don't know if anyone can see that.
###9561 
###9567 I'll leave it on the screen for a while.
###9569 So we can easily Telnet in.
###9575 It shows kind of a nice echo response from a Telnet server.
###9581 Can we have the computer.
###9583 Ah, there we are.
###9585 So we get a nice echo response from a device.
###9592 The echo's just coming from the phone.
###9596 So we can see what it's doing.
###9598 
###9602 We can go back to the slides.
###9603 
###9611 So now we've got a nice mechanism into the phone.
###9614 
###9618 The server's kind of the really nice part.
###9621 It's the nuts and bolts that kind of drives Marionette and
###9625 kind of gives us all the in's into the device and into the
###9628 browser to be able to control it.
###9632 The mechanism we're using is what we've called the
###9635 JavaScript transport layer.
###9638 It's just kind of raw TCP into the browser.
###9643 But we now can send JSON payloads through it.
###9647 I just got a few little extra bits and pieces added to it,
###9650 which aren't too important at the moment.
###9653 But it gives us this mechanism.
###9656 It's being used at the moment by the remote debugger, which
###9659 is part of Firefox.
###9661 So like if you have an Android device with Firefox for
###9665 Android, you can kind of connect your phone to a host
###9670 computer and then debug from Firefox
###9673 straight on to the device.
###9674 It's the same technology as that.
###9676 We just kind of now are using it for automation.
###9678 We've created our own actor, because it's a actor
###9685 relationship in it.
###9687 And the actor then receives all the commands that are
###9690 coming through.
###9692 It kind of breaks down what's in the JSON payload and then
###9695 kind of decides where it needs to go.
###9700 Normally it goes through to a listener.
###9703 And a listener attaches itself to all the content that's
###9705 happening on the page.
###9707 So like if you have multiple frames, a listener gets
###9711 attached to each frame so that when we switch from frame to
###9714 frame, we just can carry on executing.
###9718 
###9722 So where are we using it?
###9725 We're currently using it on devices, emulators.
###9729 We've got a special build of Firefox for
###9733 desktop called B2G desktop.
###9736 It's kind of got a number of all the things that we need
###9740 for B2G, minus hardware things.
###9744 And we're using it on Firefox.
###9748 Marionette is now a tier one testing frameworks.
###9751 So that kind of means that withing Mozilla, if you push
###9755 something into our repository and it breaks a Marionette
###9758 test, it will be backed out, and you kind
###9760 of need to fix it.
###9763 This is kind of how we view our test things.
###9769 I know it's probably not going to be to viewable.
###9771 But kind of on the left is commits grouped by pushes into
###9778 a repository.
###9779 On the right, I've limited the UI to only show
###9782 the Marionette tests.
###9784 That shows all the Marionette tests.
###9786 So Marionette, and then hopefully by proxy, Selenium
###9789 is now part of the Mozilla kind of waterfall.
###9792 So every push that goes into Gecko now tests Marionette.
###9796 It tests like the core parts of Marionette.
###9799 And then goes off and tests all the different parts that
###9801 it needs to.
###9803 And then in the sense of what's to the left of the
###9806 Marionette part kind of shows all the different platforms
###9809 that we're running on.
###9810 So we've got Linux.
###9811 We got Windows.
###9812 We got mobile devices.
###9815 So we always know that
###9817 Marionette's going to be there.
###9819 And it's become so core to the way we do things.
###9822 
###9826 So how's it used?
###9828 It's being retrofitted into a number of our test feeds.
###9833 As Malini said, we've got hundreds of
###9834 thousands of tests.
###9835 And we need to test that things are working.
###9840 Because, essentially, Firefox OS is a browser on a device,
###9845 we need to make sure that how people manipulate the dom is
###9849 still working properly.
###9850 How people are rendering CSS is still working properly.
###9854 Our reference tests are kind of important.
###9858 And we need to make sure that JavaScript and all these other
###9861 little bits and pieces that are core to the way Firefox
###9865 works still works on the device.
###9867 Except we can't use the testing frameworks before.
###9870 We just need to kind of make sure the tests work.
###9872 
###9875 And we are also starting to go into
###9876 [INAUDIBLE], so telephony.
###9879 It's kind of important for a mobile operating system to be
###9883 able to make telephone calls.
###9885 Internet is all great and all that, but people like to use
###9888 phones to make phone calls for some silly reason.
###9891 
###9896 And then we've got this interesting part.
###9900 A mobile device has got multiple parts to it that we
###9905 need to make sure that we can access.
###9907 So the browser needs to access these.
###9910 And then from an automation and testing point of view, we
###9913 need to be able to instrument them and test them.
###9916 So there's different parts.
###9919 There's GPS.
###9920 There's Bluetooth.
###9920 There's USB.
###9923 There's all these different parts of the system-- cameras,
###9926 things like that.
###9927 And browsers needs to be able to speak to the hardware.
###9930 The hardware goes, well, here's all the
###9933 inputs that you want.
###9934 And then we go from there.
###9936 And we need to test all of this.
###9939 So I'm going to show you a quick test on the computer.
###9945 So it's going to run an emulator.
###9948 
###9952 Emulators, just by nature, are kind of slow.
###9955 What this is going to do is this is going to run a
###9957 geolocation test.
###9959 It's starts with the emulator.
###9961 It's going to set a number of different bits of information
###9964 in the background to the emulator, then check it.
###9966 
###9970 Make sure your emulator style-- it's very slow.
###9972 
###9977 Runs everything.
###9980 Hooray, and all our tests pass.
###9983 But you can see it sets information, and then it's
###9986 retrieved information, checked everything's working.
###9990 Back to slides please.
###9991 
###9997 And then we also need to make sure that the UI is working.
###10002 People need to make sure that they've got a functioning
###10007 device that if they go to make a phone call, if they go to
###10011 set an alarm, they go to do all these things, those key
###10015 parts of the system are working as they expect.
###10018 They're working in a certain manner.
###10022 But it's not just making sure that Mozilla can make sure
###10027 that the UI's working properly.
###10030 OEMs who make the devices and are going to be flashing them,
###10034 they're kind of stripped on making sure that things work.
###10037 Because it's kind of their name that's on the hardware
###10041 when it goes out to people.
###10042 So they want it to be of a certain quality.
###10047 And for those who've worked with iOS and with Android and
###10052 have tried to automate the UI and then kind of gone gray or
###10056 gone bald, because you pulled your hair out, we need to make
###10060 sure that we give third party developers who want to make
###10063 apps a nice way to automate the UI, if they need to.
###10067 Or if they just need to execute different bits of code
###10071 as they see fit, we give them that.
###10074 Because if you give them a nice testing infrastructure,
###10078 you have a nice ecosystem that third party
###10082 people want to come.
###10082 People want to build apps because they can prove that
###10085 there app is of a high quality.
###10088 So I'm going to kind of show you a test
###10091 running on a device.
###10092 
###10094 If we can put it on this, please.
###10096 
###10101 This is where I hope it works.
###10102 
###10105 If it works, that'll be fine.
###10107 
###10124 The demigods have struck.
###10125 MALINI DAS: There we go.
###10126 DAVID BURNS: No, that's me.
###10128 
###10132 Let me show you how quickly the phone resets.
###10136 [LAUGHTER]
###10138 
###10156 DAVID BURNS: While that loads, I'll get everything ready.
###10163 
###10166 Sorry for the technical delay.
###10168 
###10177 All right, take two.
###10181 Uh oh.
###10182 
###10186 Come on.
###10188 
###10191 OK.
###10192 
###10198 Oh, that's why.
###10200 
###10209 That look like it?
###10210 
###10215 Maybe not.
###10216 Oh, yes.
###10217 All right.
###10218 So we try and reset the phone between tests where possible,
###10224 because some parts we can't kind of clear out.
###10228 So what it's doing is it's just going to set an alarm a
###10233 few times and then make sure everything's working.
###10237 
###10240 And I've broken it?
###10242 
###10248 Yeah, this was working earlier.
###10250 Oh well.
###10250 [LAUGHTER]
###10250 MALINI DAS: I swear it totally was working earlier, right
###10253 before the talk.
###10253 DAVID BURNS: Yeah, OK, we'll just kind of skip the
###10256 technical difficulties, and we'll go back to slides.
###10259 
###10262 So where we've been.
###10265 A lot of our testing infrastructure we kind of had
###10267 to be building on the fly as well.
###10269 
###10273 Because as Malini said, we kind of were late to the game.
###10276 We were invited late to the game.
###10278 But we've had to play catch up very quickly.
###10281 So we had done Jenkins just running in the cloud, running
###10286 our unit tests, our web API tests.
###10288 So kind of this hardware part tests.
###10291 And then we were running then against emulators.
###10294 Luckily, when were at this stage, we didn't have hundreds
###10298 of engineers working on Firefox OS.
###10301 But then things changed.
###10302 And we started getting more engineers than we needed.
###10305 And more of the system started being built.
###10307 And we needed to start running our unit tests, our web API
###10312 tests and UI tests.
###10314 Because we need to make sure that all the
###10316 functionality is working.
###10318 [INAUDIBLE], which is the code name for the UI needs to be
###10323 working at a certain level.
###10325 And we're running these on emulators and we're running
###10328 them on PandaBoards.
###10330 For those that don't know, a PandaBoard is just a Android
###10333 development board.
###10334 It allows us to do some neat things.
###10337 It's essentially just a Nexus S without a screen, and kind
###10341 of looks like a [INAUDIBLE]
###10342 or raspberry pie.
###10345 And then we went from there and we started actually also
###10348 testing on real devices.
###10350 So we've got some devices that our OEM said was going to be
###10355 over some ilk, and we started testing against those.
###10359 And soon we're going to be testing against the devices
###10362 that we're gonna also be sending out to the public.
###10364 
###10367 This is what a rack of PandaBoards looks like.
###10374 There's a number in there--
###10377 this is a unit that was designed by our IT
###10379 department--
###10381 and it's a number of PandaBoards.
###10384 They've all got ethernet, they've all got power.
###10387 And what happens is, whenever a test is ready,
###10391 we flash the device.
###10394 It's got an SD card on it that we can change, because SD
###10397 cards only have a certain lifespan.
###10400 We can swap out.
###10402 It flashes the SD card, then we run our tests and we go
###10406 from there.
###10407 One of the things mentioned earlier is that we also suffer
###10411 greatly from flaky tests.
###10414 Mobile is one of those places where you're going to get a
###10417 lot of flaky tests.
###10418 And a lot of it also comes down to hardware.
###10421 So one of the nice things about the Panda set up is
###10425 we've got a framework called Mozpool and in our pool we've
###10431 got lifeguards who check how things are going.
###10434 If they notice that a certain board has an increase in
###10437 failures, it starts taking that board out of commission,
###10440 kind of let someone know.
###10442 And then we can just hot-swap the device.
###10446 Because this is just in a data center, so our IT department
###10448 can go there, swap it out and carry on.
###10450 
###10456 The other part of our test infrastructure is making sure
###10458 that we can do stress tests against the device.
###10462 
###10464 Just running and running and running and running tests,
###10467 because people don't really switch off
###10469 their phones nowadays.
###10471 They go to bed with them on, wake up
###10473 and it's still running.
###10475 And that's the major use case that people are going to be
###10479 using and we need to make sure that the device doesn't become
###10482 sluggish over time, it doesn't crash all the
###10484 time, things like that.
###10485 We need to do all these really weird and
###10489 wonderful stress tests.
###10491 We started doing fuzzing over it with a tool called
###10495 Orangutan--
###10496 which was written by Will who's in our team--
###10500 which just does gestures on the device at a very low level
###10503 and then sees what survives.
###10505 
###10508 And we've started doing performance
###10510 test against devices.
###10512 One of the important things that people wanted to be able
###10514 to do is play games.
###10516 Most people play games on smart phones these days.
###10519 So we want to make sure that if you're playing a game, that
###10523 you're getting a high enough frame rate.
###10526 We want to aim for that 60 frames a second so we can make
###10530 sure that it is not jerky, it's not anything like that.
###10534 There's no jank, which is where you try scrolling, it
###10538 stops for a bit and carries on scrolling.
###10540 We want to make sure that those things aren't there.
###10543 And these types of tests mean that we can make sure that
###10548 when we deliver this device to people, to OEMs, and when
###10552 third party people want to start using it, they have
###10556 their confidence in what we've done.
###10559 
###10564 And that's it really.
###10566 It's been a huge learning experience for our team.
###10571 We've learned some number of weird and wonderful things
###10573 along the way, and we've tried to solve a number of problems.
###10576 And hopefully we've shared it up with you all.
###10579 Thanks.
###10579 TONY VOELLM: Great.
###10580 Great, thank you David and Malini.
###10582 [APPLAUSE]
###10587 TONY VOELLM: That was fantastic.
###10589 Actually I really loved that last picture
###10590 there with the racks.
###10592 I also learned the danger of calling APIs rest APIs,
###10595 because sometimes your devices just take a rest.
###10599 [LAUGHTER]
###10601 TONY VOELLM: So with that, if you would like to ask a
###10603 question, there's a mic in the back there
###10605 and a mic over there.
###10606 Feel free to grab the mic if you want to ask a question.
###10609 And in the meantime, we'll grab one off of
###10612 the moderator here.
###10614 So first question up.
###10616 How do you automate recovery for devices that fall off USB
###10621 or get wedged outright during testing?
###10624 MALINI DAS: Do you want to take it?
###10626 OK, well it depends on the device.
###10626 So we have the PandaBoards which you can power cycle.
###10630 And we don't use USB for them, we
###10632 communicate over the network.
###10634 Wedge outright during testing?
###10636 I don't really understand what that means,
###10637 but perhaps you do.
###10638 [LAUGHS]
###10639 But for other devices, we have to power cycle them.
###10643 We have some tests run directly against our phones,
###10648 and we have to currently manually reboot them.
###10651 But we have someone working on a solution for that right now,
###10654 because manually rebooting them is just not
###10657 sustainable at all.
###10658 DAVID BURNS: Yeah, we ask our manager to go-- because we've
###10661 got a big Faraday cage in our Mountain View office-- and
###10664 every so often we just ask our manager to go work in there
###10667 for the day and just power cycle whenever we need them.
###10669 MALINI DAS: Yeah, so that'll be solved.
###10672 TONY VOELLM: You've found a use for your manager.
###10673 Perfect.
###10674 All right.
###10674 Looks like we had some questions.
###10676 I think you were up first, so ask away.
###10678 AUDIENCE: Sure.
###10680 You touched on UI performance testing at the end there.
###10683 But what tools do you use to actually validate the UI
###10687 performance?
###10688 Do you have some kind of video recording or people who are
###10690 watching it?
###10690 MALINI DAS: Yeah.
###10691 So we have this tool called Eideticker, and what that does
###10694 is that it's just a camera that's focused on the screen.
###10698 And it captures it and checks that the data is moving
###10702 actually at 60 frames per second.
###10704 So we have two ways of capturing that video data.
###10708 One is to plug it in a video out cable directly to the
###10713 phone and send it directly to our computer and analyze HTMI
###10716 output directly.
###10718 And the other way-- which is what we're experimenting with
###10720 right now-- is with high speed cameras.
###10722 And we're just making sure that each of the frames are
###10725 changing at the rate at which we expect.
###10726 AUDIENCE: Cool, thanks.
###10728 TONY VOELLM: So following to that, so as you're sort of
###10731 swiping or moving, one thing is the frame rate, but how do
###10735 you actually know the animation is happening?
###10739 DAVID BURNS: I don't know about the animation.
###10741 But when it comes to swiping, one of the key things that
###10744 brought us to doing this type of testing was when we rewrote
###10748 a lot of the Firefox for Android stuff, when you
###10751 scrolled, we were getting a lot of checkerboarding
###10752 happening, because the drawing wasn't happening fast enough.
###10759 So we created a framework.
###10761 Well, I say we.
###10762 Will Lachance, he's on our team, he created a framework
###10766 called Eideticker, and that just watches for these
###10771 checkerboarding and then works through that.
###10775 He created Orangutan, which instruments Android and tells
###10779 it how to scroll and things like that.
###10781 So it's allowed us to test against other browsers so we
###10785 could see how well we checkerboarded.
###10787 Well, we don't want to checkerboard, but how other
###10790 browsers were handling the same website.
###10792 TONY VOELLM: Great.
###10794 Second up?
###10794 I think you were up.
###10796 And if you want, you can say your name and where you're
###10798 from and then ask your question.
###10799 If you just want to ask, that's fine too.
###10800 AUDIENCE: Hi, I'm Daniel from SNAP Interactive, and my
###10803 question goes to security.
###10807 Obviously, Marionette is a really great thing that allows
###10809 you to drive everything about the phone.
###10811 But what if someone were able to get access to that and do
###10815 those kinds of things to your phone that you don't
###10817 want them to do?
###10818 How do you prevent something like that from happening?
###10820 DAVID BURNS: At the moment, Marionette is only available
###10824 in engineering builds.
###10825 So you have to build it into Firefox OS.
###10831 We're working with our security team to work out a
###10836 nice way for developers to be able to have Marionette.
###10839 So you just go in, buy a phone from your local phone company,
###10844 and then start working with it.
###10848 Because yes, security is one of our biggest concerns.
###10852 Privacy as well, because people might be doing internet
###10856 banking on things like this, and we want to make sure that
###10859 they feel secure that they can do all these things.
###10862 But also that if a developer goes and buys it, they can
###10865 start working with it.
###10866 So we've got a number of ideas, especially for desktop,
###10871 how to sort the desktop problem.
###10873 The mobile problem at the moment, it's just don't put
###10875 Marionette on there.
###10876 And then, as and when we can solve that problem, it'll
###10880 start slowly being put back in.
###10882 AUDIENCE: Thank you.
###10883 TONY VOELLM: Great, thank you.
###10885 And another question over here please.
###10887 AUDIENCE: Yeah, hi.
###10888 I'm Jonathan from Salsa Labs.
###10889 And if I recall correctly, you guys said that you in your
###10895 WebDriver Plus protocol, you speak JSON over
###10898 TCP, rather than HTTP.
###10901 So I'm wondering whether I, as a potential Firefox OS app
###10906 developer, can use standard Selenium client libraries that
###10910 already exist to speak to Marionette or whether I have
###10912 to base it off of something you guys have written?
###10914 DAVID BURNS: So our Marionette client library is 90% the same
###10921 as the Selenium library.
###10922 
###10925 Ideally when we get to a certain place, what's going to
###10928 happen is WebDriver's got an idea of the commands that it's
###10933 got and then it's got a command executor.
###10935 And what we want to try to do is just switch in the command
###10938 executor for Firefox only and then it just knows to speak
###10941 through that and then works.
###10943 AUDIENCE: Thanks.
###10944 AUDIENCE: [INAUDIBLE]
###10947 HTTP and JSON [INAUDIBLE]?
###10949 DAVID BURNS: And the spec also says that we have to do HTTP.
###10955 We've already got a shim that people can use, but my gut
###10959 feeling is that the Selenium project is probably going to
###10962 be using straight into it, and then if you're not one of the
###10967 languages that the Selenium project manages itself, you'll
###10971 probably go through the shim.
###10972 So we're still going to have that and it just essentially
###10976 takes the HTTP, maps it down to a RTCP connection and goes
###10979 from there.
###10981 TONY VOELLM: So let me take a question from the moderator so
###10983 those that are watching live and remotely also get to ask
###10986 some questions here.
###10988 
###10990 I can throw this one over to Malini, I guess.
###10992 Do you prefer to run your automated tests on real
###10997 devices or emulators?
###10998 MALINI DAS: Well ideally, we'd like to run
###11001 devices all the time.
###11001 But we haven't solved the infrastructure problem of how
###11004 do we power cycle these devices?
###11006 And devices are very finicky.
###11008 Emulators have been incredibly reliable as a way of testing.
###11011 So we've been running all of our tests.
###11013 Any time you commit code to Mozilla, we run our tests
###11016 against emulators just because they're easy to put up in VMs.
###11020 It's a very easy platform for us to use.
###11022 And it's actually fairly representative of the
###11025 environment that you're running in.
###11026 So for most cases, emulators do just fine, but we do want
###11029 to build out more device testing.
###11032 TONY VOELLM: OK, and last question.
###11034 And then I'll do some announcements
###11036 right after this question.
###11036 So please, from the audience again.
###11038 AUDIENCE: This is Quam.
###11039 I'm from Android Test Engineering.
###11041 So from a mobile OS testing perspective, I think there's a
###11046 lot of stack between what you're offering to the app
###11049 developer down to maybe the kernel or the driver level.
###11054 How do you solve the problem of poking layers in between?
###11058 Because from the presentation, a lot of the cases I've seen
###11063 are mostly integration level or functional testing.
###11068 How do you poke levels in between?
###11070 And also, in related to the question you just answered,
###11076 there are device specific characteristics or [INAUDIBLE]
###11081 or problems.
###11082 When you test mostly on emulator, how do
###11085 you solve the problem?
###11086 
###11089 MALINI DAS: For the first question, would you
###11091 like to take that?
###11092 I'll take the emulator one.
###11092 DAVID BURNS: OK.
###11093 So for the first one, one of things Malini mentioned during
###11097 the talk was that we can set context and we can switch
###11100 between different contexts within the browser.
###11103 So 90% of the time, what app developers
###11107 are going to be using--
###11107 well, actually probably app developers are
###11110 going to use it 99.9%.
###11112 They're going to be running everything in the content
###11114 layer, which is just your average web page.
###11118 For what we're doing, we have frameworks like what we call
###11123 [INAUDIBLE]
###11123 Test and things like that.
###11125 And what that does is that will speak through JavaScript
###11130 into the Chrome layer and then the best use case I can think
###11136 of as to how we test the dom.
###11138 A lot of the dom stuff will be happening and that will be
###11140 happening in privileged space, kind of then pushes out to the
###11143 content space.
###11144 And we need to make sure that when it manipulates it in a
###11147 certain way, that we can then instrument it that way.
###11150 So we can sit in the dom like in the Chrome space, the
###11154 browser Chrome, and then just see what it's doing, ask it
###11158 questions, and then get information back.
###11161 We have--
###11161 TONY VOELLM: And with that, Malini, you have 10 seconds,
###11164 and then you two can chat at lunch.
###11166 DAVID BURNS: Yeah.
###11167 TONY VOELLM: So you get 10 seonds.
###11168 MALINI DAS: Sure.
###11168 So for device specific flakiness, on the emulator we
###11172 are able to distribute to other people in our community
###11176 so that they can use it and test and make sure that it
###11179 works in this environment.
###11180 If it fails, then it's really up to them to
###11183 fix those flaky problems.
###11184 But when it comes to device specific problems, you have to
###11187 have the device on hand to fix, to
###11190 resolve these flaky issues.
###11192 And that's another problem.
###11193 But that's why we rely on emulators so heavily as well.
###11195 TONY VOELLM: All right, thank you.
###11197 So we're going to break for lunch here.
###11199 I have two quick announcements.
###11201 If you wanted to do the topic tables, they're going to be
###11203 out in the lobby.
###11204 We have these conference rooms, by the way, the whole
###11206 conference.
###11206 There's four of them out there.
###11208 If during any of the other sessions you need to take a
###11210 break, you need to get some work done, you're free to sit
###11213 in the four conference rooms that are out there.
###11216 Right now though, they have some signs posted outside as
###11218 to what the topics are for each room.
###11220 So you can grab food and then figure out the topic.
###11224 If you have any dietary restrictions, you need a
###11227 kosher meal, something without dairy, or something like that,
###11230 the people from our great food service are here in the back.
###11235 And you can just ask one of them to help you out and
###11236 they'll get you a special meal.
###11238 And with that, we're going to break until 1:15.
###11242 Lunch is from 12:15 to 1:00.
###11244 And then we're going to come back right at 1:15, so please
###11247 in your seat by that time to hear the next talk from
###11251 Expedia on mobile automation in
###11253 continuous delivery pipelines.
###11255 With that, thank you and have a great break.
###11258 [APPLAUSE]
###11263 [MUSIC PLAYING]
###14659 TONY VOELLM: Hello.
###14659 Welcome back.
###14662 This is always one of the toughest talks of the day.
###14665 It's right after lunch.
###14667 You're going to be a little sleepy.
###14670 We could try some things.
###14671 We could maybe have this elevator go up or down.
###14673 Maybe you'll wake up.
###14674 Truck could drive out here.
###14677 If everybody could squish to the middle again just to leave
###14681 these easy access seats for people to go and sit down.
###14686 And then if you need the caffeine, it's still in the
###14689 back there so coffee, juice, soda, you can also just run
###14693 laps back there if you need to.
###14694 With that, I'm going to go ahead and kick
###14696 off the next talk.
###14698 We're going to do a couple things in the afternoon here.
###14700 So we have two full length talks here.
###14704 Actually we have three full length talks, and we're going
###14707 to have a series of lightning talks.
###14708 And the lightning talks are really
###14710 going to be like lightning.
###14710 They're going to be very fast.
###14713 And there's going to be five in a row.
###14716 So with that, I'm going to go ahead and kick off
###14718 the next talk here.
###14719 It is going to be Igor Dorovskikh and Kaustubh
###14723 Gawande are going to go and talk to us from Expedia about
###14728 mobile automation and the continuous delivery pipeline.
###14732 And so with that, Welcome up, guys.
###14736 IGOR DOROVSKIKH: Thank you.
###14737 
###14741 KAUSTUBH GAWANDE: Just to introduce ourselves, I'm Igor
###14743 and he's Kaustubh.
###14744 Oh, sorry I got that messed up.
###14746 I'm just checking if you guys are awake or already asleep
###14749 after lunch.
###14749 OK.
###14750 Good.
###14752 So let's jump right into it.
###14756 Before we get started, I joined Expedia in 2004.
###14759 And how many of you have been in a situation where the
###14766 number of automated tasks is zero?
###14769 
###14773 How many of you have had your business or the product team
###14776 say you engineering team, you just cannot ship fast enough.
###14780 You just cannot go quickly enough.
###14782 How many?
###14784 OK, not bad.
###14786 OK, all right.
###14787 So what I'm here to talk about is I heard the same thing for
###14791 many, many years.
###14792 And we're going to talk about some of the things we have
###14795 done the last couple of videos to try and address both of
###14798 those situations.
###14800 So if you're in that situation, stay awake.
###14802 It will help.
###14803 
###14806 let's get right into it.
###14808 Here's a graph of what Expedia has done over
###14812 the last few years.
###14814 So the blue bar is the number of hot fixes we
###14816 used to ship 2005.
###14818 And the green bar is the number of
###14820 releases we used to ship.
###14823 And the number of the red is the number of what we called
###14826 business AB tests, where a business can try different
###14828 functionality on the site and let the customers decide
###14831 what's right for them.
###14833 So in the web world, that's where everything is going.
###14836 You ship fast, you try different things, you let the
###14838 customers decide.
###14839 Don't assume you know what they want or what they like.
###14842 And the last is my favorite.
###14843 The part where Expedia stock rises up twice.
###14847 I wish the stock rises up 20 times versus the releases were
###14852 up only two times but unfortunately that's going to
###14853 have to wait for awhile.
###14856 So this is the best [INAUDIBLE] work on continuous
###14859 delivery can do for you.
###14861 it can help you ship faster, more releases, and ultimately
###14865 make you rich.
###14868 So what does that tend to look like?
###14870 I'm going to talk about test automation some basics.
###14873 because we have a wide variety of audience here and online
###14876 and so I want to make sure we talk of the basics.
###14879 We'll show you what the continuous delivery pipeline
###14881 of tests looks like for Expedia
###14883 specifically for our team.
###14884 We work on the Expedia front end site so everything you see
###14888 on expedia.com or one of the Expedia sites, it's our team
###14891 that's shipping that, including mobile.
###14893 We do mobile web, mobile apps.
###14896 And so we'll talk about little bit of the test methodology
###14899 and some of the unique things we have done in
###14901 the last few years.
###14904 and then Igor's going to talk about the
###14905 specific tools we use.
###14907 Almost everything we use is open source,
###14910 so it's very cheap.
###14913 Free.
###14914 And then we'll talk about the key benefits that we have
###14917 gotten as a test organization.
###14918 So specifics on what benefits I have
###14920 constantly seen and measured.
###14923 So there's a lot of talk in the industry about agile.
###14926 Continuous integration.
###14928 Continuous delivery.
###14929 Mostly [INAUDIBLE]
###14930 are falling.
###14931 There's a lot of talk DevOps.
###14932 There's a whole DevOps movement going on.
###14934 So this is the best slide I've found to explain what
###14937 continuous delivery really means.
###14939 
###14942 In 2006, Expedia was agile, but we didn't really have a
###14945 continuous integration system in place.
###14947 Well, then we fixed that.
###14948 2006 to 2009, we had continuous integration in
###14951 place, didn't really have continuous delivery in place.
###14954 So it's been a progression.
###14956 The last few years, we've been focused on the continuous
###14959 delivery piece.
###14960 And my talk is going to be focused on the--
###14963 and Igor's going to cover the automation tools we're using--
###14968 the test automation piece of continuous delivery.
###14970 
###14974 So basics.
###14977 Most people know what a test automation pyramid is.
###14979 What I'm here to tell you is just one simple thing.
###14982 If you are serious about continuous delivery, get your
###14984 test automation pyramid right.
###14987 It's super critical to getting to continuous delivery.
###14990 Which means lots and lots, thousands, hundreds of
###14992 thousands of unit tests.
###14994 A small number of integration tests, and a very small number
###14997 of UI or end to end tests as we call them.
###15000 It's super important.
###15001 I'll show you a good graph.
###15004 So just over the last year, the green is obviously the
###15007 number of unit tests that we evaluated.
###15011 Orange the medium or the integration tests and the red
###15013 are the large tests.
###15015 For a long, long time,
###15016 Expedia's pyramid was inverted.
###15018 We were lot of [INAUDIBLE]
###15020 tests.
###15021 Some integration tests and very few unit tests.
###15024 Man, it was so difficult for a tester to catch bugs.
###15028 Only they like our new automation.
###15028 It was crazy.
###15030 So this has been a huge part of helping us get to
###15034 continuous delivery is get your test pyramid correct.
###15037 Measured it and drive it insanely.
###15039 
###15042 Let's talk about the continuous
###15044 delivery pipeline itself.
###15046 What does the pipeline look like?
###15047 Before a developer checks in any piece of code, there are a
###15051 series of pre-commit tests that they need to run and Ari
###15054 in the first talk referred to this.
###15056 Most of these are unit tests.
###15057 They run in milliseconds and you can run hundreds of
###15059 thousands of them very, very quickly.
###15063 Once it's checked in, you have a single branch, called trunk.
###15067 Again, the Google talk referred to this as well--
###15070 single branch, all developers are checking
###15072 in code in one place.
###15074 We run a couple of tests, sets of tests.
###15078 for the mobile team, we use JavaScript unit tests.
###15081 So there's open source tool called Jasmine.
###15082 We use that.
###15084 There are plenty of other tools.
###15085 You guys can pick what you want.
###15087 And then we run a series of trunk small tests.
###15090 What are these small tests?
###15091 These are basic happy path functionality that a typical
###15095 Expedia user would do.
###15096 Search for a flight, book a flight.
###15099 Search for a hotel, book a hotel and so forth.
###15102 So we make sure the basic functionality is working even
###15104 before the build gets promoted to our live servers.
###15107 
###15109 Assuming the previous tests pass, it gets promoted to the
###15115 next stage where we run a much broader set
###15118 of acceptance tests.
###15119 These are a little bit more involved.
###15121 Search for a hotel, change the dates, click on a few things,
###15124 make sure I like all the try one, try two scenarios are
###15127 working, great.
###15129 Those are green, then deploy to an environment
###15134 that is very special.
###15136 this test environment does not have any live dependencies.
###15140 No live services downstream.
###15141 No live connections to third parties.
###15143 one of the most interesting problems Expedia has to solve
###15147 is we have live connections to hundreds of airlines.
###15151 Global distribution systems which is where the airline
###15153 fares get filed.
###15154 And you have to talk to them in real time because airline
###15157 availability and prices can change between seconds.
###15160 I'm sure lots of people here have seen price changes all
###15163 the time, right?
###15164 And so we are dependent on third party data in real time.
###15168 And imagine trying to automate that.
###15171 One of the hardest problems I think.
###15174 So what we do is we mask all those dependencies and say we
###15176 want to focus on the UI only.
###15178 We are going to stub out, or mark out all the dependencies,
###15182 so that whatever we are testing only covers the UI and
###15185 we can find things fast.
###15187 The things that our devs might have broken.
###15190 So we run those on the iPhone, Android, and then we use
###15194 Chrome as basically a base device.
###15197 It covers all the other devices that are out there
###15200 that are slightly older, but they're still in use in Asia
###15207 Pacific countries, and some of the European countries and
###15210 things like that.
###15211 So we try to cover as many of customer base as possible.
###15215 Keep in mind, none of the test run unless the previous thing
###15219 has passed and is green.
###15221 All right.
###15222 Some simple rules around the pipeline.
###15224 
###15226 it has to be green at all times.
###15229 There are hundreds of check-ins coming in.
###15231 Not to the scale of Google, but at least we have 400
###15235 developers checking in every single day.
###15239 The changes conflict with each other.
###15240 Things break.
###15243 So it's important that there's a certain amount of discipline
###15246 keeping the pipeline green at all times.
###15248 Otherwise, you cannot get to continuous delivery.
###15251 If a build breaks, which can happen, it auto-locks the
###15255 branch so no more check-ins can get in.
###15257 Let's not pollute the code base so that we can figure out
###15261 which seal has broken the branch.
###15265 And then what we do is we say, OK.
###15267 If the build is broken, we have to be able to fix forward
###15270 in 10 minutes or less, or else the CL is
###15273 going to get reverted.
###15276 It's a very, very low tolerance for people keeping
###15280 the build broken, right?
###15281 And the reason we come back in 10 minutes is we flirted with
###15285 the idea of five minutes, 15 minutes and all that good
###15288 stuff and what we realized is the simplest reason for a
###15291 build break is when devs miss checking in a file
###15296 accidentally.
###15297 And it takes no more than five or 10 minutes to get the file
###15300 back in and call it green.
###15304 There's the build control where we rotate the
###15306 responsibility amongst different team members,
###15309 Developers, testers, we actually even have PMs do this
###15313 so that they understand why it's important.
###15317 If a build is broken, their job is to get it green in the
###15320 10 minute time frame.
###15322 And what we have found is initially, it used to take us
###15326 five, six hours to actually get builds where they need to
###15330 be, but now we're down to 10 minutes, 15 minutes intervals.
###15333 So we have seen some good success there.
###15338 Let's talk about the oral methodology that we use in
###15342 testing, and then Igor's going to talk about the specific
###15345 tools we used to cover each of these.
###15348 So Expedia's a very agile company and customer the most
###15353 important thing to us.
###15354 I think there is no test better than simulating exactly
###15359 what the user is doing.
###15360 And these VDD tools--
###15363 and Igor's going to talk about a very specific tool that we
###15365 use- like to simulate exactly the user actions.
###15369 And the best part about it is, you can have PMs, product
###15373 managers, business teams write them because
###15375 it's written in English.
###15376 You don't need any technical degrees, you're don't need to
###15379 be a superstar SAT to write the Cucumber scenarios.
###15383 Your test engineers, your PMs can write them as well.
###15388 We use really the most for UI and integration level of
###15390 testing because that's more users scenarios.
###15394 At the code level, we really strongly encourage our
###15397 developers to take a [INAUDIBLE]
###15398 approach.
###15399 Write the test first, then write your code, and your code
###15402 is not good until the test passes.
###15404 We have had mixed success with this, so we're still working
###15407 on getting it better.
###15409 Alright, you have all these great tests in place now.
###15411 Fantastic.
###15412 What's next?
###15413 Let's take them, put them in Jenkins which is the build
###15415 system that we use.
###15417 When you include them in Jenkins you have to make two
###15420 key decisions.
###15422 What is the speed of the test you are running, and how often
###15425 do you want to run them?
###15426 
###15429 If they are really, really fast, you can run them very
###15432 often, and ask for them every single build, so you've got
###15435 lots of regression coverage.
###15437 If they are really slow like the large test, or the UI or
###15440 the end to end test, well guess what?
###15443 You are going to have to figure out whether you want to
###15444 run them a few times a day, or once a week or whatever.
###15449 And so again going back to Ari's talk this morning, he
###15452 talked about the [INAUDIBLE]
###15454 of the problem.
###15455 This is why we choose to run the large test only twelve
###15459 times a day. every two hours.
###15461 So they do not run as part of every single build.
###15464 Just to go back, what that means is what you see here are
###15469 all the regression test cases that run except the large
###15474 tests that can take hours to run.
###15476 Some of our tests take three, four hours to run.
###15478 You can't put them in the build.
###15479 You got to run them at a certain frequency.
###15481 So we run them every two hours.
###15483 
###15487 All right, so you have these tests.
###15489 They are in Jenkins.
###15490 But, again, what do you with live decencies?
###15493 That's when you use mocking, stubbing, remove them so that
###15495 you can focus on testing your code, the stuff
###15498 that your dev changed.
###15500 
###15502 Once you have this, you need to have visibility.
###15504 People need to know what's going on with your builds,
###15508 with your tests, so we use some Jenkins plug-ins.
###15513 These are called built-in test radiators.
###15515 We're going to show you some examples.
###15516 And we also have a video of how the process works in real
###15520 time a little bit later.
###15523 I have been in this situation way too many times.
###15526 You have tests, they run, they fail, and people ignore them.
###15528 They just don't care.
###15529 Or they just go whatever, I mean, it's the tester's job to
###15532 go take a look at them, or the automation engineer's job.
###15535 So again, discipline, in terms of how quickly we react with
###15540 to failure, and how quickly can we fix it.
###15542 Again, the video will highlight how we have done it.
###15546 And hopefully, that will be helpful for some of you guys.
###15550 So over to Igor.
###15551 He's going to going to talk about specifically frameworks
###15553 we are using for mobile and how it's integrated into the
###15556 whole Jenkins system.
###15558 IGOR DOROVSKIKH: Thank you, Kaustubh.
###15558 I enjoyed the speech a lot.
###15560 I hope you continue until the end.
###15564 But anyway, my name is Igor.
###15566 I'm test lead engineer at Expedia for the past year.
###15571 So I was in mobile department, like, the
###15574 second QA when I started.
###15576 And I had to basically solve what kind of tools we have to
###15580 use, and how we can map the test pyramid to fulfill all
###15585 the problems and solve all the problems we had at that time.
###15589 So I'll try to go as fast as we can because
###15594 we're limited on time.
###15596 There are other the talks in this conference about the
###15600 specifics of some of these tools.
###15602 But what I tried to focus on how it fits into the
###15605 continuous delivery process.
###15608 So I'll start it with Jasmine.
###15610 So Jasmine is a J-Unit task framework.
###15614 We use it to, basically, put it in the top of the pyramid,
###15619 which is the functional BDD kind of--
###15623 even though it says unit test, I still think it's BDD
###15626 approach for testing the JavaScript.
###15630 So in order to run the JavaScript test in the
###15633 Jenkins, we use the Jasmine Gem, which is a Ruby library,
###15636 with the CI reporter to generate J-Unit XML reports
###15642 that helps us to draw graphs in the Jenkins to see how we
###15646 progress over the time.
###15649 And the good thing about Jasmine, it complements the
###15652 other UI functional test, which our Selenium.
###15655 And in order to write the Selenium test, we're using
###15659 Ruby as the main language and Cucumber on top of it to write
###15664 our test in English.
###15665 Kastubh was mentioning that it's important that the test
###15669 has to be written in a language that everybody
###15671 understands, including project managers, developers, and also
###15678 QAs, obviously, right?
###15680 Even product team is looking at the test to see what kind
###15683 of coverage do we have.
###15685 Later, I will show you an example of all Cucumber
###15687 scenarios, so you have a better idea for those who have
###15690 never have we've seen that before.
###15691 We also use Cucumber with a Ruby to write our
###15696 integration-level test, which is the API test for mobile
###15700 departments, specifically.
###15702 And we use a just regular HTTP library with a JSON parser,
###15706 and it works very well for us.
###15708 Again, it's all written in Cucumber in English.
###15712 But it fits in the middle layer of the pyramid.
###15715 That's our kind of integration test.
###15718 And for the lower level of pyramid, we use the TestNG.
###15723 Before, we had the J-unit, but the problem was, J-unit, it
###15726 was kind of hard to parallelize all the tests.
###15729 And TestNG solved that problem for us.
###15731 So we use TestNG as our, primarily, unit test framework
###15735 to test our platform, which is a back end platform for the
###15741 whole Expedia.
###15743 And as to Kastubh mentioned earlier, it's important that
###15747 the test executes fast, so we're not going to be
###15751 dependent on the live environments.
###15753 And that's when EasyMock, we use, it's a mocking solution
###15757 for our unit test.
###15759 And for the UI test, and as well as the integration test,
###15764 we use our custom stubbing solution.
###15766 So that helps to speed our test execution in the
###15769 continuous integration environment.
###15773 OK, so the previous slide was actually mostly focusing on
###15779 the mobile web and mobile web tools we use.
###15784 Here, you can see, we also do the mobile apps as a part of
###15788 our team that we have to test both on iOS clients and
###15794 Android clients.
###15795 So specifically for the iOS, we use the Frank.
###15800 It was the first framework that we started looking at
###15805 last year that was supporting Cucumber.
###15808 Like I mentioned earlier, for us, the BDD tool Cucumber was
###15811 the main focus, plus we can use Ruby, that means we can
###15815 reuse a lot of our test methodology.
###15817 That we established before, even for native clients.
###15821 And that's why Frank felt, that that category, at that
###15823 time, and we'll start using that.
###15826 The only part that it I cannot test with Frank
###15829 is the hybrid apps.
###15831 It doesn't support the web views in your native
###15835 applications.
###15837 So for the Android, we using Robotium currently.
###15840 But we're looking to Kalibash because Kalibash is very
###15843 similar to Frank.
###15844 They're pretty much identical.
###15846 The Kalibash is basically, that's what we're looking for
###15849 to transfer our test--
###15850 in the future migrate all of them
###15852 from Robotium to Kalibash.
###15854 And we're start doing that by already converting end to end
###15857 tests, functional tests for Android.
###15862 And because we also have a pipeline for the native apps
###15866 as well, just like for the mobile web, we tried our
###15870 stubbing solution was a tool called VCR.
###15874 And it's not a joke because, like regular VCR, it records
###15877 live responses into the cassettes, which you can
###15879 replay later, and this is our stubbing solution.
###15882 It's open source.
###15883 You can find it easily, Google it, it's a great tool for the
###15888 testing native apps if you need stubbing solution.
###15891 
###15896 OK, so you already probably know this, guys, that we are
###15900 big fans of open source tools at Expedia because they're
###15903 simply free, and a lot of people contributing to them.
###15908 But unfortunately, all of them has an issues.
###15914 So some of you using the Selenium web driver, either on
###15919 iPhone, or desktop browser like Chrome, Firefox, and
###15924 maybe on the Android.
###15925 But because we're mobile, obviously, we're dealing with
###15928 the mobile clients.
###15930 So specifically, for the Android Selenium web driver,
###15934 we've found an interesting issue.
###15935 Whenever try to test HTTPS pages, and there's an invalid
###15941 certificate on the alive test environment, your driver will
###15944 basically get stuck.
###15946 You're going to get blank page and that's it.
###15950 It's a failure.
###15951 So the work around was, basically, generate the
###15956 certificate on the regular Chrome browser and then import
###15960 it to the real device.
###15963 And it worked very well.
###15965 Another problem with the Android Selenium web driver we
###15969 encountered was the drop down boxes, or drop down options,
###15973 they call them.
###15974 So we couldn't solve the problem because the Selenium
###15977 driver couldn't handle that.
###15980 So we use the Jquery as the hacky solution.
###15984 And it works up to date.
###15987 So we use a SIM launcher, it's a Ruby lightweight server, to
###15991 start our iOS simulator before we start
###15994 executing Selenium tests.
###15996 And the problem was that that particular framework didn't
###16000 have the flexibility to rotate a simulator
###16004 while you do test execution.
###16006 So one of our engineers in London actually wrote
###16010 AppleScript to add that functionality.
###16012 So whenever we run our Selenium test, we can rotate
###16019 simulator and see how our responsive design will render
###16022 our mobile web application in the web view.
###16026 
###16029 So basically, those problems are related, obviously, to the
###16033 Selenium web driver, both on the AS and Android.
###16036 Now, on the Frank, which we use to test our native app on
###16041 iOS client, we just couldn't figure out how we're going to
###16046 collect the logs if the application crashes.
###16049 So what we used is a third party framework, Crashlytics,
###16053 which is not free, but it's great.
###16055 It gives you a lot of information.
###16056 It's probably the only framework that's not free that
###16058 were using.
###16059 But it gives you great information and logs.
###16062 AUDIENCE: It's free now.
###16062 IGOR DOROVSKIKH: It's free now?
###16063 There we go.
###16065 Awesome.
###16066 So Crashlytics enables us to get the logs--
###16070 crash logs--
###16071 as well as networking data to analyze if
###16075 the application crashes.
###16076 And we also use the [INAUDIBLE]
###16079 I put here.
###16080 It's basically, besides debugging, we try to collect
###16086 analytic data.
###16087 We use [INAUDIBLE]
###16088 to change the configuration application in the run time.
###16092 It helps also to do more like, I would say, analytic logging
###16096 and testing in that matter.
###16098 
###16101 And finally, I've been mentioning
###16103 cucumber many times.
###16104 For those who haven't seen that before.
###16107 This is the scenario, written in [INAUDIBLE] language in the
###16110 Cucumber format, which is, if you guys look at the screen,
###16114 it's very English-oriented, readable.
###16117 It supports multiple languages.
###16118 English is not the only language.
###16120 The power of this is that you write your test in the
###16124 business logic as your acceptance criteria.
###16130 And then, all the parameterization, all the
###16132 parameters you have to hard code into your code like we
###16135 used to do with the unit test frameworks.
###16138 Everything is here.
###16139 This is the text file, right?
###16140 And if you can look at this specific scenario, where we
###16144 tried to test the hotel search against multiple countries in
###16150 the Seattle area and make sure the image is there.
###16154 If you want to just expand the number of
###16156 countries you want to test--
###16157 I mean localization--
###16159 if you want to change the Seattle to New York, that can
###16163 be done here.
###16165 It gives us a flexibility and scalability, meaning that we
###16170 are flexible in terms of changing tests on the fly
###16174 without looking at the code.
###16175 It can be done by nontechnical people like project managers,
###16178 QAs, developers, at any time.
###16181 They call us Three Amigos, right?
###16183 And another thing, it's a live document.
###16185 It replaces the old test cases and all tests widths.
###16189 So we do not, in Expedia mobile, we do not have any
###16192 test cases.
###16192 We do not have test widths.
###16194 Cucumber, they call them feature files,
###16197 are replacing those.
###16198 
###16201 Can you guys start the video?
###16204 So right now this is the live demo of how we execute our
###16210 mobile web test in parallel.
###16212 It's important run tests in parallel for the speed of the
###16219 pipeline, right?
###16220 You want to get coverage as fast as you can.
###16222 And this is a UI test, which are slow.
###16225 They are the largest test.
###16226 They go end to end around.
###16228 And you want to execute them on as
###16229 many clients as possible.
###16231 Here in the demo, you can see there's both the iOS, iPhone
###16235 simulator and Android simulator running exactly the
###16237 same test, but what you don't see on this demo that it would
###16241 do in real lab, running against real
###16242 devices on mobile web.
###16247 So this is a great example that parallelization saves you
###16250 tons of time, which you will need if you want to implement
###16254 the continuous integration into your department, into
###16257 your company.
###16258 
###16266 This is the sweetest part of automation, when
###16268 you see this working.
###16269 
###16307 I think it's a two minute video.
###16311 AUDIENCE: How many times have you [INAUDIBLE]?
###16313 IGOR DOROVSKIKH: Once.
###16314 
###16316 Which is basically keep the both tasks.
###16318 They are not starting all the time at the same time.
###16321 The Jenkins control that.
###16323 So for the purpose of the demo, we recorded both back to
###16326 back simulator started at the same time.
###16329 But they could be, like, delayed by-- depends
###16331 on the check in.
###16333 They are triggered automatically.
###16335 OK, so let's go to the next one.
###16337 OK, web build radiator is a Jenkins plug-in that we're
###16341 using at Expedia to monitor the health of the pipeline and
###16345 the real time.
###16346 This is the tool that helps us, basically, to spot the
###16349 failure right away and to jump on it and make sure the
###16354 developers fix it as soon as possible.
###16356 Kastubh mentioned 10 minutes period.
###16358 It's very fast.
###16359 That's why visual
###16360 representation is very important.
###16362 I'm sure that probably most of you have been in a situation
###16364 where you were running your tests, and there's a fail
###16366 error, and nobody look at it for a day, at least, right?
###16369 So these radiators are running on big screen TVs around the
###16373 office, and you'll see the video in a few minutes, where
###16376 you're going to see that how it helps to visualize the
###16379 health of your pipeline.
###16380 It's really important.
###16381 And red call is basically a representation of fail error,
###16385 which, you know, attract attention right away if
###16388 there's one.
###16392 So this is the, we call it web test radiator.
###16395 This is not a plug in.
###16396 It's just confluence page where we are basically
###16400 representing the graphs from different Jenkins jobs to see
###16404 overall picture of a product.
###16406 So this is the mobile website that we are using currently
###16409 for the mobile hotels.
###16411 And you can see, on the left side, the graph is much
###16414 greener than on the right side it's because it runs against
###16416 stub data and mock data.
###16419 On the right side, the test is running against the live
###16422 services, which is the test environment.
###16424 This is live services, which undergo the a lot of changes
###16427 during the day, and that's why it's much more redder.
###16431 So when you are building a pipeline, it's important to
###16435 have both and see what's going on with live
###16439 services and stub data.
###16440 
###16444 OK, let's play the second video.
###16447 It's self-explanatory.
###16448 
###16450 [MUSIC PLAYING]
###16584 IGOR DOROVKIKH: It helps after lunch, right, to wake you up?
###16587 So, yes, this is exactly what we do--
###16590 we're responsive to the failures during execution.
###16593 You see what happened?
###16594 Developer checking stale code, broke the test, QA look at it,
###16599 and it's not necessarily QA.
###16601 Sometimes the project manager, even the director of the whole
###16604 team comes, say Igor, why is the radiator is red.
###16606 So it's very important that actually the whole team
###16608 participates in the process.
###16610 And if they spot the failure, they react to it, fix it, and
###16613 it's green again.
###16614 
###16617 And before I give my term back to Kaustubh, I just want to
###16620 make two keynotes.
###16621 What I learned for the past year, what's important in
###16623 order to be successful in terms of embedded test
###16627 automation and continuous delivery, is you always have
###16630 to plan ahead.
###16632 Always plan your testing, either it's BDG tests,
###16634 functional test, or integration test, at least a
###16637 week or two weeks before you start a sprint.
###16639 Especially, if you are an agile
###16640 company, it's very important.
###16643 Besides that, it's very important to understand what
###16646 kind of test you will put into the pipeline.
###16649 Not all the tests go there.
###16650 Be very selective.
###16652 It cannot be large.
###16654 For those tests that you think are the one that is a good
###16656 candidate for the automation for the pipeline, always make
###16660 sure you consult with developers.
###16662 Ask a second opinion.
###16664 Talk to the project managers if it's good for the product.
###16667 And for those tests that will be like for more like an
###16671 integration environment, or any other live environments,
###16675 that will take longer time--
###16677 like large tests for two hours or three hours of execution,
###16680 put them there.
###16681 Make sure you segregate, right?
###16683 That's very important.
###16684 And now Kaustubh will wrap it up.
###16688 KAUSTUBH GAWANDE: So just a quick recap of some of the
###16690 benefits we have seen from doing this.
###16692 This is just the last couple of years.
###16695 We've increased our Java release.
###16698 Content releases can go out every day.
###16700 But Java releases is the hard core changes that can break a
###16703 lot of things.
###16704 We've increased that almost four times.
###16706 The typical regression, like I said, you're checking a bug,
###16708 oftentimes, it takes a day to find the bug, are day like fix
###16713 it on verify it--
###16714 well, with this new system, you just saw, in a matter of
###16716 minutes, the code got checked in, something broke, we
###16721 noticed it, we fixed it, moved on, right?
###16723 So worst case scenario, when we have massive breaks, maybe
###16726 four hours to fix the whole thing end to end, but a lot of
###16730 the time it's been minutes that we can get issues fixed.
###16734 We run 100s and 100s of stubbed regression runs every
###16737 day that find all kinds of issues.
###16740 And when you combine them with regression you run with how
###16742 quickly did they get fixed, it really enables you to do
###16745 continuous delivery.
###16746 Just from my team's standpoint, the testing time
###16749 we have saved by doing this is in the order magnitude of 40%.
###16753 So something that used to take us five, six, seven days to
###16757 test and ship, we're doing it like two days or less.
###16760 And that's helping us move faster, get more agile, and,
###16764 obviously, the obvious one is, the moment you have
###16766 automation, you can run it on multiple devices in parallel.
###16769 So we have four times the device coverage we have today
###16772 than what we had a year ago.
###16774 And as the number of devices in the industry are scaling,
###16776 you really need a solution like that that you can just
###16779 keeps scaling more and more devices.
###16782 That's it, guys.
###16783 Questions?
###16785 [APPLAUSE]
###16791 TONY VOELLM: Great, Thank you, thank you.
###16793 Yeah, I learn a lot.
###16794 All I need to do mobile testing at Expedia is a
###16796 cucumber, a radiator, and some Velcro to stick
###16799 my phones on a wall.
###16800 So thank you.
###16803 In all seriousness, if you have questions, please do line
###16806 up at the mics.
###16808 I'll take some questions off the moderator here.
###16811 And let's see, first question up.
###16814 Did you find automated test in a different language Ruby than
###16819 your application--
###16820 oh wow, this one is hard to parse.
###16822 It says, did you find automated tests in a different
###16825 language, Ruby, than your application, limits
###16828 developers' collaboration on tests.
###16830 KAUSTUBH GAWANDE: I'll take that.
###16831 So we made a very a conscious decision here.
###16833 Last year, when we were picking Selenium, we knew we
###16835 could run it with either Ruby or Java.
###16838 And we said we'll go with Ruby although all our devs are
###16841 really good at Java.
###16842 In fact, it was the developers who came and told us.
###16845 You know, Ruby's as a scripting language works much,
###16847 much better for automated tests as compared to Java,
###16851 which can be a lot heavier.
###16853 So it was in collaboration with devs where we said, OK,
###16855 what is the right tool to use, and we agreed on using Ruby.
###16859 Has it limited the collaboration?
###16860 Absolutely not.
###16861 We have our devs writing Ruby tests all the time.
###16864 I just got an email yesterday saying a new dev that joined
###16868 checked in 75 new tests that are now
###16870 running in the pipeline.
###16871 So I think the devs are actually really part of the
###16876 solution here.
###16877 Collaborate with them and find what tool is right for you.
###16880 TONY VOELLM: Thank you.
###16881 All right, so we have two live questions.
###16883 So I think you got here first.
###16885 You can say your name, your company, if you
###16886 want, and your question.
###16888 Any piece that you'd like.
###16889 AUDIENCE: Hi, I'm Chris McMann with Wikipedia, the Wikimedia
###16892 Foundation.
###16893 I'd like to ask you about enthusiasm for creating
###16897 feature files in Cucumber.
###16899 How do you build enthusiasm.
###16900 Do you have enthusiastic
###16901 contributors for your scenarios?
###16904 And how big of a backlog of scenarios and feature files do
###16908 you keep at any given time?
###16911 IGOR DOROVSKIKH: So I'll answer that question.
###16913 When I started, I was the only enthusiast.
###16918 But I had full support from developers.
###16922 And I think about that as a living organism.
###16926 You have to infect everybody on the team, like a parasite,
###16930 and make sure the people all get the disease
###16932 of Cucumber, right?
###16934 And then what happened is, a year later, right now,
###16937 everybody writing this, let me give you a good example.
###16939 Project managers write an acceptance criteria in the
###16943 Spring in the Cucumber format.
###16945 Then developers and QA pick this up, massage it out, make
###16949 it look clean and nice, and put Ruby logic into a page
###16954 object model, and all tests become live.
###16958 So in my opinion, it's only successful tool when everybody
###16962 is using it.
###16963 Everybody means everyone on the team.
###16965 If it's only the QAs, you will fail.
###16968 Does it answer your question?
###16970 AUDIENCE: Yeah, we can talk about this some more.
###16973 I'm doing the same thing.
###16974 IGOR DOROVSKIKH: We will.
###16975 TONY VOELLM: The thing was--
###16976 let's take this offline later--
###16977 IGOR DOROVSKIKH: Absolutely.
###16977 TONY VOELLM: Just so it's on the mic.
###16980 There's one more like, OK the live question sat down.
###16983 I guess they got their questions answered.
###16984 We'll go to the moderator here.
###16987 Does testing mobile web apps on real devices find more bugs
###16991 in testing on a desktop browser re-sized with fake
###16995 user agents?
###16997 IGOR DOROVSKIKH: Actually, it's a good question.
###17000 Sometimes we have to test in real browsers.
###17002 And a good example is a Facebook connect.
###17005 So Facebook login feature for Expedia, because of the
###17008 limitation of Android Selenium web driver and iOS Selenium
###17012 web driver, we couldn't launched the new window to
###17018 test that functionality.
###17019 So we used the Chrome with the iPhone user agent where we
###17023 actually did some resizing to test the responsive design and
###17027 also were able to launch the new login
###17030 page for the Facebook.
###17032 So yes, actually, we tried to use a lot of open source
###17035 tools, lately, just to solve problems around the driver.
###17039 So wait for the APM talk.
###17041 KAUSTUBH GAWANDE: I think just to quickly add, yes, I think
###17044 there's a place for both.
###17046 You want to use Chrome with user agent strings.
###17049 But you also want to use simulators
###17050 and also real devices.
###17052 There's no one size fits all.
###17053 You have to do all three because they find different
###17055 types of bugs.
###17056 IGOR DOROVSKIKH: I agree.
###17057 TONY VOELLM: Great, thanks.
###17058 Yeah, so here's a hot question that's been popping up further
###17061 and further on the interest list.
###17063 It says, does testing mobile apps, sorry, actually, it just
###17068 got itself to go down.
###17070 Was the UI demo run with mocked data?
###17073 Is your deployment to prod automatic, or is it gated with
###17076 manual intervention?
###17078 So how much automation do you have?
###17079 And are you mocking out your data.
###17081 KAUSTUBH GAWANDE: So the reason why we focused the talk
###17084 on the test automation piece is because we haven't fully
###17086 fleshed out of the continuous deployment piece.
###17089 What I do know is that, you know it used take us seven
###17093 days to do a manual test run all the different languages.
###17097 Now it takes one day.
###17099 So there is manual intervention, but it's like
###17101 significantly lower.
###17103 And one of the things that we did was, we take screen shots
###17106 as the app runs, and we pushed them automatically to our
###17111 localization team who are the experts in the UI.
###17113 They look at that.
###17114 And we get feedback in less than 24 hours.
###17117 So we are also using automation to speed up those
###17120 local verification process.
###17122 TONY VOELLM: Nice.
###17123 OK, I think we have time for one more question, so we'll
###17124 take the live question over here.
###17126 AUDIENCE: Hi, my name is [INAUDIBLE].
###17128 I work for ITA software by Google.
###17130 Thank you for being such a great customer.
###17133 I see that, in Cucumber, you have project manager writing
###17137 the test definition--
###17138 well, the test objective in free form at the
###17140 beginning of the test.
###17141 And then you have a test engineer come and write the
###17144 test itself.
###17147 Over time, with such a large body of tests, how do you
###17150 manage to see tests drifting from the definition?
###17154 So we have an integration plan.
###17159 And we keep that up to date.
###17161 Whenever a feature changes, part of the job of the job of
###17166 the QA engineers is to go and update the existing test out
###17168 of there, and also deprecate tests.
###17171 We do internally go in there in there and deprecate tests
###17173 that are no longer, like, valid.
###17175 So the good thing is, you don't to go to a document and
###17179 update the test plan now.
###17181 You're actually updating your alive automation, right?
###17183 So which means that it's going to get run.
###17186 If it sits there, you have a choice.
###17187 Either it has to pass, or you have to remove it so that you
###17191 know it's no longer applicable to the feature.
###17194 So it's part of the spring development process to going
###17196 and update that.
###17197 IGOR DOROVSKIKH: And we use tagging for that.
###17199 It helps a lot.
###17200 We create different profiles.
###17201 KAUSTUBH GAWANDE: Yeah, we have tags.
###17203 TONY VOELLM: Very nice.
###17204 So thank you, Kaustubh.
###17205 Thank you, Igor.
###17207 And if you guys want to suggest a topic table
###17210 tomorrow, it's sounds like Cucumber is
###17211 going to be a hot topic.
###17212 So thank you, thank you, thank you.
###17214 
###17228 So now we're going to go ahead and enter into our series of
###17231 lightning talks.
###17232 Each one of these is going to be 15 minutes, including Q&A.
###17236 And so we're going to keep these pretty fast paced.
###17239 First one up here is David Rothlisberger.
###17242 And I'm going to start a rumor that, like, he's related to
###17244 someone on the Pittsburgh Steelers so he says he can get
###17246 everybody free tickets.
###17250 So with that, he is from YouTube.
###17251 And he's going to talk about automated set top box testing,
###17255 which will be fascinating.
###17256 DAVID ROTHLISBERGER: Don't need that.
###17257 TONY VOELLM: OK.
###17258 DAVID ROTHLISBERGER: So it's YouView, not YouTube.
###17260 TONY VOELLM: Oh, sorry, oh, YouView.
###17261 [LAUGHTER]
###17263 DAVID ROTHLISBERGER: So if we could have my laptop up on the
###17267 screens, please?
###17268 
###17273 OK, so at YouView, in the UK, we make set-top boxes.
###17278 And to test our set-top box we have scripts running on a PC
###17283 sending infrared signals--
###17285 pretending to be human user pressing
###17286 buttons are my control.
###17288 And we check the video output from the set-top box using
###17291 video capture hardware and image processing to ensure
###17293 that it's done the right thing.
###17296 We have other many other types of test as well, but this is
###17298 the most interesting one to talk at a
###17300 conference like this.
###17302 So today, what I'm going to show you is how you might go
###17305 about implementing such a system.
###17307 
###17311 The command line we're looking at here runs GST Launch, which
###17315 is provided by GStreamer.
###17317 GStreamer is a set of libraries and utilities for
###17321 handling audiovisual media.
###17323 If use Linux on your desktop, your media player is likely to
###17326 be Totem, which is build on GStreamer, just to give you
###17329 one example.
###17332 So let's run this.
###17333 
###17339 GST takes as its command line argument GStreamer pipeline.
###17343 So these exclamation marks here, a GStreamer equivalent
###17347 to the shell's pipes.
###17349 So this pipeline has a video test source element generating
###17354 a video streaming with this test pattern.
###17356 And its output is piped to this color space converter
###17359 element, which converts each frame to a format understood
###17362 by the next element in the pipeline, which is ximagesink.
###17366 A sink is an element that consumes video.
###17369 And this particular one renders out to an x11 display.
###17379 GStreamer ships with a ton of different elements,
###17382 such as this one.
###17384 V4L stands for Video for Linux.
###17386 It's an API for drivers.
###17388 And V4L 2 source supports any device with Video Linux
###17393 drivers, such as my laptop's webcam here.
###17395 Or it could also be a external video capture device.
###17398 
###17403 We can customize the behavior of individual elements by
###17406 setting their properties.
###17408 So if I go back to video test source, I can set its pattern
###17413 property here to something different.
###17415 And we can see it's generating a different video pattern.
###17417 
###17423 Now here's where it gets interesting.
###17424 I'm going to add this template match element.
###17427 Template match is a thin wrapper around an open source
###17430 image processing library called Open CV.
###17433 The CV stands for Computer Vision.
###17435 Open CV is originally by Intel.
###17438 And Template Match takes a path to an image.
###17443 And I'll show you what image looks like.
###17444 It's this white circle on a black background.
###17448 And when I run this, we can see that template matche is
###17451 drawing a red border wherever it finds a match
###17453 in the video stream.
###17456 Now the CPU overhead of the image processing is
###17459 introducing a little bit of jitter into the video stream,
###17463 which causes some time stamping
###17464 problems for the sink.
###17465 
###17468 So just tell the sink to ignore timing information in
###17472 the stream itself and just display frames as soon as they
###17475 arrive, and it's a little bit smoother.
###17476 
###17488 Each element can post messages to the GStreamer bus.
###17491 So I'll ask GST launch to print those messages.
###17494 
###17501 And here we can see that template match has posted a
###17503 message for every frame that it's processed showing us
###17508 whether or not it found a match and the X and Y
###17511 coordinates of that match.
###17514 So I hope that you can see how all these pieces fit together,
###17518 and how easy it is to develop a better capture image
###17523 matching system of this type.
###17525 All these components are open source, so we can really take
###17527 control of our test infrastructure.
###17529 We're no longer beholden to proprietary systems.
###17531 
###17537 Now, I consult to a company in the UK called YouView.
###17540 YouView is a joint venture by the BBC and other major UK
###17543 broadcasters and ISPs.
###17545 And YouView makes a set-top box.
###17548 To test the set-top box, we've developed Stb-tester, and
###17551 we've open sourced.
###17552 So it's built from these components
###17554 that I've just demoed.
###17556 So it supports any video capture hardware with Video
###17559 Linux drivers, or, indeed, any GStreamer source element.
###17565 And it uses GStreamer python bindings.
###17567 It allows you to write your test scripts in Python.
###17571 And they look like this.
###17574 Set-top box tester.press sends an infrared signal.
###17577 
###17580 Wait for match, searches for the specified image, and
###17582 raises an exception if it doesn't find it.
###17586 So this script navigates to our network and internet
###17589 settings menu and we've encapsulated that into a
###17592 separate Python functions so it can be
###17593 reused across scripts.
###17596 Then we press down until we find this image.
###17599 And I'll just ask my editor to display those images online.
###17603 So I'll remind you, this is just Python.
###17605 And those were just string literals.
###17607 It's my editor that knows how to display the images inline.
###17610 It's [INAUDIBLE]
###17611 before anyone asks.
###17614 So you press down until the sub menu is selected.
###17618 We press OK.
###17620 Then we press right until this automatic option is selected.
###17624 There we press down and we assert that next button has
###17627 been highlighted.
###17628 We press OK, and within 30 seconds, we expect to find
###17631 this image.
###17633 So as you can see, it's very simple.
###17635 It's very readable.
###17637 It's entirely procedural, and it reads much like a manual
###17641 test script written in English.
###17644 So non-programmers on the test team have no trouble
###17646 understanding this, and relating it to their own
###17649 requirements, test coverage, matrices, and so forth.
###17654 But at the same time, it is Python, so it's very powerful,
###17657 and you can do anything you can imagine, really.
###17660 So I'll just show you a couple of quick examples of other
###17663 stuff we've done.
###17664 
###17666 This is a video I recorded earlier of an Stb-tester
###17669 script that knows how to navigate through this double
###17672 carousel of pairs.
###17674 So I've told it to find BBC iPlayer.
###17677 And now that it's found it, I've told it to find 4oD.
###17681 So again, the red rectangle is showing us where Stb-tester
###17685 you test has found a match for what it's looking for.
###17688 And now it's found 40D.
###17689 I've asked it find Demand 5.
###17692 So it's looking for this long thin blue rectangle to
###17695 identify the current selection.
###17697 It looks for an image of unselected player to find
###17701 where it needs to go.
###17701 And it figures out what buttons it needs to press to
###17703 accomplish that.
###17706 And I'll just play that again, while I'll show you the source
###17709 code implementing that logic.
###17711 I won't go through it, but it's just to show you that
###17713 it's fairly simple.
###17714 It's barely two pages of code.
###17717 And most of that is docstrings and doctests.
###17721 Although I have removed error handling.
###17723 But if you're interested in seeing the full code, I've
###17726 posted it on stb-tester.com as an example.
###17730 So essentially, your script would just call Find Player,
###17733 pass in an image of the unselected player to know what
###17736 it needs to find and an image of the selected player to know
###17739 when it's got there.
###17740 
###17742 Here's another example.
###17744 This State Machine is YouView's setup wizard.
###17748 So each image in this diagram, each node, represents a
###17754 possible state that the UI can be in.
###17757 And each edge represents an action that the user can do
###17760 from that given state.
###17763 This diagram's generated entirely automatically from
###17766 some Python code we've written to describe the Setup Wizard.
###17772 Each image you see is exactly the same image that Stb-tester
###17775 tester uses to identify that the UI is in
###17778 that particular state.
###17780 And each edge, each user action, is a Python function
###17784 that carries out that action.
###17786 And you can click on one of them.
###17787 And it shows you the source code implementing that.
###17789 And that is all fully hyperlinked.
###17790 So you can draw down as deep as you like.
###17793 
###17797 Non-programmers can still follow the flow of each of
###17801 these functions here.
###17802 
###17805 So you could write a test script where you explicitly
###17808 call each of these actions in the order you want them.
###17811 Or you could do something smarter.
###17813 We do, after all, have this representation
###17815 of the state machine.
###17815 She's it can randomly generate random walk through it.
###17820 Or you could have a test script that takes a given path
###17822 and just tries cutting the power to set-top box at every
###17826 possible state, just to see what happens.
###17828 You know, all this kind of stuff that's incredibly
###17829 tedious to do manually, especially for
###17831 each software release.
###17832 
###17835 I'll show you the full state machine there.
###17837 
###17840 All done.
###17843 So if you look at this in a certain light, it almost looks
###17845 like a wire-framey kind of UX design document.
###17850 And really what we're aiming for is fully machine-checkable
###17854 specifications.
###17855 And this is generated from plain text files.
###17858 So it's version controllable, all that good stuff that we're
###17862 used to for our code as developers we can now have for
###17865 our specifications as well.
###17867 It's very exciting.
###17870 Before I quickly take some questions, I'll just point out
###17875 that stb-tester.com has loads of documentation.
###17881 We've got introductory material, some videos, to help
###17883 you get started.
###17885 There's mailing lists, if you have any questions, and we try
###17887 to do the development of it as openly as possible.
###17892 So thank you for your time.
###17893 [APPLAUSE]
###17900 TONY VOELLM: Great, thank you, David.
###17903 All right, we can go ahead and pull up the moderator.
###17906 If you have questions, you go to either side here.
###17909 In terms of asking questions-- that was very fascinating the
###17912 way you did the sort of image matching and so forth.
###17918 I'll start off with a question of my own--
###17920 how complicated does the image logic have to be, or is it
###17926 just very pixel perfect in terms of matching and looking
###17928 for elements.
###17930 DAVID ROTHLISBERGER: So as we capture video directly from
###17933 the set-top box, we're not going through cameras or
###17935 anything like that, we have fairly high fidelity images,
###17938 but we do have video capture hardware that does H364
###17942 encoding in the hardware, so we do get some
###17945 artifacts from that.
###17947 So our image processing algorithm does handle that.
###17951 And it's got a few knobs that you can tune either globally
###17953 or for a specific image, if you'd like.
###17957 TONY VOELLM: Very cool.
###17958 He also reinstalled my faith in Emacs as being cool, the
###17961 fact that it will embed the images for me.
###17964 OK, I'll take a question right here off of the moderator.
###17967 It says, does having images and test scripts cause flaky
###17973 tests when styles change.
###17977 DAVID ROTHLISBERGER: So I wouldn't call it flaky tests.
###17978 I'd say that the tests start failing predictably if the
###17981 style changes.
###17983 So yes is the answer to that question.
###17985 
###17988 As you've hopefully gathered from some of my examples, most
###17990 of the actual image matching we actually pull into library
###17994 functions which the test scripts call themselves.
###17998 So very few test scripts actually read like the one
###18001 full of images that I showed at the beginning.
###18003 So it's just a matter of changing the common functions,
###18007 or your scripts not working.
###18008 And you can do things like match any of these images so
###18011 that your tests continue to work across different software
###18013 releases if you need to still be testing a version that's in
###18017 production that's got different images than a
###18020 development version.
###18022 TONY VOELLM: Nice, clearly this next question was written
###18024 by somebody who's done this.
###18027 It says, how do you manage the image repository without
###18029 sucking the soul of some poor test engineer?
###18032 [LAUGHTER]
###18039 DAVID ROTHLISBERGER: Well, again, everyone seems to be
###18041 fixating on these images.
###18043 To be honest, the main problem we've had is not with the
###18046 image repository.
###18047 It's with flaky video capture hardware.
###18050 So I guess the answer to this question would be much like
###18053 the previous one, where the image repository is fairly
###18057 small compared to the number of tests that use it.
###18062 And we also have a lot of unit tests of our tests.
###18068 We've captured a lot of screenshots.
###18069 And any time we want to make a change to the image processing
###18072 algorithm, we run all those unit tests against our
###18074 collection of previously captured images to make sure
###18077 that everything continues running properly.
###18081 TONY VOELLM: Great, is this a live question?
###18084 AUDIENCE: Yeah.
###18084 TONY VOELLM: OK, sure, go ahead.
###18085 We have time for just one more.
###18086 AUDIENCE: So I was just wondering if you used your
###18089 framework to measure performance, let's say, such
###18092 as latency, if you click on something, how long does it
###18094 take to go to the other view, things like that.
###18097 
###18102 DAVID ROTHLISBERGER: So when we're doing the image
###18104 processing on a full sized, 720p, or whatever, full size
###18110 video stream, even with a fairly powerful computer, we
###18117 do the image processing in real time.
###18119 So what we do, generally, is we just drop frames if we
###18123 can't process them.
###18124 But for testing performance, we flick a
###18127 switch in the test script--
###18130 
###18133 we use Python Context Manager to have this apply just a
###18135 portion of the script--
###18137 where we cue up every single frame, and then we can measure
###18143 things like that, like, smoothness of
###18145 animations or latencies.
###18147 Latency is a bit difficult because we've got to take into
###18149 account all the various latencies in the system, the
###18152 video capture device, the encoder, the infrared emitter,
###18155 and so on, and so on.
###18156 So we're working on it.
###18158 We're getting there.
###18159 TONY VOELLM: Great, and with that, thank you, David.
###18161 DAVID ROTHLISBERGER: Thank you, Danny.
###18162 TONY VOELLM: That was very insightful.
###18163 DAVID ROTHLISBERGER: Cheers.
###18164 [APPLAUSE]
###18169 TONY VOELLM: So our next speaker up is Ken Kania.
###18173 He is from Google.
###18175 And he's going to talk about web driver for Chrome.
###18178 And so with that, have fun.
###18180 KEN KANIA: Thank you.
###18181 
###18183 All right, so thanks Tony.
###18185 So to start off, my name is Ken.
###18188 Just a little bit of background--
###18189 I work on the Google Chrome Testing team, particularly on
###18192 the browser side.
###18194 So a little bit of background of how
###18195 Chrome testing is broken.
###18197 Just real quick, there's the browser team.
###18199 Then there is kind of the mobile team, then
###18201 there's the OS Team.
###18202 So I'm primarily on the browser side.
###18203 
###18209 OK, so basically, I'm going to be talking today about a tool
###18212 that we have supported within the Chrome team which is
###18215 called Chrome Driver, or also called Web Driver for Chrome.
###18218 So you can see up here, it's very simple problem.
###18220 Many of you are probably familiar with it.
###18222 You may be even familiar with the tool.
###18224 So we have, in Chrome, just Chrome, over 300 million
###18227 active users.
###18228 This is pretty old data, but at least that still holds
###18232 true, hopefully.
###18233 But so we have ever expanding amount of platforms.
###18237 So of course, we just started with Chrome, with Chrome for
###18239 Beta on Windows 2008, expanded into other desktops, now Mac,
###18244 Linux, and then, more recently, Chrome OS branched
###18247 out into Chrome OS, and then now mobile, Chrome for
###18249 Android, and Chrome for iOS.
###18251 So the question, the basic question, is, as a web app
###18254 developer, how can I go about automatically verifying that
###18258 the critical functionality of my app works across all these
###18261 different platforms?
###18262 So this is a pretty broad question that you could look
###18264 at just in browsers in general.
###18266 But today, this talk, I'm just going to focus just on Chrome.
###18268 So within Chrome, how can I verify my functionality, the
###18272 critical functionality that map provides across all these
###18274 platforms automatically.
###18276 And so hopefully, during your development process, you've
###18280 engaged in good unit testing.
###18282 Maybe if you're a really diligent tester, you've also
###18284 done some sort of isolated component testing.
###18288 But at the very end of the day, you want to be able to
###18290 have some guarantee that what the end user sees and what you
###18294 go through as an end user is actually correct.
###18296 
###18299 And basically, the solution to this problem is Chrome Driver
###18304 so a little bit of background.
###18305 Chrome Driver follows the W3C web driver working draft that
###18311 some of the Mozilla guys talked about a little bit
###18313 earlier on this morning.
###18315 So because of that, it's interoperable with all the
###18317 open source web driver client libraries, whether its Java,
###18321 or Python, or Ruby, or whatever fits your boat.
###18326 It is open source.
###18327 Chrome Driver is open source and maintained by the members
###18330 of the Chromium project.
###18331 And Chromium, for those of you who aren't familiar, is just
###18333 the project that supports Google Chrome and another
###18335 Chromium-based browsers.
###18337 So for the rest of this talk, I'm just going to describe a
###18340 couple things.
###18340 Number one, how can you use Chrome Driver?
###18344 What does it actually do?
###18346 And number two, what kind of work we've done to enable
###18352 chrome driver Torque, not just on desktop, but also the other
###18355 Chrome platforms, specifically Android, in this talk.
###18360 And then, hopefully, I'll give you a little bit of a deeper
###18362 dive about how exactly Chrome Driver works, just for you
###18365 guys who are curious and maybe who want to adopt kind of
###18367 similar technologies underneath, depending on what
###18370 frameworks you are using.
###18373 So to start, web driver, so that previous slide doesn't
###18377 really make whole lot of sense if you don't
###18379 know web driver is.
###18380 So web driver is a cross-browser automation API,
###18383 which is primarily for website testing.
###18386 That's what it, historically, was for.
###18389 Now there's become more use cases, wider audiences using
###18392 web driver.
###18393 But that was, at least, one of the main, original, and still
###18395 is, the main intention for web driver, the web driver API.
###18400 So it's cross browser.
###18401 So this API covers, I listed couple of things there.
###18404 We have browser control, being able to simulate the user
###18408 input, whether it's mouse, or typing, keyboard, et cetera.
###18412 And also, another category I just put together is, web
###18416 stuff, random web kind of stuff, like being able to find
###18419 elements on a page, evaluate script, evaluate JavaScript,
###18422 manipulate local storage cookies.
###18425 So that's basically web driver.
###18426 So web driver is a cross browser automation API.
###18428 And Chrome Driver is essentially the implementation
###18431 of that protocol for Chrome.
###18433 Not a very difficult concept.
###18436 But so, just to get you a little bit familiar with those
###18438 of you who perhaps haven't seen a lot of web driver stuff
###18441 before, here's a sample test written in Python using the
###18444 open source Python web driver library.
###18448 That first statement, we're just creating an instance of
###18451 Chrome Driver.
###18452 We're passing in the path to our Chrome Driver binary
###18455 executable.
###18456 We'll talk about that little bit later.
###18458 The second statement is simply navigating to our test page,
###18461 in this case, which is Google.
###18463 Then we're finding an element on that page with the name q.
###18465 We're saving a reference to that element inside this
###18468 variable search box.
###18469 We send some keys, which is just
###18471 typing, type Chrome Driver.
###18473 We submit that form.
###18475 And at this time, web driver will then wait, if there's any
###18478 navigation that's occurring because of that typing, or
###18480 because of the form submission.
###18483 And then we actually do the one actual test part of our
###18485 test, which is, we assert that Chrome Driver is in the title
###18489 of the page that we have navigated to.
###18491 And lastly, of course, we just quit.
###18493 That's a simple, really simple test that hopefully gives you
###18496 a feel for what you can do with the API.
###18499 So now, how can we go about using Chrome Driver?
###18503 So an important thing here is that Chrome Driver, actually,
###18507 for desktop, for Windows, Mac, and Linux, has been around for
###18509 quite some time, over a year.
###18513 You can easily find that on our public Chrome Driver site,
###18517 code.google.com/p/chromedriver.
###18518 Of course, you can just search for it.
###18521 But recently, in the past couple of months, several
###18524 members of the Chromium team from Android, also from the
###18527 browser side, have been working on a new version of
###18530 Chrome Driver, which we just call Chrome Driver 2.
###18532 
###18535 Pretty creative.
###18537 So basically, this is a re-architecture of Chrome
###18541 Driver to be able to span, like I was talking about at
###18545 the beginning, multiple and more Chrome platforms.
###18549 Because we want our testers to be able to run these tests
###18551 against as many Chrome platforms as possible.
###18553 So with this re-architecture, we were able to support, not
###18556 only desktop, as I have listed at the top, but also Android.
###18560 And so I'm happy to announce that we do have alpha support
###18563 for Chrome on Android, Chrome Driver on Android testing,
###18567 with Chrome on Android.
###18569 And you can kind of get hold of that on our website.
###18572 I posted a couple of links here that you can look at.
###18575 A couple caveats with be Android alpha.
###18579 Currently, you do need a special configuration.
###18583 You do need a Mac or Linux host connected via USB to your
###18586 actually Android device.
###18589 And there's also a couple of things, like you need Chrome
###18591 27, a couple more details that you can see on the site.
###18595 And basically, though, really, what you need to do is specify
###18599 the Android package capability when you start your session.
###18604 And for Chrome OS and for iOS, unfortunately, if you want to
###18608 use that, you just need to be patient or I want to
###18613 contribute.
###18614 So you have to wait for that.
###18617 So how does it work?
###18619 A little bit of background on how it works.
###18620 So there's mainly three components.
###18622 On the left here, I have the web driver client, which is,
###18625 essentially, your test.
###18626 It doesn't have to be a test.
###18627 Maybe you're writing something else which uses the web driver
###18631 library, which is available in all those different flavors,
###18634 different languages that I was talking about earlier.
###18636 And that communicates, these are all processes, at least
###18638 for Chrome.
###18639 So that's one process, your web driver client process.
###18641 And that talks to Chrome Driver, which is the tool that
###18645 we're talking about in this talk, which functions as the
###18648 web driver server.
###18649 And that, of course, communicates over the standard
###18652 web driver protocol that we've been talking about today.
###18655 And Chrome Driver talks to Chrome, controls Chrome, via,
###18658 right now, two main ways--- dev tools and extensions.
###18662 And so this is Chrome Driver two.
###18665 The old Chrome Driver used a different Chrome automation
###18668 API, which was desktop only.
###18670 But so now we're just going to talk about Chrome Driver 2.
###18673 So a little bit about dev tools and extensions for those
###18676 guys who, perhaps, haven't heard a whole lot about it.
###18679 So dev tools is the same thing.
###18681 You can see it easily in Chrome by just Right clicking
###18683 the page, going Left clicking, Inspect Element.
###18685 You'll see that kind of debugger view that comes up
###18691 usually at the bottom of the page.
###18692 And you'll see as the DOM tree.
###18694 You'll be able to see performance metrics.
###18697 You can trace and see the network activity, what's
###18700 taking so, what resources are taking how long to load and
###18702 kind of that break down.
###18704 So that's essentially, that debugger interfaces is using,
###18709 basically, dev tools underneath.
###18711 Dev tools, of course, is short for developer tools.
###18715 So we're using that.
###18717 And the main benefit behind using that is, number one,
###18721 it's pretty low level.
###18721 It used to be mostly implemented in web kit, which
###18724 is now Blink, or has been split into Blink.
###18729 But it's supported on all the platforms that Chrome runs on,
###18732 except for iOS, currently.
###18735 You can do, on iOS 6-plus, you can do dev tools, but it's
###18740 only officially supported through Safari on OSX.
###18743 So we can't actually access that right now with Chrome
###18746 Driver on iOS.
###18748 The second main tool that we use, or API that we used to
###18751 automate Chrome is the extensions API that Chrome
###18753 comes supported with.
###18755 So of course, many of your guys are familiar with
###18757 extensions, the concept of extensions.
###18759 But extensions were meant to modify or enhance the
###18764 functionality of the browser.
###18766 And we've taken that, and we've just of course, plugged
###18768 in our own custom extension to be able to control the browser
###18770 through some of the APIs that are provided there.
###18774 But however, since extensions are desktop only, we've relied
###18777 mostly on developer tools for most of the stuff
###18780 that we care about.
###18781 
###18783 So here's just a nice diagram for you guys who are
###18786 interested in kind of what the overall implementation really
###18789 looks like.
###18789 So there's three pieces here.
###18791 There's the Chrome Driver Server.
###18793 And there's the browser, Chrome's
###18795 multi process browser.
###18796 So you have that browser processing.
###18797 You have those two rendered processes.
###18799 You can see, commands will come into through the HTTP
###18801 server from our web driver client.
###18804 It'll be delegated to a particular session.
###18807 So perhaps you might have multiple web driver clients
###18810 talking to this one Chrome Driver server.
###18812 So you might have multiple sessions.
###18814 And these sessions usually control their own instance of
###18817 the browser in this case, it might be a little bit
###18819 misleading, but you can see each session has a line to
###18822 this dev tools server.
###18824 Usually, those are separate browsers.
###18825 But the session we will talk to the dev tools server, which
###18828 then delegates down to particular renderers through
###18831 the dev tools agent.
###18832 And hopefully, your web app that you're trying to test is
###18835 running in one of those renderers.
###18837 And another one of those renderers hopefully, we have
###18839 the Chrome Driver extension running to be able to do some
###18842 of the extra stuff we need to do to automate
###18844 the browser on desktop.
###18845 
###18847 So what's kind of some of the future stuff that we're
###18849 considering for this tool, some plans that we
###18853 hope to start on?
###18854 So, in general, since we have switched to developer tools
###18858 for the basis of controlling Chrome, that gives us a lot of
###18862 more, since it's a little bit lower level than our old API,
###18864 it gives us a lot of really cool features like being able
###18867 to profile what, in JavaScript, or on your page is
###18871 taking up so much memory, what kind of memory leaks,
###18873 possibly, do you have.
###18875 Some interesting performance measurement stuff, access to
###18878 the logs of the JavaScript console.
###18883 Talking more specifically about Android, we're
###18888 considering supporting the upcoming
###18891 Chrome-backed web view.
###18892 So right now, web view is, of course, kind
###18894 of an Android concept.
###18895 
###18899 We are considering, though, supporting, when Chrome
###18902 supports or powers that web view, to be able to integrate
###18904 with that and actually test that.
###18906 We are considering also running the driver on the
###18908 device, instead of requiring that host configuration I was
###18911 talking about earlier.
###18913 For iOS, it's a little bit tricky, as I mentioned,
###18916 Because of the limitations just in the UI web view, how
###18918 we're using the UI web view in Chrome for iOS.
###18923 And we're still in pretty early stages of development,
###18926 kind of planning, so not a whole lot to say there,
###18928 unfortunately.
###18930 So that's basically the end of what I wanted to talk about.
###18933 So if you're interested in using ChromeDriver as a tool,
###18937 we have ways that you can file bugs.
###18940 I have that link up there.
###18940 Also, there's a user forum, a public user forum.
###18944 And of course, since it's all open source, we love to have
###18946 third party patches, contributions, you name it.
###18951 That concludes my talk.
###18952 Thank you.
###18953 [APPLAUSE]
###18958 TONY VOELLM: Great.
###18959 Thank you, Ken.
###18961 You've come a long way since writing games based on the
###18963 Power Puff Girls.
###18964 
###18967 That's what happens when they tell me these little tidbits.
###18970 It looks like we may have time for one question.
###18974 If there's not a live question--
###18975 
###18978 OK.
###18978 Let's go ahead and take one live question, and then we're
###18981 probably going to just move on to the next talk.
###18983 So please.
###18983 AUDIENCE: For some time, Firefox has been able to
###18985 control the profile.
###18990 I think Chrome's handling of profile now
###18994 has parity with Firefox's.
###18996 And I don't think it's part of WebDriver specification.
###18998 Is that something that you're talking to Mozilla about, and
###19003 will it continue to support,
###19004 manipulating profiles in Chrome?
###19006 KEN KANIA: Right.
###19008 To start off, we are not currently talking with Mozilla
###19012 about that.
###19013 But we are interested in maybe not supporting profiles per
###19017 se, but there's a distinction in Chrome--
###19020 I'm not sure about the other browsers--
###19021 between your user data directory
###19023 and also your profile.
###19024 So for ChromeDriver, we do, in the tool, allow you to specify
###19028 a custom user data directory, which maybe has several
###19032 profiles already set up.
###19033 Be able to do stuff like that.
###19035 But we don't have any way now to dynamically, through that
###19038 WebDriver API, create new profiles, or edit profiles, or
###19041 anything like that.
###19044 TONY VOELLM: Great.
###19045 Thank you, Ken.
###19046 KEN KANIA: OK.
###19047 Thanks.
###19047 [APPLAUSE]
###19052 TONY VOELLM: Our next speaker up is Vojta Jina.
###19057 He likes funky jazz, and he has a very action-packed talk.
###19061 He's probably going to run right to the
###19062 middle, or to the end.
###19064 So you probably won't have questions, and we'll just go
###19067 right on into the next talk right after he's done.
###19072 Here you go.
###19072 Great.
###19073 Thank you.
###19073 VOJTA JINA: Thanks.
###19075 
###19086 This conference is about automation in testing.
###19091 So I assume you guys are one of those crazy people who try
###19094 to automate everything.
###19095 
###19098 Even if it takes more time than to do it manually, we
###19101 write a script for it because that's what we believe in.
###19107 And that's cool.
###19108 I mean, Angler team, we are the same.
###19111 Like we basically try to automate everything.
###19114 So from simple things like automatic deployment, to
###19118 website, to things like--
###19122 we have CI server, and whenever I push some code to
###19125 GitHub, it automatically builds Angler, runs all the
###19129 tests on different browsers, and screams at
###19132 me and if it fails.
###19133 
###19136 Or every release has a change log.
###19140 That's basically a list of changes, like list of new
###19143 features, back fixes, breaking changes.
###19147 And you know what?
###19148 We generate even that.
###19150 We have a convention for Git messages, and then there's a
###19154 script that basically generates the change log based
###19156 on the Git history.
###19159 My favorite example is Angler docs.
###19162 So let me actually show you the docs.
###19165 
###19167 If you go to docs.angler.js.org, there is
###19173 Angler documentation.
###19175 This is, for instance, API docs for ngClick, which is a
###19178 directive in Angler.
###19180 And down here, here's an example.
###19183 Here is a source code for that example, and then there's a
###19187 live preview, like demo, where you can actually play with it,
###19190 and see how it works.
###19192 Cool.
###19194 Of course, the whole documentation is generated
###19196 automatically.
###19198 But the thing I want to show you is the second tab, which
###19202 says, "End to end test." That is basically an example for
###19207 you how you could possibly test such a code.
###19210 Right?
###19210 Like end to end test for that.
###19213 But what do we do with that?
###19214 We extract all these tests, and then we round them as a
###19218 part of the build.
###19219 Let me show you that.
###19222 So it looks like something like this.
###19224 Now you can see it's basically going through the whole
###19227 documentation, and checking whether these
###19229 examples still work.
###19233 This is really awesome, because before we did this, it
###19236 would be like-- all the time, it would happen-- like someone
###19238 would email me.
###19239 Like, hey, man.
###19239 Your docs example for HTDP doesn't work.
###19243 Like, ah.
###19244 Cool
###19244 I even didn't know there was an example for that.
###19248 But now with this, you don't have to think about it.
###19251 And if you break it, it will scream at you.
###19254 
###19256 We basically tried to automate everything.
###19259 Let me kill this guy.
###19263 And we do testing a lot.
###19265 We rely on testing a lot.
###19267 And, therefore, we want to make sure that our testing
###19270 story is a really efficient.
###19272 That's pretty much why we did Karma, which is, I would say,
###19275 a test run that fits our needs.
###19277 Because we did we made it for ourselves.
###19280 And that's what I want to show you now.
###19282 I want to show you this test run that we use to test
###19285 Angler, and pretty much to test any JavaScript.
###19290 So let's do a demo.
###19291 
###19295 So Karma is an MPM package.
###19298 So assuming you have no JS, you get install it through and
###19302 MPM Install Karma.
###19304 And then, the first thing you need in order to start, you
###19307 need a configuration file, which is basically for Karma
###19311 to know about your project.
###19312 Basically what are the files of the project?
###19315 What browsers you want to use, which testing framework you're
###19318 using, and stuff like that.
###19320 To make it simple, you can generate this config file by
###19325 Karma in it.
###19326 And it would ask you a couple of questions, like what
###19329 testing framework you want to use, which browsers,
###19333 and stuff like that.
###19334 And it will generate the config file for you.
###19337 Or if you are using Grunt--
###19340 Do you know, guys, Grunt JS?
###19341 It's a really awesome task runner for JavaScript.
###19344 So if you are using Grunt, there's a Grunt plug-in for
###19347 Karma that allows you to configure Karma through Grunt,
###19350 and you don't need this configuration file at all.
###19355 All right.
###19355 For This demo, I'm going to be using Angler codebase, which
###19361 already has this config file.
###19363 So we can start it.
###19364 I can do karma start.
###19366 
###19371 What's happening in the background, it starts a
###19373 browser that I told it in the config file that
###19377 I want to be using.
###19379 You know, we can forget about the browser for now.
###19382 But the important thing is that there is a real browser
###19385 in the background that karma will use to
###19387 actually executive a task.
###19389 That's something I want to actually talk about, because
###19393 you can execute--
###19394 you can test [INAUDIBLE]
###19396 browsers.
###19396 You could do like OJS and Rhino.
###19399 But for us, it was really crucial to use real browsers,
###19403 because if you know Angler, there's tons of like
###19405 components, and custom directives, and stuff.
###19408 And that's tons of DOM manipulation.
###19409 And we need to DOM API.
###19411 We need to test these things.
###19413 So we need a real browser for that.
###19415 Plus, there are so many inconsistencies between
###19419 different browsers.
###19420 And honestly, JavaScript itself, as a language, it's
###19423 not that bad.
###19424 It's pretty consistent.
###19425 But the DOM API, that's what's most of the issues.
###19429 So again for us, we need a real browsers.
###19433 Plus, the third thing, there is a good advantage once
###19437 you're using real browsers.
###19438 It basically communicates through HTDP in [INAUDIBLE]
###19442 circuit, so it means you can use any browser.
###19445 You can test your phone, your tablet, TV, Playstation,
###19450 whatever you want.
###19451 
###19454 OK.
###19455 Let's go to source code.
###19458 Another thing that's happening in the background is that
###19461 Karma is now watching all the source files of my project.
###19465 And whatever I hear is like cache factories and service in
###19469 Angler, it's not important what it is.
###19471 But I'm going to save the file, just press Command-S.
###19476 And you can see that Karma immediately sees that, and
###19480 starts executing all the tests.
###19482 You can see it executed over 1,800 of unit tests in, like,
###19486 three seconds on the real browser.
###19488 
###19493 I mean, three seconds is not bad, but if you have a huge
###19496 project, it can be more.
###19498 And our goal is to get this instant feedback so I can run
###19502 these tests all the time.
###19503 Because what I really do during development is, like, I
###19505 want to run these tests on every Save.
###19509 That's why we have this feature.
###19512 We call it d-describe and [INAUDIBLE].
###19516 On the right side, that's my test.
###19519 I'm not sure if you realize the syntax.
###19520 It's a Jasmine testing framework.
###19522 
###19525 I should mention that Karma is agnostic of testing
###19528 frameworks.
###19528 You can use it with any testing framework you like,
###19531 pretty much.
###19532 There is an adapter for [INAUDIBLE], Mocha, Jasmine,
###19534 and Nodeunit, and stuff.
###19536 We at Angler are using Jasmine.
###19538 That's why this example is in Jasmine.
###19540 But you can use anything else.
###19542 Describe in Jasmine basically means, like, defining a test
###19546 suite, a list of suites.
###19548 And it means defining a single test.
###19551 And what I can do, I can focus these things.
###19554 I can put d-describe.
###19555 And now when I say, if you can see, it immediately executes
###19558 just this suit.
###19560 So it's even faster.
###19562 Now, it executed only 24 of these 1,800 unit tests, and it
###19566 was like, I don't know, a few more seconds.
###19570 And so the goal is--
###19572 The thing about this that's important is it gives you like
###19576 new workflow.
###19577 It's basically like using test as a development workflow,
###19582 where you basically can stay in your text editor, and you
###19585 don't have to move back and forth between the browser and
###19588 your text editor to see how things work.
###19591 Because what I can do--
###19593 let's say in this test, I can do--
###19595 I don't know--
###19596 console.log(cache1.) Whatever it is.
###19601 Maybe give me size.
###19602 
###19606 It gives me error, undefined, whatever.
###19609 OK, so there's no size.
###19612 So that gives us info.
###19613 
###19616 The thing is that I just saved the file, and I immediately
###19619 see in the console the results from the real browser.
###19623 So I don't have to go to the browser to do these things.
###19626 This is really important for the workflow, because you can
###19629 stay in the browser.
###19631 Sorry, in the text editor.
###19632 
###19640 One more thing that I want to mention is that there's no
###19644 support from the text editor.
###19645 I'm using Sublime.
###19646 You can use Emacs, Vim, whatever you want.
###19649 Because the only thing that the text editor in this
###19651 workflow does is saving files.
###19653 
###19656 I got one more thing that I want to show you.
###19658 And that's debugging.
###19663 Because what I can do, I can, inside this code, if I want to
###19668 actually use a real debugger, I can do this, and guess what.
###19678 I can go to the browser that I had somewhere in background,
###19681 and I have debugger.
###19682 I can watch variables.
###19684 I can see call stack.
###19685 I can step into functions.
###19687 And this is something that is not a feature of Karma.
###19689 It's just the browser.
###19690 Like most of the modern browsers, they have debuggers.
###19693 So it only allows you to use that.
###19696 And again, you don't need any support from the text editor
###19699 to do that.
###19700 If you happen to be using something like WebStorm, or
###19704 some better IDEs, you can even configure it to do this do
###19707 debugging directly from WebStorm.
###19709 So you can put break points and stuff.
###19711 You even don't have to leave your IDE for debugging.
###19715 
###19723 All right.
###19725 There is tons of other features.
###19727 Like, it can do code coverage.
###19730 It can [INAUDIBLE] a file so you can develop.
###19732 You can use CoffeeScript and it will compile CoffeeScript
###19735 on the fly.
###19736 There's a Dart plug-in for testing Dart.
###19741 All kinds of other plug-ins.
###19743 But I think the most important feature is the workflow, that
###19746 you can run tests, and instantly get the feedback.
###19750 That's the main thing, so that's what I
###19752 wanted to show you.
###19754 If you like it, you can go to GitHub check it out.
###19757 It's open source, so [INAUDIBLE] pull request.
###19760 And as I said, we're probably running time pretty soon, so
###19764 I'm not sure if we are going to have questions.
###19767 But I'm going to be here today, and whole tomorrow.
###19770 So find me, and I'm more than happy to talk to you guys
###19773 about pretty much anything.
###19776 TONY VOELLM: Thank you, Vojta.
###19777 Actually I think we may have time for one question.
###19780 
###19783 I have to say I was really happy that you only typed
###19786 karma start.
###19788 And you never typed karma end.
###19789 I was a little worried if that was going to happen, because--
###19792 VOJTA JINA: Oh.
###19794 I did Control-C.
###19794 TONY VOELLM: I tried to make everyone up here.
###19796 OK.
###19798 OK, with that, we can take a live question, if someone has
###19800 a live question.
###19801 Or we can go to the Dory.
###19805 Or we can move ahead.
###19807 OK.
###19808 I got a question here.
###19809 The number one question.
###19810 You probably saw this, actually, in the UI, too.
###19813 It says, "Why was Karma renamed from Testacular?"
###19816 VOJTA JINA: OK.
###19818 I didn't expect that question at all.
###19820 
###19825 I don't think I want to answer this question on the stage.
###19831 But the good thing is that now typing Karma is way faster
###19836 than Testacular.
###19837 Because especially, if you are using a regular layout,
###19840 keyboard layout, it's like really--
###19842 it's really easy to type.
###19843 
###19846 TONY VOELLM: Great.
###19847 All right.
###19847 Thank you, Vojta.
###19848 Than you very much.
###19851 VOJTA JINA: I think I would like to close this with a
###19854 quick story.
###19854 I think we have two minutes, so I can do that.
###19856 TONY VOELLM: 30 seconds.
###19858 VOJTA JINA: 30 seconds?
###19859 I will do it quickly.
###19860 Because I'm really happy about that thing.
###19864 There is a project called YouTube on TV.
###19867 It's basically if you have Playstation 3, there's a
###19869 YouTube app, and it's written in Angler.
###19872 And a few months ago, we were helping the team to debug some
###19875 performance issues, and I noticed that they have like 90
###19880 or 100 unit tests.
###19882 I was like, well, that's not many.
###19884 So I asked them, like, guys, why don't
###19886 you write more tests?
###19888 And when they showed me like how painful it was to, like,
###19891 add a new test in their [INAUDIBLE], and how slow it
###19896 was to run these tests, I was like, OK.
###19899 I understand that.
###19901 And so the next week, I helped them to set up their
###19903 environment with Karma.
###19904 And we actually set it up to even run it on real
###19907 Playstation.
###19908 And it was really cool, because in a few days, maybe a
###19912 week, I got an email from Tyler, one guy on the team.
###19915 And he was like, Vojta!
###19917 This shit is awesome!
###19918 Like it completely changed our life.
###19920 We test drive everything now.
###19923 Believe me or not, but after a week or something, they had
###19926 over 400 unit tests.
###19927 So it basically took them about a year to write 100
###19930 tests, and then they wrote like 300 tests
###19933 in just a few days.
###19936 The point is that you should spend time figuring out your
###19941 workflow and your environment.
###19943 Find the right tools for you.
###19945 It doesn't have to be Karma.
###19946 I don't care.
###19947 Use whatever works for you guys.
###19948 But it's so much worth it to spend the time.
###19951 Because once you do it, it will save you tons of time.
###19954 TONY VOELLM: Cool.
###19955 Thank you.
###19955 Thank you.
###19955 [APPLAUSE]
###19961 TONY VOELLM: Next up here we have Patrik Hoglund, who is an
###19966 avid drummer, which probably comes in quite handy when he's
###19971 banging his head against this automated video quality
###19975 measurement system.
###19976 So with that, Patrik.
###19977 PATRIK HOGLUND: Thank you.
###19978 Thank you.
###19980 Right.
###19981 So I'm going to talk about automated video quality tests.
###19984 That is a problem we run into with the WebRTC project.
###19988 First, has anyone heard about WebRTC before?
###19992 There's a couple.
###19992 OK.
###19993 Well, for the rest of you, no.
###19995 WebRTC is a web standard that is being developed right now
###19999 for video and voice chat built into the browser.
###20002 We are implementing this right now in Chrome.
###20005 And also, Firefox and Opera are implementing this web
###20009 style in here.
###20011 WebRTC gives you the possibility to, in a web page
###20015 with JavaScript, acquire users' webcam and microphone,
###20018 with their consent, of course, and send it over the net
###20023 directly between the participants.
###20025 So it uses peer-to-peer technology.
###20027 And all the stuff is built into the standard, so it's
###20029 really easy to write a video chat application that works,
###20033 regardless of LIT, and firewalls, and other things
###20037 that can be in the way.
###20038 OK?
###20040 So the Chrome implementation of this is done in Stockholm,
###20044 and Mountain View, and in Kirkland.
###20045 And I work in the Stockholm office with this project.
###20049 So we wanted to test this.
###20052 But to explain what we need to test, I'm going to explain
###20056 briefly how a WebRTC call works.
###20059 This diagram here, as you can see, is a very simplified
###20063 description.
###20064 So what happens here is that we can imagine we have two
###20068 browsers on two different machines somewhere.
###20071 And then it is up to the web page to implement that
###20074 application part there, as you can see.
###20076 And implement a signaling solution.
###20079 The point of the signaling solution is to first figure
###20081 out like, who would you like to call
###20083 with WebRTC, for instance?
###20084 And [INAUDIBLE]
###20086 implement like a contact list, or random, or whatever.
###20093 And also the signal resolution exchanges the information that
###20097 is needed to set up the call.
###20098 For instance, what code [INAUDIBLE] support and so on.
###20101 We're going to gloss over that part completely, and start
###20104 focusing on number two.
###20105 You can see it on there, which is media.
###20107 When media starts flowing.
###20108 OK?
###20109 
###20111 Given that we set up a call, how do we test it?
###20113 So one of the goals we set out to do here was to set up a
###20117 call and measure the video degradation.
###20119 Because obviously, when we send video over the internet,
###20122 we're going to have to compress it.
###20125 Also in WebRTC, there's a ton of built-in algorithms for
###20130 bandwidth estimation, and like adapting the encoding
###20133 parameters to how much bandwidth you have, or how
###20136 loose you connection is.
###20139 Or, as I like to see it as a test engineer, a lot of things
###20143 that can go wrong.
###20144 A lot of things that can break.
###20146 So we wanted to measure the video quality to the console
###20149 at the other end of the call.
###20152 We wanted those measurements to correspond to user
###20155 perception as much as possible.
###20157 What do I mean by that?
###20158 Well, basically if a user would think it looks bad, it
###20162 should get a low score.
###20163 And if it's artifacts that a user doesn't really notice
###20166 that much, it shouldn't affect the score too much.
###20171 We wanted this thing to run continuously.
###20172 We wanted it to be a reusable toolchain with small tools
###20177 that have well-defined tasks as much as
###20179 possible to make it reusable.
###20182 And we wanted the implementation work to be a
###20186 self-contained unit so we could hand
###20188 it off to an intern.
###20189 And that is precisely what we did.
###20190 We handed it off to our intern, [INAUDIBLE]
###20193 from Bulgaria.
###20194 And she implemented it, and it worked great.
###20196 So that's why I'm here to share with you an overview off
###20201 what goes into making a tool like this.
###20204 We're going to obviously gloss over a lot of details, but
###20206 hopefully we'll give you an idea of what we need to do.
###20210 OK.
###20211 When we started this thing, we already had the tests, which
###20213 could launch a browser, open two tabs, launch a small C++
###20218 binary, which is a signaling solution, and have the two
###20222 tabs set up a WebRTC call.
###20226 Set up a video, it gets fed into a regular video tag.
###20229 HTML5  tag.
###20232 We had some fake webcam drivers on all major platforms
###20238 so that we could basically feed known input video into
###20241 the webcam and have it look like the webcam to WebRTC.
###20246 We also have implementations of the peak signal to noise
###20249 ratio and structural similarity algorithms.
###20251 I'm not going to go into detail what those are, but
###20254 supposedly together to give a pretty good picture off the
###20257 video quality.
###20258 
###20262 Then the first problem to solve was, how do we record
###20268 what is coming out of the video tag on the other side?
###20270 First, we considered screen scraping solutions where we
###20273 scraped the pixels on the screen, and
###20274 that kind of thing.
###20275 But fortunately, we were able to avoid that because you
###20278 would have had to make a platform-specific
###20280 implementation of that.
###20282 Instead, it turns out you can take a canvas tag, and tell
###20285 the canvas tag, hey, canvas tag.
###20287 Capture the pixels that I'm displaying in that
###20289 video tag right now.
###20292 We hooked up to a JavaScript timer that tries to capture at
###20296 30 FPS, or as fast as it can, really.
###20301 And then we ran into some other problems, like we can't
###20303 write the frames to disk from the JavaScript environment, so
###20308 our intern wrote a Python server that we've talked to
###20311 using web circuits.
###20313 And then the Python server writes them to disk.
###20315 It's a bit more [INAUDIBLE].
###20317 So after running this, you end up basically with a couple of
###20322 hundred of image files on disk.
###20323 And then we run a small tool to consolidate those
###20326 into one YUV video.
###20328 That is raw video.
###20331 All right.
###20332 But there's still some problems, like we have no idea
###20336 where the video starts.
###20337 Like when we run the tests, we don't know where we'll start
###20340 and end the video because the driver is just going to loop
###20342 it over and over.
###20345 Since the algorithms I talked about, they're only going to
###20348 compare frame to frame, and give you a score.
###20350 You need to compare the right frame in the output video with
###20353 the right time in the input video.
###20355 Otherwise, you're going to get the wrong score.
###20358 Even if you solved that synchronization problem with
###20360 the camera driver, what if we dropped the first two frames?
###20364 Then we would compare frame and the output video with
###20367 frame and minus two in the input video.
###20368 The score would be very much punished for something the
###20372 user wouldn't have noticed.
###20372 So that's not good.
###20375 If the JavaScript happens to not capture all the frames,
###20378 because I sure don't know hard to predict how fast
###20381 JavaScript will run.
###20382 
###20386 The trick is to encode barcodes into the input video.
###20391 So you can see a bar strip at the top there.
###20394 It is going to move along with the video.
###20396 You see three examples of the video here because this is
###20398 what our test looks like.
###20400 What's going in, what's coming out from the other side, and
###20402 the camera is keeping up capturing the stuff there.
###20405 
###20409 How will that help us?
###20410 Well, it will make it able for us to encode a unique ID in
###20415 each frame in the input video, and then later find out which
###20419 frame we actually capture on the other side.
###20422 The encoder user uses--
###20424 I'm going to go quickly through these details-- so the
###20427 encoder uses a library called Zebra Crossing.
###20430 It can generate barcode for us.
###20434 So we generate a bunch of barcodes in rising numbers,
###20436 like one to whatever.
###20439 Then it uses an ffmpeg to convert those to YUV.
###20442 Then combine the YUVs to a barcode movie.
###20445 So that's going to be a very narrow movie with a moving
###20447 barcode in it.
###20449 And then we can stitch that together with an input file of
###20452 our choosing and create a video such as the
###20456 one we saw over here.
###20457 
###20461 Our setup of the feed that we do into a fake webcam.
###20465 Have WebRTC acquire that webcam.
###20468 Then we also test that our device acquisition code, and
###20472 all that stuff, works for the operating systems.
###20476 We capture what we get on the receiving side with the video
###20479 camera thing I talked about.
###20481 Decode the barcodes, and then we analyze it.
###20484 The analysis step is the next slide that I'm
###20487 going to talk about.
###20487 First, the barcode decoder.
###20489 What does the barcode decoder do?
###20491 It takes the YUV movie we produced in the capturing
###20495 step, splits that into a bunch of PNG files, because that is
###20499 all Zebra Crossing understands.
###20501 Again, using ffmeg, run it through Zebra Crossing and,
###20504 then we've got a bunch of numbers.
###20506 So our tools is going to produce
###20508 a file called Stats.txt.
###20510 That is a mapping for each frame in the output video,
###20513 what is the corresponding frame in the input video?
###20517 That is used in the final analysis step here.
###20520 So now we have this thing that takes the original video, the
###20524 captured video, and that mapping.
###20527 And then it's just going to run PSNR and SSIM on each
###20530 frame, using the map [INAUDIBLE] that's .txt.
###20533 
###20538 What we end up with is something like this.
###20542 It is a bit hard to see here in the graph, but what you can
###20545 see in a graph is that first those lines that you see in
###20549 there, that is the distribution of scores.
###20552 So each frame is scored individually.
###20555 And then the big thick line in the middle, that is the
###20556 average for that particular run.
###20559 What you can also see, or maybe not, is that we are
###20562 around four to six decibel peak signal to noise ratio,
###20566 which I would say is reasonable for internet
###20569 transmitted video.
###20571 The big dip on the right there, by the way, is our
###20574 regression, it looks like.
###20577 And when it goes back up again, that is where the
###20581 regression was rolled back.
###20582 
###20585 For the structural similarity, similarly, we get consistent,
###20589 I think, about 0.926 out of one in the score.
###20594 
###20598 When we put the whole thing together, we end up with that.
###20605 As you see, it's a fair amount of stuff in there.
###20607 The parts I mentioned earlier, like you have your input video
###20612 that you just need to prepare and encode once.
###20614 And then when you run your test continuously, you feed
###20617 the same video into the webcam, and you run the tests,
###20622 as in our case.
###20626 And then you do the necessary conversions so that you get
###20629 the YUV file.
###20630 And you decode the barcodes.
###20632 And you end up with something you can analyze, and produce a
###20636 score from that.
###20637 
###20639 So that concludes my talk.
###20641 Thank you for you time.
###20644 [APPLAUSE]
###20649 TONY VOELLM: Thank you, Patrik.
###20651 So if you have a live question, you
###20654 can go to the mic's.
###20655 I see somebody up there.
###20656 And then we can also pull from the Dory.
###20658 So why don't we go live first, please.
###20660 AUDIENCE: Hi.
###20660 So a question about the output frames.
###20663 Does it ever happen that you lose output frames because you
###20665 couldn't decode the bar coding where the video quality is so
###20669 low you can't decode it?
###20670 PATRIK HOGLUND: Yeah, so it hasn't happened
###20674 very much for us.
###20675 When it has happened, it is because WebRTC is completely
###20678 broken and the CSS rendering black or garbage or whatever.
###20681 So if the image gets so distorted that even the
###20685 barcode library can decode the barcodes, then the image is
###20687 probably completely broken.
###20690 So that is the conclusion you can draw from that, really.
###20692 
###20694 TONY VOELLM: Let's pull one from the Moderator here.
###20697 Do you test AV sync issues?
###20699 If yes, how do you do it?
###20703 PATRIK HOGLUND: No, we don't.
###20705 So I guess that answers that question.
###20707 No, but I mean that is almost maybe something you can extend
###20711 the test to.
###20713 And by the way, there is a tape for all of you here that
###20716 all this code that we have written for this is open
###20719 source and check in through the Chrome repository.
###20721 So if you want to use it, know yourself out.
###20724 So if you want to write something like that, you can
###20725 probably do it.
###20726 TONY VOELLM: Very cool.
###20727 Let's take another one here.
###20728 Are you able to measure the video quality while streaming
###20731 at various network conditions?
###20734 PATRIK HOGLUND: No, but we would love to
###20736 be able to do that.
###20739 Presumably when you have a lot of packet loss or a burst of
###20744 packet loss or a lot of delay or whatever, you would expect
###20748 the bandwidth estimation algorithms to adjust
###20749 accordingly.
###20750 And then you should see probably that,
###20752 OK, 2% packet loss.
###20754 Well then we got maybe 34 in PSNR or whatever.
###20756 And nothing can keep your stuff
###20758 working for all the customers.
###20760 And I think this is something people don't do enough of.
###20763 Verifying that, OK, it looks great on Google's office
###20768 network, but it will not work in an ADSL line
###20771 in India, for instance.
###20772 So we have plans for that.
###20775 TONY VOELLM: Interesting.
###20776 We have time for one more live question.
###20778 I think you got up here first, or did you?
###20781 Toss up.
###20782 OK, left.
###20784 Please, what's your name, where do you
###20786 work, and your question.
###20787 AUDIENCE: I'm [INAUDIBLE].
###20788 I'm from Amazon.
###20790 So the question I had was why barcodes?
###20792 You might as well have written numbers in there.
###20796 PATRIK HOGLUND: Yeah, absolutely.
###20798 Well, we had a library for it, like I said, Zebra Crossing.
###20802 And I think barcodes are relatively resistant to normal
###20805 artifacts when you encode and decode a video.
###20808 I mean, we don't want that to be flaky.
###20810 And it has turned out to work very well.
###20812 TONY VOELLM: If they had used numbers, then they would have
###20815 had a Cookie Monster instead of zebra.
###20818 
###20820 OK, thank you, Patrik.
###20824 Thank you.
###20824 Thank you, Patrik.
###20825 PATRIK HOGLUND: Thank you.
###20825 [APPLAUSE]
###20829 TONY VOELLM: Got ahead of myself.
###20831 Actually next up is going to be Minal Mishra from Netflix.
###20834 And he's going to talk about when bad things happen to good
###20838 applications.
###20839 
###20843 MINAL MISHRA: Thank you.
###20845 Good afternoon, everyone.
###20847 I hope you can hear me all right.
###20849 I'm Minal, and I've managed a few of the key
###20853 platforms in Netflix.
###20854 
###20857 To start off, did everybody know that
###20860 yesterday was Earth Day?
###20861 So happy Earth Day to everyone.
###20864 I'm going to use Earth science to kind of introduce my topic.
###20870 So let's start with what makes Earth a
###20873 successful life system?
###20875 
###20878 One of the most widely accepted
###20879 theories of plate tectonics.
###20882 Plate tectonics, for the uninitiated, is basically
###20887 large scale movements in the Earth's lithosphere.
###20889 
###20892 It is not limited to just the formation of mountain ranges
###20895 and ocean trenches, but it also postulates that it is
###20900 very essential for life to succeed on Earth.
###20904 Some of the tasks that are accomplished by tectonics are
###20909 replenishment of depleted nutrients, generation of
###20913 magnetic field, which prevent the violent solar wind from
###20917 affecting Earth, and stabilizing the temperature of
###20921 the planet by recycling carbon dioxide.
###20926 So what is the similarity between a successful life
###20931 system and a successful software application?
###20934 
###20937 A successful software application needs to adapt and
###20943 constantly innovate, depending on market demand.
###20946 This means that there is constant change in every layer
###20951 of the stack.
###20952 And haven't we all seen that?
###20955 With the success of the mobile platforms, we know that these
###20960 platforms need to constantly and rapidly innovate.
###20963 
###20966 But every coin has a flip side.
###20971 So does this churn.
###20973 In the case of life supporting plate tectonics, we have seen
###20978 catastrophic side effects, like volcanoes, landslides,
###20982 earthquakes.
###20984 And while we have come to accept these side effects, we
###20988 have also made tremendous progress in the technologies
###20992 that are used to determine and drive these events with high
###20997 rate of accuracy.
###21000 Thankfully, we in the software industry don't have to deal
###21002 with anything of that magnitude.
###21004 
###21006 But software development, the dynamics, go hand in hand with
###21014 its own side effects that we refer to as bugs.
###21018 And we have gone and developed a lot of systems that help
###21023 catch these bugs sooner than later.
###21025 I'm going to talk about one said system that, at Netflix,
###21029 has helped us catch these bugs, which is
###21032 our endurance systems.
###21034 And I will basically also explain, discuss some case
###21040 studies which will help me illustrate how bad things that
###21044 are out of your control can affect a good application.
###21049 So let's start with what is the motivation behind
###21054 endurance test for a consumer application?
###21058 
###21060 The user expectation, right?
###21063 We all, as users, have began to use mobile applications
###21068 rather than website, because of the magical experience
###21072 offered by it with greater performance.
###21074 
###21077 The performance of application, again, varies
###21079 from platform to platform and also on the application
###21083 architecture.
###21086 We also face unpredictable user behavior where user
###21089 behavior might invoke code path that might affect the
###21093 performance of the application.
###21096 And finally, for a media applications like Netflix
###21100 where users spend at least 30 minutes--
###21103 we don't have TV shows which are shorter than that--
###21107 a simple memory leak can lead to suboptimal experience for
###21111 our consumers.
###21114 So like every other automation team, we went ahead and built
###21120 a functional automation system.
###21123 The architecture that you see here is very similar to a lot
###21127 of the client automation architecture that are
###21130 available today.
###21131 However, we built a custom in-house solution basically,
###21139 which could scale to multiple different platforms that our
###21143 application is available on, and also build reusable parts.
###21147 So certain platforms use certain parts.
###21150 But overall, this is the architecture of one such
###21153 platform using those reusable parts.
###21156 
###21159 And of course, with the continuous integration mantra,
###21163 we put our functional test behind the continuous
###21166 integration system on Jenkins.
###21168 
###21171 The thing with the custom solution was that it was
###21174 modular enough that we could basically develop endurance
###21179 tests on top of the system with minimal effort.
###21182 And then with the power of Google Spreadsheet, we were
###21186 able to build a reliable endurance reporting system.
###21189 
###21193 Obviously, we are a client automation team.
###21195 We don't want to deal too much with databases,
###21197 server, and the cloud.
###21199 So why not use Google Spreadsheet?
###21202 So what do we measure?
###21204 We basically split performance counters into three parts.
###21209 Platform specific, which is memory utilization of the
###21214 platform itself, CPU utilization metrics that is
###21218 provided by platform.
###21220 The second being video playback statistics where we
###21223 measure things like the playing video bit rate and
###21226 audio bit rate, which is again dependent on network
###21229 conditions and the hardware itself that you're
###21233 playing back on.
###21234 The frames rendered dropped.
###21236 The buffer size, which is important.
###21239 And rebuffer count, which is really important from a
###21241 consumer perspective, since it determines the quality of
###21244 experience.
###21246 The third piece is, of course, the application metrics where
###21251 we measure start up time for the application.
###21253 In order to give a good consumer experience, you need
###21256 to have faster start up times.
###21257 And we also measure certain transition times between pages
###21262 as the users navigate through them.
###21265 
###21268 So CI for endurance.
###21271 You can see the image right there, which is pulled from
###21275 the performance metrics that you normally
###21278 receive from a car.
###21281 Like a lot of people in the Bay Area where I live, I also
###21284 drive a hybrid car.
###21285 And what I've realized is the continuous feedback on my
###21290 driving performance has helped me become a better driver.
###21293 
###21295 So we took this idea, and we put it for our application to
###21302 continuously measure the performance of our
###21304 application.
###21306 This also ensured that performance is treated as a
###21309 feature and not as an afterthought.
###21312 And for the test team's benefit, we can then ensure
###21317 that our endurance tests are current.
###21318 
###21322 But you know what they say about old habits.
###21325 They die hard.
###21326 I realized that when I came back from a long vacation and
###21330 I began driving my car, I easily slipped back into the
###21334 old bad habits.
###21335 And I felt that having looked at my performance train over a
###21340 period of time, I could easily correlate the mistakes that I
###21345 was making with the trends and be easily
###21350 able to remember them.
###21351 
###21354 So we decided to build trend shots on top of our continuous
###21357 integration for the endurance tests where we use simple
###21361 statistical functions to kind of track progression over
###21366 build for the different performance counters.
###21370 And we looked out for the statistical outliers.
###21372 
###21376 Using this system, we were able to find several bugs that
###21381 were introduced by our developers.
###21383 But to justify the title of this talk, I'm going to talk
###21389 about two such case studies where we found issues using
###21394 this system that were not introduced by our developers.
###21399 The first one, last year, Netflix realized that the API
###21406 service that delivers data to hundreds of different devices
###21410 needed to be rearchitected.
###21412 The main reason behind that was the fact that one size
###21418 fits all model could not work with low power devices.
###21423 So the direction that we moved to was giving the controls to
###21430 the devices to be able to tweet the response so that you
###21435 get just enough response data to render a
###21438 rich UI for your platform.
###21439 
###21442 As I mentioned before, we were tracking the start up times on
###21449 our platform over different builds.
###21452 And this chart over here basically shows you the
###21455 different start up times to the different experience that
###21459 you might launch into.
###21460 One is the regular experience and the other is the kids
###21464 experience.
###21466 What we realized is, after a point, once we switched to the
###21470 new version of the API, the start up time to the kids
###21476 browse screen increase by about 25%.
###21480 And we were able to look at this build and immediately
###21483 notify our partner team.
###21485 And over a period of time, we were able to fix it before it
###21489 actually affected our end consumers.
###21493 The next example is even more scary.
###21496 Because we got notified of this issue three days before
###21502 our release.
###21504 This was a release that was scheduled in December when we
###21507 were releasing a ton of promotional features for our
###21510 new original series, "House of Cards." It's a great show, if
###21515 you haven't seen it.
###21518 So the other thing that we also do is, like I showed in
###21523 the application stack itself, like we are dealing with
###21527 bleeding edge services.
###21528 We also deal with the bleeding edge ADK from our partners.
###21533 So like a good consumer of the platform ADK, we were the
###21544 first one to take the ADK version.
###21547 The top graph basically shows you the application memory
###21550 that is provided by the counters in our application.
###21554 And it kind of remained consistent over
###21556 the last six months.
###21557 You can see it's kind of remained flat in terms of how
###21559 much memory it is utilizing.
###21561 The bottom chart shows you the available native memory, which
###21566 is the counter provided by the system, which tells us how
###21571 much memory is remaining.
###21572 And you can see, as we switch to the new version of the ADK,
###21578 you can see the mountain ranges are there where there
###21582 were times when memory hit rock bottom.
###21584 And there were times when it remained constant.
###21587 But while testing this, we found a functional bug, which
###21590 was more worrisome where the playback would crash every
###21599 time you changed the audio stream, which is a big deal
###21603 for our customers.
###21604 And we realized we were able to track this
###21606 bug back to the ADK.
###21608 So we reverted back to the previous version of the ADK,
###21611 notified our partner, and went ahead with our business.
###21615 Three days before the release, the partner comes back to us
###21618 and tells us that the bug has been fixed and you can
###21623 go and adopt it.
###21624 So we said, OK, we'll test it out.
###21626 Everything worked fine.
###21627 Functionality, the application looked really good.
###21631 But what you see out here is that the native memory
###21634 consistently hit rock bottom.
###21636 So these are tests.
###21638 Endurance tests are tests which run for two hours over
###21641 our platform.
###21642 And most of our functional tests gets
###21643 done within 30 minutes.
###21645 So the memory leak over here manifest itself after one hour
###21648 of video playback.
###21650 And as a Netflix consumer, you know there are no movies which
###21654 are less than one hour long.
###21655 So we were able to track this down to an ADK.
###21660 Again, we reverted back and shipped the version in time.
###21666 The key takeaway that we have over here is basically any
###21671 form of test that you're developing, whether it be
###21673 functional integration or performance test, make sure
###21677 you're consistently running it and analyze the result that
###21681 you get out of these tests.
###21684 With these thoughts, I would like to end the talk with the
###21687 quote from Robert Allen, which has a bigger meaning in life,
###21690 but I think it's still appropriate
###21692 for the test community.
###21694 Thank you.
###21695 [APPLAUSE]
###21701 TONY VOELLM: Great.
###21702 Thank you, Minal.
###21705 That's an old adage.
###21706 If nothing's running, it doesn't use any memory.
###21707 So that's a good learning.
###21710 I think we have time for one question.
###21715 I don't see any live questions just yet.
###21717 We'll wait for the Dory.
###21719 If there's a good Dory question, I'll pick it.
###21721 Otherwise, we're going to go into a break right after this
###21724 until 3:45.
###21726 And then we have two very interesting talks-- one from
###21730 academia and one talk that has influenced many
###21734 of the others here.
###21737 So let me see this Moderator question here.
###21742 It says, do you include any testing parts into your
###21746 product delivered to end users?
###21749 What statistics do you get from the apps on end users'
###21753 devices, and how do you deal with that huge, I suppose,
###21757 amount of it?
###21758 And if the lawyers are not here, it's OK.
###21759 Don't answer that.
###21761 
###21763 MINAL MISHRA: Yeah, basically we do a
###21765 lot of end user testing.
###21767 We do instrument our client applications with a lot of
###21772 information that gets logged into our service.
###21775 We have a huge cloud-based system, which basically
###21779 collects all this data.
###21780 And we basically process this data in a distributed cloud
###21785 platform to kind of get an analysis of what our users are
###21790 going through.
###21791 Because it's very hard for you to test all the cases.
###21795 And the best way to test it is by testing it in production.
###21798 TONY VOELLM: Great.
###21800 And with that, thank you.
###21801 We'll be back in seat at 3:45.
###21804 So I will see you then.
###21805 Thank you.
###21805 [APPLAUSE]
###21810 [MUSIC PLAYING]
###23621 TONY VOELLM: Hello.
###23622 Hello and welcome back.
###23625 We have two more talks today, very fascinating talks that
###23629 are coming up.
###23632 This first talk is from academia.
###23634 And we have a couple of talks from academia, here.
###23638 This next speaker is Tao Xie.
###23641 And he is from North Carolina State University and will be
###23644 talking about testing for educational gaming and
###23647 educational gaming for testing.
###23650 And one nice little fact is he is actually a UW alumnus, so
###23654 he is a dawg, D-A-W-G. So with that, thank you.
###23658 
###23660 TAO XIE: Thank you, Tony.
###23662 Good afternoon.
###23664 Next, I'm going to talk to you about some recent work in
###23668 collaboration with Microsoft Research, including Nikolai
###23671 Tillman, Jonathan De Halleux, along with Judith Bishop.
###23677 That theme would be about the synergy of testing and
###23681 educational gaming.
###23685 On the testing side, I will talk to you about the dynamic
###23688 symbolic executions incorporated in the tool
###23691 called Pex, from Microsoft Research, along with
###23694 parameters unit testing as a way for you to incorporate
###23697 behavior checking for your testing.
###23700 And then, with this foundation of technology, we have these
###23705 games, Pex For Fun, as a way for you to teach students or
###23710 teach yourself about different kinds of skills, including
###23714 software testing skills.
###23716 In the rest of the talk, I will basically give you the
###23718 background, first, on the testing.
###23720 And then we'll move on to educational gaming.
###23724 Particularly, I will give the background.
###23725 And then I will give you a little bit brief introduction
###23729 of writing code, in the browser, in your favorite
###23733 browser, of your choice.
###23735 And then I will talk about a gaming type of coding do's, in
###23739 the Pex For Fun website, and further discuss how we could
###23742 leverage such gaming types in educational settings,
###23747 including teaching and learning, and then
###23749 conclude the talk.
###23750 
###23753 Here's a screen snapshot of the tool, Pex, released by
###23757 Microsoft Research.
###23759 It's a publicly available tool.
###23761 The URL is near the bottom of the slides.
###23766 Basically, it's a plugin for Visual Studio.
###23769 Currently it supports different kinds of Dot Net
###23772 language, including C Sharp, Visual Basic, and F Sharp.
###23777 Like here, basically, it's very easy to for you to use.
###23781 Install the plugin, and then you could, just several mouse
###23784 clicks for you to generate a set of test inputs, as
###23787 displayed near the bottom on the Visual Studio window.
###23793 Let me give you a little brief overview of the key
###23796 technology, called dynamic symbolic execution, in Pex,
###23799 how we could generate test data automatically to achieve
###23803 high code coverage.
###23804 On the side, I have this very simple piece of code.
###23808 That's a code in the test.
###23809 As you can see, the inputs would be an integer array.
###23812 And then inside, we have three conditionals.
###23816 The first one, checking whether the array is a null
###23819 pointer, and then the second one, checking whether the
###23821 length is greater than 0.
###23823 And then the third one is checking whether the first
###23825 element is equal to that very big number.
###23827 In that case, we will throw an exception to indicate a
###23831 potential bug in that particular code location.
###23835 Dynamic symbolic execution was proposed back in 2005 and,
###23840 these days, have been incorporated in different
###23842 kinds of testing tools, including security testing
###23845 tools, along with Pex.
###23847 Dynamic symbolic execution will start with a default
###23851 input for the argument or [INAUDIBLE]
###23853 selected or randomly selected input value.
###23856 For this case, we could just use a default value as a null
###23860 pointer for the integer array.
###23862 We execute the program, being instrumented with additional
###23866 code, to collect runtime information, particularly
###23870 which path this test execution would tranverse.
###23873 And what constraints on the inputs do we need to satisfy
###23877 in order to tranverse that particular path.
###23880 As we could see, if execute a null pointer, we would
###23883 tranverse the true branch of the first conditional.
###23886 At the same time, we collect the constraints, record as a
###23889 past condition, as a equal to null pointer, after we finish
###23893 the execution.
###23895 Next, we want to generate new test data, right?
###23897 Because we want to excise different
###23899 behaviors of the code.
###23901 How to do that?
###23902 We picked an already collected past condition and
###23907 negate part of it.
###23908 In this case, it's simple, because we have only one
###23911 constraint.
###23911 We negate it.
###23912 We have a not equal to null pointer.
###23915 We fit these new constraints to a constraint solver or a
###23918 [INAUDIBLE] improver.
###23920 The constraint solver would give us a concrete input value
###23924 that would satisfy this particular constraint.
###23927 For this case, it's easy.
###23929 We could see, we just need an empty array to satisfy the
###23934 constraint, that array is not null.
###23938 Then we further execute the program with
###23940 this new input data.
###23942 Further, we can see now, we reach the second conditional.
###23946 And we take the fourth branch, because a.length now is equal
###23951 to 0, not greater than 0.
###23953 Similarly, in the next iteration, we negate part of
###23956 the constraint, in this case, a.length greater than 0.
###23961 We fit the new constraint to a constraint solver.
###23963 We get the new concrete inputs as one array
###23968 with only one element.
###23969 That element is equal to 0.
###23972 With this new input, we further go through
###23974 the process we have.
###23976 In this particular case, we now reach the last
###23979 conditional.
###23980 But the first element of the array is not
###23983 equal to a big number.
###23984 It's equal to 0.
###23986 So we next would negate the last
###23989 constraints of the path condition.
###23992 Finally, we fit the constraint to the constraint solver.
###23995 We get this big number in order to trigger the exception
###24000 throwing statement.
###24002 For this particular simple example, we are done, because
###24005 we actually explored all the paths in this simple program.
###24010 In reality, many real world applications of software and
###24014 their tests wouldn't be that simple.
###24016 We may have an infinite number of the paths or, at least, a
###24020 huge number of the paths in the code.
###24022 We need to have some advanced technologies, including those
###24026 incorporated into Pex, to deal with those complicated
###24029 situations.
###24029 In this talk, I'm not going to go into the details about
###24032 these technologies.
###24034 But the basic idea of dynamic symbolic execution is,
###24037 actually, what I described.
###24038 
###24041 So far, we focused on crashing or exception throwing
###24046 situations, in the previous example.
###24049 We know, if you want to assure high quality assurance, in
###24053 terms of a functional correctness, only catching
###24056 this crashing or robustness issues may not be enough.
###24059 We need to go one step further to write down some strong
###24063 enough assertions in order to catch these, like a functional
###24067 correctness box.
###24068 To do that, we could leverage parameterized unit testing,
###24072 which is a methodology to help you to engage developers and
###24077 test generation tools to work together, in order to exploit
###24081 the best out of this test automation.
###24084 In conscious conventional unit tests, which do not have
###24089 parameters, right?
###24090 When you write unit tests, you don't have parameters.
###24092 You just write some test methods, and then you execute
###24095 the body of the test methods.
###24097 But in parameter unit testing, a unit test has parameters
###24101 like the one I put on the slide.
###24104 As you can see on here, we have two parameters, list and
###24110 an integer item.
###24112 The body of this unit test is testing adding an element into
###24116 a list to see whether the count of the list has been
###24120 increased by one.
###24121 Very simple behavior.
###24123 How do we do that?
###24124 How do we check the behavior?
###24127 Next, we would put several lines of code, very similar to
###24130 what you have been doing in traditional unit tests.
###24134 Basically, you write down the method call that you want to
###24136 test, and then you write all the assertions that you want
###24139 to check the behavior.
###24142 Keep in mind here, the assertions that you are
###24144 putting here need to be general enough to deal with
###24148 all different kinds of argument variables coming in.
###24151 Not just hard-coded like 10 or 20, or push one element to an
###24155 empty list, that kind of specific situations.
###24159 To allow you to write these kinds of general properties as
###24164 assertions, we have a specific kind of construct called
###24168 assumptions, which may not exist in
###24171 conventional unit tests.
###24172 Basically, you could [INAUDIBLE]
###24174 in this case lists not equal to a null pointer.
###24177 Otherwise, as you can see, we will throw exceptions in the
###24180 body of the unit test.
###24183 As you can see, for this kind of parameter unit test, we
###24188 basically separate two constraints, two concerns,
###24191 more precisely.
###24193 First, we want developers to write down what you really
###24196 want to check, the behavior checking of the sequence of
###24200 the method calls along with the assertions.
###24203 Then we allow test generation tools like tests to generate
###24208 high quality test data, to excise different portions of
###24212 the code, if possible, violating the assertions that
###24215 you put down there.
###24216 So it's a nice way of separating the concerns of
###24220 these two parts, one being done by humans, the other
###24223 being done by test automation.
###24224 
###24228 Actually, parameter unit testing or parameter unit
###24230 tests have been supported by quite different testing
###24233 frameworks, like including different kinds of .NET
###24236 testing frameworks along with JUnit 4 or beyond for the Java
###24243 unit testing.
###24245 The parameter unit testing would be fully exploited in
###24248 terms of the power in practice when you are using parameter
###24253 unit testing in combination with test
###24256 generation tools like Pex.
###24260 For the .NET programs, we have Pex that I mentioned already.
###24263 For the Java unit testing, we have some tools such as
###24267 Agitar, AgitarOne, for allowing you to use test
###24271 generation for parameter unit tests written by developers.
###24274 
###24277 So far, so good.
###24278 Today, we already listened to quite some talks engage in so
###24283 many different kinds of testing tools, including the
###24285 one that I just described, Pex.
###24289 But after the talks, or like in our typical scenario, when
###24293 we get tutorials at industry contexts or academic settings,
###24298 then quite some audience may not have the exact tools
###24301 installed on their laptop.
###24303 After the talk, after the tutorials, they may not
###24306 actually expend the effort to install the tool
###24309 and try out the tool.
###24310 So that's an issue we have been observing.
###24312 So without actually seeing how things are, what kind of
###24317 benefit you would get, they may not bother to install
###24320 different kinds of tools in their environment.
###24322 So that's an issue that we commonly observed in terms of
###24326 tool adoption.
###24328 My collaborators at Microsoft Research have a similar
###24331 observation to how to deal with that.
###24334 They basically put the tool online, not just putting the
###24337 tool online or downloading, actually making the tool
###24340 useable within a browser.
###24342 So that's how the Pex for fun website would come into place.
###24346 Actually, if you had a mobile device or laptop or your
###24350 desktop, you could actually enter the URL pex4fun.com and
###24354 try things out to get the sense of what benefits you
###24358 could get with the power of test
###24359 generation underlying Pex.
###24363 Here's the website, a screen snapshot.
###24365 As you can see, in the middle, you can enter the source code
###24369 that you want to test and a particular name, like puzzle,
###24372 with certain parameters.
###24373 You can view that piece of code as a parameter unit test.
###24377 Then you just click the button near the middle left hand
###24381 side, Ask Pex.
###24383 Then Pex will generate test data and send back the test
###24387 data to the browser being displayed to you near the
###24390 button of the web page.
###24392 So that's a basic functionality of this website.
###24396 It can allow you to quickly get a sense of what this tool
###24400 could do for you.
###24401 I think that kind of an experience could be borrowed
###24405 by many other tool vendors or other tools in terms of giving
###24408 people a quick overview of what their tools
###24411 could do for them.
###24414 But indeed, there has to be some limitation on the browser
###24419 version of the tool.
###24420 For example, the total length of the code in the test might
###24424 not be too long.
###24426 You only have one file being copy-pasted in that browser
###24430 text box for the code in the test.
###24432 Single-threaded.
###24434 No environment interaction, such as you cannot use FiiO
###24440 network communication, that kind of thing, in
###24442 the code in the test.
###24444 No non-deterministic behavior.
###24448 It will try to avoid floating-point computations,
###24450 which cannot be handled well by existing [INAUDIBLE].
###24455 We also impose this 20-second expiration time for test
###24460 generation when you click the button, Ask Pex.
###24464 But some of these issues are just specific to the browser
###24467 version, not to the--
###24468 like we're use still the plugin version.
###24472 In summary, so far I've discussed the dynamic symbolic
###24474 execution, how it works, and how Pex could be used, and how
###24479 Pex could be migrated to a browser version so that many
###24483 people just open up their browser and then get a sense
###24487 of what it could do for you.
###24488 
###24491 In order to make this browser version really usable, to have
###24495 similar user experiences as they were doing within their
###24500 typical IDE, for example, VideoStudio, my collaborators
###24505 in Microsoft Research put a lot of effort in creating
###24509 these nice features, such as auto code completion, when you
###24513 just type in, for example, console.w, it would pop up
###24518 some suggestions for the method that you want to put
###24522 in, along with a description of these API methods.
###24525 Very nice features, it just allows you to feel the similar
###24529 experiences as in the normal, typical IDE.
###24534 So basically, for this kind of a browser version of the tool,
###24537 you could leverage the cloud to do the computation, do the
###24542 test generation.
###24543 And you use the browser as the front end for the user to
###24549 enter the code they would like to test and then also use the
###24552 browser to display the test data being
###24555 generated back to the users.
###24556 
###24559 So far so, good.
###24560 We have Pex, and we have the dynamic symbolic execution
###24565 incorporated in Pex.
###24567 My collaborator at Microsoft Research put this Pex for fun
###24570 website so that you could play with it.
###24573 But think about it.
###24575 Unless you are really like a geek, otherwise you wouldn't
###24579 come back to this website.
###24580 Like, oh, every now and then, you just type in some code and
###24583 click the button and say, oh, how fun it is.
###24585 Or you generate strong forward detection capability, like in
###24591 terms of test data, and then you play it again and again.
###24594 I mean, I think few people would do that.
###24597 Then we think about how we could leverage this websites
###24600 and the test generation to do something more fun and more
###24606 useful in our world and life.
###24608 That's how the coding duels come into the picture.
###24611 It's a major game type for Pex for fun website.
###24617 So far, for the coding duel game type, particularly for
###24622 the Ask Pex button, basically you click one time of Ask Pex
###24627 button that will indicate one iteration of gameplay.
###24632 About one month ago, we had more than 1.1 million of the
###24637 clicking the button.
###24638 So many people around the world are using this website
###24643 to do a different kind of thing, like particularly for
###24646 learning while having some fun.
###24648 Or it's being used in a classroom setting.
###24650 
###24653 Let me give you some idea on what a coding
###24655 duel would be like.
###24656 And the ideas are very simple.
###24659 For a game creator like myself or actually anyone around the
###24664 world, you could create a secret implementation on the
###24669 right hand side.
###24670 Basically, you write a very simple piece of code.
###24673 And then you also release [INAUDIBLE]
###24676 of the secret implementation.
###24678 Then the players would need to complete or finish the player
###24685 implementation so that the player implementation would
###24689 have the exact same behavior as the secret implementation.
###24694 And you would say, I cannot see the secret implementation.
###24697 How could I type in the code to make the behavior the same
###24700 as the underlying secret implementation?
###24703 It's mission impossible.
###24705 That's how aspects of Pex come into the picture.
###24709 Pex would give you feedback to tell you under what inputs you
###24713 have the same behavior between these two versions, under what
###24716 inputs you have different behaviors.
###24719 In addition, Pex would be the judge to determine whether
###24723 these two implementations have the same behavior.
###24726 Let me use an example to walk you through.
###24729 On the left hand side, I already created a secret
###24734 implementation, a very simple one, recursion function.
###24738 On the right hand side, I release to the player with the
###24741 player implementation basically the anti-one.
###24744 You just return x.
###24747 Then when the user, the player, tries to play this
###24751 game, first, the player would click the button Ask Pex.
###24755 Because without any hints, the player has no clues on what
###24759 directions the player needs to modify the code.
###24763 Then after the player clicks the button Ask Pex, behind the
###24767 scenes, we actually have this test driver being synthesized.
###24772 It's more like a parameter unit test.
###24775 You have the input argument the same as the signature of
###24779 the two implementations.
###24782 But we construct a new branch there saying that if the
###24786 return value of the secret implementation is not equal to
###24789 the value of the player
###24791 implementation, we throw an exception.
###24793 As you can see, dynamic symbolic execution will try to
###24797 cover all feasible paths, of course, all feasible branches.
###24801 And if possible, Pex, or dynamic symbolic execution,
###24804 will fire test input to cover that branch.
###24808 What does that mean?
###24809 If you can cover that branch, it means that you have at
###24813 least one test input to cause the behaviors of the two
###24816 implementations to be different so that you have a
###24819 failing test.
###24820 So in reality, if you click the button for these two
###24824 implementations, you will see the table displaying two
###24829 passing tests and one failing test.
###24832 Basically, we are saying that if your argument value is 1,
###24836 the written value is 1 for both implementations.
###24840 2, similar thing.
###24841 The return value will be 2 for both implementations.
###24843 But if you have input value as 3, the secret implementation
###24848 will return 6 in cell 3 which would be returned by the
###24852 player implementation.
###24854 So as you can see, as a player, when you see this kind
###24859 of feedback, you try to modify, you try to do some
###24862 generalization, objection, reflect on how would you
###24866 modify the code implementation so that you could satisfy the
###24871 constraint of the three test inputs.
###24873 Basically making the passing tests still pass, but making
###24877 the failing test also pass.
###24880 We use this kind of gaming with middle school students.
###24884 We see very interesting behavior there.
###24887 They may just say focus their energy on the failing test
###24890 without thinking about making the passing first two parts of
###24893 the test also pass.
###24895 More like overthinking the [INAUDIBLE]
###24897 solving in their mind.
###24901 So to summarize these coding duels, basically we provide
###24905 these kind of fun and engaging experiences by allowing the
###24909 user, the player to have this iterative gameplay over time
###24914 by clicking, asking Pex over time when they change the
###24918 player implementations based on the feedback.
###24921 The feedback is adapted and personalized.
###24925 Like you play the same again.
###24927 You may write down different a player implementation, make
###24930 different revisions.
###24931 Then the feedback you are getting would be different
###24934 because dynamic symbol execution, or Pex, would
###24937 leverage both the player implementation and the secret
###24940 implementation to generate specific tests to show the
###24944 differences or the commonalities of the behavior.
###24948 It's very difficult to do cheating.
###24950 You may say, oh, because earlier, I mentioned that
###24955 floating-point computation would not be good for
###24957 [INAUDIBLE], so let's just put a bunch of floating-point
###24959 computations there to fool Pex or fool dynamic symbolic
###24963 execution, that would not work well.
###24964 It's very difficult to defeat that.
###24966 In theory, you could.
###24967 But in practice, it's very difficult to cheat.
###24969 We have very clear winning criterion.
###24972 Basically, as long as Pex cannot generate a failing
###24977 test, then you win the game.
###24980 We have quite some users posting their feedback and
###24986 their experience online.
###24986 I'll just read you some of the interesting ones.
###24989 "I used to love the first-person shooters and the
###24993 satisfaction of blowing away a whole team of noobies playing
###24996 'Rainbow Six,' but this is far more fun." The user was
###25001 referring to playing Pex for fun.
###25004 The second one, apparently, as you could guess, the second
###25007 one is a professional, rather than a student.
###25011 "I'm afraid I'll have to constrain myself to spend just
###25014 an hour or so a day on this really exciting stuff, as I'm
###25018 really stuffed with work." We don't want to impact your
###25021 normal workload there.
###25023 But on the side, it's good to have some kind of
###25025 entertainment while learning yourself.
###25030 The third one is talking about the learning
###25032 and teaching aspect.
###25034 "It really got me excited.
###25035 The part that got me most is about spreading interest in
###25039 teaching computer science.
###25040 I do think that it's really great for teaching and
###25042 learning." We have many, many more different, very positive
###25047 feedback from the users.
###25050 And recently, like two years ago, we had this coding duel
###25057 competition at our major software engineering
###25059 conference, International Conference on Software
###25062 Engineering 2011.
###25064 And we provided these 30 coding duels for the
###25069 conference attendees including students and researchers.
###25073 As you can see, I zoomed in there with one of the coding
###25076 duels, number 10.
###25079 Basically, the green entries would indicate that user
###25084 actually solves the coding duel, wins the coding duel.
###25088 For the red ones, that would indicate the user makes an
###25092 attempt but fails.
###25093 The number there indicated how many attempts the user made,
###25097 basically how many times the user clicked Ask Pex before
###25101 they actually finally got it for the green one.
###25103 Or the red ones, in the end, they still
###25106 couldn't win the game.
###25107 It's very interesting to see for this particular coding
###25110 duel is not that trivial.
###25112 As you can see, we have one user solving
###25117 the game four times.
###25118 That's very good, four times actually got it.
###25122 But we can see the other had 147 times and finally got it.
###25127 You could reflect that user's really patient or determined.
###25132 It's up to you to judge whether you want to hire this
###25135 person to be you tester or not, right?
###25138 So you could have different interpretations on that.
###25142 But as later I will describe more, another very interesting
###25145 thing for you to see is that as a teacher who would create
###25150 this kind of a game for a student to try, a teacher
###25152 could actually see every single step the
###25156 user actually tried.
###25157 For this particular case, we should actually go inside to
###25160 see for that user with 147, what on earth did this user
###25166 finally got it right?
###25168 Like, what's the turning point, or why do you need so
###25171 many times?
###25171 Or for the fourth one, what is actually the magic happened?
###25175 Four times you got it.
###25177 It's very interesting to see the process besides just
###25180 seeing the end result.
###25183 So to summarize what we talk about coding duels, basically
###25186 it's given a particular secret implementation and an empty or
###25191 incomplete player implementation, we ask users
###25194 to try to improve the player implementation so that the
###25198 behavior would match the secret implementation one.
###25201 The students need to infer the intended behavior of the
###25205 secret implementation that they couldn't see, and then
###25208 they would iteratively try to generalize that behavior to
###25212 the code implementation that they are working on.
###25216 We also have this kind of a social experience to make it
###25219 more fun and engaging.
###25221 We had this live feed.
###25223 Then on the website, you could see at this particular moment
###25227 who are solving what.
###25230 Are they successful, or are they failing and
###25232 still trying very hard?
###25234 It would be fun to watch if you don't have many useful
###25239 tasks at hand.
###25240 Especially when you create some coding duels, to just
###25243 see, oh, who are solving my duels.
###25245 That's an interesting live feed there.
###25249 We also had these rank lists for different users.
###25253 A user could gain some points by creating coding duels for
###25259 other people to play.
###25260 Also gain some points by successfully solving certain
###25266 coding duels.
###25267 We have these kind of rank lists of people around the
###25270 world on this website.
###25273 We had a leaderboard along with other nice features for
###25277 social experiences.
###25278 
###25280 We would like to take advantage of these platforms
###25283 so that we could really get much in terms of the teaching
###25287 and learning, rather than just say I will put it there so
###25289 that anyone who would like to try it out, just try it out.
###25294 To do that, basically we provide
###25298 different kinds of features.
###25299 For example, as a teacher, we could create a course by
###25304 assembling different web pages.
###25307 Like the course page, we already have different
###25309 materials on different topics, testing, along with different
###25313 programming topics.
###25315 Here is a screen snapshot there, basically for the
###25318 teacher, This is like a sample course.
###25322 We can see that on the right hand side, we have this kind
###25326 of dashboard of showing the students' progress on solving
###25331 some exercises in the form of coding duels.
###25334 And in real time, the teachers could look into what kind of
###25339 problem they are facing.
###25340 Are they struggling on a particular thing?
###25342 Or maybe the exercises are not that clear in terms of giving
###25346 students a requirement.
###25348 
###25350 We used coding duels in a graduate
###25354 software engineering course.
###25355 Typically, you would think, oh, this kind of a nice game
###25359 could be used in intro programming courses.
###25363 Indeed, that would be the case.
###25364 For example, if you are teaching LOOP, you could just
###25368 take a certain piece of the loop head out and then ask the
###25373 student to fill in that particular, for example, the
###25376 upper bound of the loop, this kind of thing.
###25379 But at same time, we actually tried it out at a graduate
###25382 software engineering course in terms of teaching them
###25384 specification writing requirements, testing design
###25388 patterns, many different kinds of topics.
###25392 Here's just a screen snapshot of a particular exercise that
###25396 we prepared for training students in
###25398 specification writing.
###25400 As you know, in testing, in order to right very strong
###25404 test articles, you need to write strong properties.
###25408 For the topic of parameter unit testing, to write that
###25413 unit test with parameters, you need to have strong assertions
###25417 of properties to really check the behavior that you would
###25420 want to check.
###25421 So this exercise actually has some natural language
###25425 descriptions of some properties of a
###25427 particular API method.
###25429 And then we ask students to actually translate these
###25433 natural language discussions into some formally checkable
###25437 properties.
###25438 So in this particular exercise, as you can see,
###25441 students may not have much space for guessing because
###25445 it's actually solving the given exercise.
###25448 But the nice thing about it is that you actually get
###25451 automatic grading.
###25453 Both the instructors and the TAs are very happy.
###25456 Because in the end, you just look at, oh, how many failing,
###25460 how many passing into the green
###25462 entries and the red entries.
###25464 And you just calculate the scores, rather than really go
###25467 inside to grade them with tiny details.
###25472 And here is just one example of how we use coding duels for
###25477 teaching testing.
###25479 The code in the test actually is a stack,
###25482 is a boundless stack.
###25484 We create this coding duel by passing in some parameters
###25490 like the elements, array element capacity, this upper
###25493 bound for the stack, and the element which could be the
###25497 element you want to push into the stick.
###25500 Or you want to check whether the stack has this element.
###25502 But we don't know.
###25503 We don't tell you exactly how we are going to use that.
###25506 But earlier, the first two lines are basically talking
###25510 about assumptions we put in.
###25512 And then we have the next four lines describing the setup of
###25517 that stack.
###25518 Basically we just put this array element into the stack
###25522 so that you could allow the test generation to generate a
###25527 particular state for you in this particular setting.
###25531 And then in the end, we put down the assertions we really
###25534 want the code in the test to be checked.
###25538 But we keep the middle empty.
###25541 As you can imagine, the middle part, the empty part, that
###25545 needs to be filled would be about what method on the tag
###25549 you want to invoke on the stack.
###25551 In addition, you may also need to add some assumptions to
###25554 really make sure that the assertion will be passed.
###25558 So if you have interest, you could go to the URL to try it
###25563 out yourself to see the different kind of exercises.
###25565 
###25568 How do you use Pex for fun?
###25569 I already demonstrated some scenarios.
###25573 As we all know, MOOC has been very popular, Massive Open
###25577 Online Course.
###25579 There are at least two major challenges there to make
###25582 things work in MOOCs.
###25584 First, grading.
###25586 If you have thousands or even millions of students, you
###25589 cannot afford hiring TAs to grade these students'
###25593 submissions because typically, they are free in
###25598 terms of the course.
###25600 Then here, if you Pex for fun, you could create exercises and
###25604 get this automatic grading for free as a nice
###25607 feature on the side.
###25609 But indeed, it's an open challenge in terms of like
###25613 addressing cheating.
###25615 If one student just copy-pastes another student's
###25618 solution, they're working on the same duel, we really don't
###25621 have certain controls in terms of that.
###25624 It's an open challenge for many different technologies.
###25628 It can be a useful course assignment in regular course
###25631 situation, both academic settings or industry setting
###25635 for training.
###25636 We have done that in terms of the topics from intro to
###25640 programming or software engineering,
###25642 including testing topics.
###25644 We actually could have these competitions, including
###25648 student competitions and professional competitions.
###25651 We had this experience at ICSE 2011.
###25654 And finally, as I hinted on earlier, it would be very
###25657 interesting for you to actually observe one
###25660 particular player or user's problem-solving process.
###25664 As a recruiter or a company's employees, you want to hire
###25668 some potential employees.
###25671 You want to see how they are doing.
###25673 But basically, you could create some well-designed
###25676 coding duels for them to solve.
###25678 Not only seeing how many attempts they are making, you
###25680 see the problem-solving process.
###25682 They're kind of similar to what you typically would do
###25684 using the whiteboard to see how a particular person would
###25689 do on solving some problem.
###25691 So it could be used in that way for you to really assess
###25694 people and improve people.
###25696 Like for example, your children, you want to see how
###25699 they are doing on programming on particular problem solving.
###25704 To summarize what we discussed in teaching and learning,
###25706 basically, if you want to become a teacher, to really
###25710 create a course for students or employees or friends to
###25715 play with and see their problem-solving process, you
###25719 could sign in with a Microsoft account, like a Hotmail
###25724 account [INAUDIBLE].
###25725 And then you pick a nickname and send us the nickname, and
###25728 then we could enable you with a teacher role.
###25732 And as a teacher, you could create courses.
###25734 You could monitor the progress of students'
###25736 problem-solving processes.
###25738 You could interact with them in different ways.
###25742 So in the future, there's a lot of exciting things ahead
###25746 like how to provide tutoring support for students if they
###25750 are facing some difficulties.
###25753 You see the 147 user trying 147 times.
###25760 Typically, a student would get frustrated after they try a
###25763 number of times.
###25764 For this case, we shouldn't just say, oh, you keep trying
###25767 or you fail.
###25769 You may have some hints on the side like in
###25772 the real-world setting.
###25773 And how to detect plagiarism, I mentioned already it's an
###25776 open problem.
###25777 For the ranking, so far we use passing or not, right, whether
###25781 you have behavioral differences or not.
###25783 But we really want to have other criteria like code
###25786 quality and other kinds of criteria for us to take into
###25790 account in terms of providing better grading.
###25792 Support other languages, [INAUDIBLE].
###25794 More detail in this upcoming paper.
###25796 It's available from my homepage.
###25800 And in conclusion, I talk about two different kinds of
###25803 technologies, but they are correlated to each other,
###25806 supporting each other.
###25808 Dynamic symbolic execution, along with Pex and parameter
###25810 unit testing, and Pex for fur as an application or platform.
###25814 To conclude that, my email address is there.
###25818 We welcome collaborations on this exciting period.
###25821 I would say in 40 or 50 years, you may retire.
###25825 Right?
###25826 Educating the next generation to do a better job than us or
###25830 at least as good as us is very important.
###25832 I think that besides just doing tests with automation,
###25836 it's a good opportunity for us to think about how to make
###25839 education and learning more fun and more valuable for the
###25843 next generation.
###25844 Thank you.
###25845 [APPLAUSE]
###25851 TONY VOELLM: Great Thank you, Tao.
###25854 Very fascinating.
###25856 So I had forgotten earlier, I had a few things up here.
###25860 So for some live questions, I was going to throw this out to
###25864 a live question.
###25865 We'll determine the best one here.
###25867 So this is a little Androidy.
###25869 
###25871 So we have the Dory up.
###25872 Let me go to the Dory, or to the moderator here.
###25876 It's not a door.
###25879 So first question up, how does a tool like Pex fit into the
###25883 software life cycle?
###25885 TAO XIE: OK, so Pex could be used like the other test
###25891 generating tools.
###25891 You finish your code implementation, and then you
###25894 apply Pex to generate test data to excise different
###25898 portions of the code.
###25899 In addition, it actually could fit in TTD, Test-Driven
###25902 Development.
###25903 But in this situation, you write parameter unit tests
###25906 first without actually having your code implementation.
###25909 But in this setting, keeping my parameter unit test
###25912 [INAUDIBLE] would be very powerful to force you to write
###25915 quite a lot of functionality when you try pass the test.
###25920 It's debatable whether that's a good thing or a bad thing in
###25923 terms of philosophy of TTD.
###25925 But it could allow you to spend more time on writing the
###25929 code implementation rather than with very minor
###25933 increments of adding new features.
###25937 TONY VOELLM: Interesting.
###25937 There's one live question here, so we'll go ahead.
###25940 Tell us who you are, where you're from, and then your
###25942 question please.
###25943 AUDIENCE: I'm Jessica Nickel.
###25944 I live in New York City, and I work at Targetspot.
###25947 I was in education for 10 years before transitioning to
###25950 QA testing.
###25951 And I find this really exciting.
###25953 And I'm just wondering if there are plans to develop a
###25957 curriculum around this so that way teachers can be guided who
###25961 may not be so technical but who are interested in
###25963 incorporating this into their classrooms.
###25966 TAO XIE: Yes.
###25967 Yes, actually, there are quite some materials already on the
###25971 website for you to customize use in your setting, including
###25975 like intro programming along with parameter unit testing.
###25980 We are still putting in quite substantial efforts in getting
###25984 more materials to cover different topics and customize
###25987 for different levels.
###25989 We also welcome collaboration in terms of these particular
###25992 aspects, like developing more course materials so that more
###25995 people could benefit form this course.
###25999 TONY VOELLM: Great question, by the way.
###26000 That was a good question and the first one up, so I'll set
###26002 that there for you.
###26005 OK.
###26006 I think we have one more live question.
###26007 So please go ahead, who you are, where you're from, and
###26011 your question please.
###26012 AUDIENCE: Hi, my name is Mark, University of Malta.
###26015 So I can see how symbolic execution is really good for
###26018 generating a bunch of test cases, which
###26019 maximize your coverage.
###26021 How does Pex handle the [INAUDIBLE] side of things?
###26023 So once you've generated the test, how can you be sure that
###26026 the system is behaving properly for
###26028 that particular test?
###26029 TAO XIE: Right.
###26030 So that would fit in what I describe as a
###26034 parameter unit tests.
###26035 Of course, you could just apply Pex like any other test
###26038 generation tool.
###26039 You don't write anything.
###26040 You just rely on crashing or not, or throwing and
###26043 exception or not.
###26044 That's already there.
###26046 If you want to have higher confidence in terms of
###26048 behavior that you are checking, you write this kind
###26052 of a parameter unit test with strong enough assertions so
###26055 that it's not hard-coded for some constant input value, but
###26059 more general.
###26060 So you would get the benefit by additionally doing
###26064 parameter unit testing.
###26065 OK, Thank you.
###26067 TONY VOELLM: Yeah, thanks for the question.
###26068 So up here on the moderator, it says, "Pex only identifies
###26072 unit testing parameters, right?
###26074 It will not handle functional or integration testing."
###26077 TAO XIE: OK.
###26078 So basically, as you can see, Pex basically, with the nicely
###26083 specified interface, that's the test data that Pex would
###26086 generate tests.
###26088 You could encode your integration test or functional
###26090 test inside this parameter unit test.
###26094 But the next question is that, could it scale well?
###26097 That's another question.
###26099 We need to see what kind of code we are dealing with,
###26103 whether the code we are testing would have dependency
###26106 with the environment.
###26107 Maybe you need to do environment isolation,
###26109 [INAUDIBLE]
###26110 like do mocking, this kind of thing.
###26111 So you may have to do a lot of these additional techniques
###26115 typically you would do in your traditional unit testing, yes.
###26119 TONY VOELLM: Very interesting.
###26120 And we have time for one more question.
###26122 So is this a live question?
###26123 We'll take it, please.
###26124 AUDIENCE: Hi, I'm Daniel [INAUDIBLE].
###26126 I'm a Googler.
###26127 The parameterized testing assumptions and assertions
###26130 reminded me quite a bit of code contracts but also felt
###26134 kind of like the opposite.
###26135 Like rather than specifying within your code parameters,
###26137 you're writing the test which is meant to be kind of
###26140 auto-verified.
###26141 I was wondering if you could kind of contrast those
###26142 approaches a bit.
###26143 TAO XIE: OK, very good question.
###26145 So in a code contract, like pre-, post-conditional design
###26148 by contract, you write the pre-, post-conditions in the
###26151 production code.
###26153 So typically, people would write mostly preconditions.
###26158 And very few people would write post-conditions.
###26162 Why?
###26162 Because it's very difficult to write post-conditions because
###26165 it's very complicated to capture the behavior of that
###26169 particular piece of code.
###26171 If you write parameter unit tests, yeah, you also have
###26173 assumptions and assertions.
###26175 Notice here, the assertion there would be specific to the
###26178 scenario that you constrain, with the method sequences in
###26182 the middle and assumptions that you put in.
###26185 So that you have a much easier time for you
###26187 to specify the behavior.
###26189 But indeed, code contract would have more applicable
###26194 scope or testing different situations only [INAUDIBLE]
###26196 the piece of code.
###26197 Parameter unit test would be just applicable on the
###26200 scenario that you specify there with whatever
###26203 test data coming in.
###26204 So I think that's a tradeoff that we are making.
###26207 I mean, the design by contract has been going
###26209 on for quite a while.
###26210 But we haven't seen enough practitioners take up
###26214 substantially.
###26215 Hopefully, parameter unit test would allow people to actually
###26219 get some benefits of these formal methods.
###26221 But at the same time, they are still following their
###26224 traditional practice of doing unit testing,
###26226 writing unit tests.
###26228 OK, thank you.
###26228 TONY VOELLM: OK, great.
###26229 Thank you, Tao.
###26229 TAO XIE: Great Thank you.
###26230 TONY VOELLM: Thank you.
###26231 [APPLAUSE]
###26238 TONY VOELLM: So this next speaker up I believe has
###26240 spoken at more GTACs than anybody else.
###26244 He probably does not need an introduction,
###26247 but I will do one.
###26248 This is Simon Stewart from Facebook, and he is going to
###26252 talk to us about how Facebook tests Facebook on Android.
###26256 And so with that, I'll hand it off to you.
###26258 Thank you.
###26258 SIMON STEWART: Brilliant.
###26259 [APPLAUSE]
###26265 SIMON STEWART: Thank you very much for that introduction.
###26268 Yes, i think I have spoken at more of
###26270 these than anyone else.
###26271 This is the one where I snatch the
###26273 crown from James Whittaker.
###26275 [LAUGHTER]
###26279 SIMON STEWART: Sorry, James, if you're watching.
###26282 Before I begin, I've been having a fantastic day today.
###26286 The quality of the talks has been amazing.
###26288 And the thing that I've really noticed has been just the
###26291 awesome work the stenographers have been doing.
###26293 Like when I haven't been paying attention.
###26295 [APPLAUSE]
###26301 SIMON STEWART: And the signing down here is phenomenal.
###26303 Just blown away by how well organized this is.
###26305 So well done, Google.
###26307 Keep up the good work.
###26309 Yeah, so how Facebook tests Facebook on Android.
###26313 If I'd been thinking carefully when I named this
###26315 presentation, what I would have done is I would have
###26317 called it "How Facebook Bakes Quality Into Facebook on
###26321 Android." Because we don't just test for the sake of
###26325 testing, right?
###26326 It isn't something that we sit there and go, you know what?
###26329 I really fancy doing some pointless testing today.
###26333 There's nothing I'd rather do.
###26336 Actually, sometimes I do feel like that.
###26338 But it's only when it's a really slow day.
###26341 Why are we doing this testing?
###26342 We're doing it to bake quality into our apps.
###26345 We can't bolt quality onto an application at the very, very
###26349 last minute.
###26351 We can't bake security in at the very last minute, either.
###26353 We can't bake performance in at the last minute.
###26355 These are things that we need to be thinking of all the way
###26358 through the life cycle of the application.
###26361 So yes, how Facebook tests Facebook on Android.
###26367 So let me take you back to 2012.
###26371 It was a long, long time ago in a galaxy right here.
###26375 The Facebook app on Android, it worked.
###26379 It was kind of fun.
###26381 And it also had really, really, really lousy user
###26386 experience.
###26387 Here's a quote from Mark here going, "We were never able to
###26391 get the quality we wanted.
###26392 Looking back, that's probably one of the biggest, if not the
###26396 biggest, mistake we made."
###26398 And why was the performance of the application so appalling?
###26403 Well, actually, it wasn't that bad.
###26405 But what we were doing is a pattern that's fairly common
###26407 in the world of mobile applications.
###26410 And that's to use the WebViews extensively.
###26413 Facebook was a web company.
###26415 We like to be able to release software.
###26417 We do it twice a day now.
###26418 We push to our live website twice a day.
###26422 That allows us to iterate on things really quickly.
###26424 It allows us to make a series of chronic and awful and
###26427 terrible mistakes, realize that we've done something, and
###26429 fix it in the next day.
###26431 Problem is that you can't do that on a mobile app.
###26436 Someone downloads the app, and then they're stuck with it.
###26440 If you've got a bug in that application, they may never
###26442 update again, which is a horrific place to be in.
###26446 So we'd like to retain some flexibility.
###26448 And the way we did that is we used WebView.
###26450 And the WebViews on Android and iOS are sub-optimal, I
###26455 think is a way to describe them.
###26459 There's a number of problems with them, not least of which
###26461 is they're like no other browser out there.
###26465 The Android one is based on the stock Android browser,
###26469 which is not Chrome, unless you're on Jelly Bean.
###26473 And if you're on Jelly Bean, actually, the browser is
###26475 Chrome, and the WebView is
###26476 something completely different.
###26478 The JavaScript engines tend to behave appallingly.
###26482 They're very slow.
###26483 They're tedious.
###26485 And so what we were doing is we were making each of these
###26486 WebViews to allow us to iterate more quickly.
###26489 And it was just leading to a really poor
###26492 experience for our users.
###26493 So we had to stop.
###26495 We reassessed.
###26496 What we did is we decided we were going to make mobile a
###26499 first-class experience.
###26501 
###26504 That went the wrong way.
###26506 I could do the entire talk in reverse, by the way.
###26509 Start on the final slide, begin with your questions, and
###26511 then just make it up from there.
###26513 
###26515 Hands up if you'd like me to do that.
###26518 There's one hand.
###26519 Two hands, brilliant.
###26520 Next year.
###26522 I'll be invited back for sure after this.
###26526 So what we did is we decided we were going to take our
###26528 engineers, and we were going to train them up on mobile.
###26532 And this graph here has the numbers removed, but there's a
###26535 total of about 1,400 engineers at Facebook.
###26538 Not all of them contribute to our mobile codebase.
###26541 But what happened is it was all going
###26543 along fairly regularly.
###26544 And then we went, what we need to do, we need
###26546 to put mobile first.
###26548 We took our PHP developers.
###26549 We ran them through training courses.
###26551 We educated them.
###26552 We hired people in who were skilled at Android and mobile
###26555 development.
###26556 And that's the result.
###26558 We had this massive uptick in the number of engineers
###26561 committing code to our mobile codebases.
###26564 That's a fantastic thing.
###26565 We're now moving a lot faster.
###26569 The important thing, though, is that it's engineers
###26572 contributing to our mobile codebase.
###26574 There are no Android team.
###26578 What I mean to say is, there is no longer an Android team.
###26581 We tried to do that.
###26582 We tried to have a group of people who were responsible.
###26585 We called them the Core Android Team.
###26587 And they were going to be awesome, and they were going
###26588 to somehow keep up with the flood of new features coming
###26592 into the web.
###26594 And that didn't work.
###26596 So what we did is we took a step back.
###26598 We reassessed again.
###26600 And now what happens is each of the teams producing a
###26603 feature own that feature on every platform it's on.
###26607 So if you own pictures, you own it on the web, the mobile
###26611 web, iOS, Android.
###26613 So that's far easier for people to keep things in sync.
###26617 There's probably people on those teams who are
###26619 specialized on Android or iOS.
###26621 But there isn't a group of people who are responsible for
###26624 desperately trying to ape features from the web in a
###26627 mobile client.
###26628 And that allows us to keep parity in place.
###26631 And that means that users get a far better experience.
###26634 If something appears on the web, chances are it will also
###26637 appear on the mobile client relatively soon after that.
###26641 We do have spoons.
###26642 So there is no Android team.
###26644 We do have spoons.
###26647 So what's a developer's day like?
###26649 Let's say you're on one of these feature teams, and
###26651 you're going to do something.
###26653 How do we bake quality into the application?
###26656 It's done all the way through the process.
###26660 So let's begin with how we build.
###26662 That seems to be quite an important
###26664 thing to do with software.
###26666 We need to build it.
###26669 So we use Git at the moment for source control.
###26673 It's a DVCS.
###26675 And so what we do is we have a central repo.
###26677 And that seemed like a good idea.
###26680 Everyone works on their local machine.
###26682 There are two branches that we care about day to day.
###26686 Google I know only have one.
###26687 And that's because none of their tests fail because
###26690 they've got the presubmit, and it's awesome.
###26692 We haven't got the presubmit, so people check in.
###26696 So there are two branches that people care about.
###26698 The first one is master.
###26700 That represents not a villain from "Doctor Who," but the
###26704 most recent version.
###26707 You can see who enjoys Britsh sci-fi here.
###26710 
###26712 It's the latest version of the code.
###26714 So master has everything in it that has been committed to the
###26718 code base so far.
###26719 It's a linear history.
###26721 What we also have is a moving tag called stable that
###26725 represents the last time that we were sure that our unit
###26728 tests were passing.
###26729 So there's master, and there's stable.
###26733 That's kind fun.
###26735 And all this code is checked out, for Android at least, in
###26738 a single tree with effectively three or four directories up
###26743 at the top.
###26744 Java, Java tests, because you never mix tests and Java code.
###26748 It's just not the thing that you do.
###26750 Third-party libraries, we keep those out of the tree.
###26754 And resources used for Android.
###26756 
###26759 OK, I've got my drink of water here.
###26761 Yes, so it's all one tree.
###26764 That's kind of fun because we've got more than one mobile
###26766 app that we make for Android.
###26768 And there's Instagram in there.
###26770 There's a Facebook app.
###26771 There's a messenger app.
###26771 There's a camera app.
###26773 If you download an app for Android from Facebook, it's
###26781 all been built from that tree.
###26782 
###26788 I'll throw that all over my laptop later.
###26792 So--
###26794 yes, people know Murphy as well.
###26796 So what does it look like when you begin
###26798 working on a feature?
###26798 Well, what you do is you're probably on the stable branch.
###26804 You create a new branch for your fancy feature.
###26806 Hackity hack, hackity hack, hackity hack, you get commit.
###26810 And you create a new feature.
###26812 But while you've been working, there have been N other
###26815 developers also checking in code.
###26817 So periodically, you want to grab the work they're doing
###26819 and rebase.
###26821 So you're always working on the top of the tree.
###26823 You go hackity hack, hackity hack, hackity hack.
###26826 When you're ready, you commit.
###26828 And then you do a rebase.
###26830 So what we like to do is while you're developing locally on a
###26834 branch of your own, you can have as many
###26836 branches as you want.
###26838 You can have your commital organized any way you want.
###26841 But when we push it into master, we want a logical
###26844 change to go into our codebase.
###26846 We don't want the individual steps you did.
###26849 Now there's a number of reasons for doing that.
###26851 The first one, a logical change is a lot easier for
###26854 other people to comprehend.
###26855 If you want people to understand what you're doing,
###26858 what you need to is explain why you're doing it.
###26860 That helps increase the quality of the code when
###26862 someone comes and has a look at things.
###26864 And second of all, if we need to yank your changes, it's a
###26868 lot easier for us to do that if we can see the one logical
###26871 change that went in, rather than the intermediate steps,
###26873 particularly if you're like me and you work on two or three
###26875 things at the same time.
###26877 So we always just squash our commit before we run this
###26881 command, arc diff.
###26882 
###26885 So how do we write all this code?
###26890 We use IntelliJ.
###26891 Its Java, right, so there's two choices of IDE, IntelliJ
###26897 or Eclipse.
###26900 Both of them are perfectly reasonable choices.
###26902 But the way that we've structured our codebase means
###26904 that IntelliJ is actually a really good fit for us.
###26907 And from a massively biased point of view, I prefer it.
###26910 
###26914 And Facebook is small enough that, actually, an individual
###26917 choice and someone advocating can really make
###26921 a difference there.
###26923 So you're using IntelliJ.
###26925 You want to make sure the code is good.
###26928 You want to make sure the code is testable.
###26930 How do you make sure the code is testable?
###26933 You use what?
###26934 You use dependency injection.
###26937 So when you're doing object-oriented software, OO
###26941 software, you've got collaborators.
###26943 The class that you're working on collaborates
###26945 with a bunch of things.
###26946 And there are two ways that it can get hold of its
###26948 collaborators.
###26949 The first way was popularized by J2EE back in the late '90s,
###26953 early 2000s, and was service location.
###26956 You had this big thing, and you went into it in the middle
###26960 of your method.
###26960 And you went, thing, give me a database connection.
###26963 And thing would look at you and go, here's a database
###26965 connection.
###26965 And that would be fine.
###26968 And then 2003, 2002, early 2000s, this dependency
###26975 injection phrase started becoming more popular.
###26978 And the major difference with that is that rather than
###26982 having the method go, thing, give me one of these, the
###26985 method signature or the class under test somehow accepted
###26989 its collaborators from the thing that created it.
###26993 So there's constructor-based dependency injection, where
###26995 all your collaborators are passed in at
###26997 construction time.
###26999 And there's also setter-based dependency injection.
###27002 Also some magic-based dependency injection, where
###27005 you annotate things and then Guava or Spring or whatever it
###27008 is that you like suddenly populates fields that you have
###27012 no idea how it did it.
###27013 But it's done it somehow, right?
###27015 Now the advantage with dependency injection over
###27018 service location is it makes your collaborators really,
###27022 really obvious.
###27024 It encourages you to think about who your class is
###27026 collaborating with.
###27028 I remember I was on one project, not at Facebook, and
###27032 they were using service location, and I ripped out all
###27034 the singletons, and I added every single thing they
###27037 depended on till they construct a signature.
###27039 And 14 arguments later, somebody went, that's a really
###27044 big signature.
###27045 Yes, yes it is.
###27047 Do you think we've got too many roles and
###27048 responsibilities?
###27049 I went, I don't know.
###27051 We should probably slim that signature down somehow.
###27053 So yes, how are we going to do that?
###27055 Thinking what we'll do is we'll split the class up and
###27057 have fewer responsibilities.
###27059 And what they said to me is they went, ah,
###27061 we'll pass in a map.
###27063 [LAUGHTER]
###27068 
###27071 SIMON STEWART: So yes, dependency injection, a
###27073 really, really useful way of ensuring that
###27077 your code is testable.
###27077 It makes it really easy to swap out collaborators at test
###27080 time, and that's vital.
###27081 
###27084 So you've written your code in IntelliJ.
###27086 That's nice.
###27087 You've used dependency injection like a good
###27089 developer should.
###27091 You probably want to build your code.
###27095 Now we use a tool called Buck at Facebook for
###27098 building our code.
###27101 Why do we use a tool that nobody else in
###27104 the world yet uses?
###27105 
###27108 There's a number of reasons for it.
###27110 What we want is we wanted a tool that had minimal overhead
###27114 when we added a new library or module to the project.
###27117 Our original [INAUDIBLE] solution had a lot of
###27119 boilerplate code.
###27120 It had lots of submodules.
###27122 If you've used Maven, the way that you would do a new module
###27126 is probably you'd have a top-level library, and then
###27127 you'd have some sort of POM that would point
###27129 to it and who knows.
###27131 It's ugh.
###27132 We want to keep boilerplate out of our codebase.
###27134 Boilerplate is things that machines should do for us.
###27137 But we also wanted the build tool to be
###27140 friendly to the IDs.
###27141 We'd structured our code in a way that actually plays really
###27144 nicely with IntelliJ, and we don't want to lose that.
###27148 We want really, really fast, clean builds.
###27152 But we want our incremental builds to be even faster
###27156 because as Ari said right at the beginning of the day,
###27160 doing a clean is a bug in your build system.
###27162 You should never, ever need to do that.
###27165 So yes, we want faster incremental builds.
###27168 And what we need to do is we ahead of time don't know all
###27171 the things that people are going to try and build.
###27173 So we want to support adding ad hoc build steps.
###27177 So Buck, our build system, has three really important
###27181 concepts in the middle of it.
###27183 The first is a build rule.
###27185 Now that's a procedure for-- oh, you can
###27187 all read, can't you?
###27189 Yeah, OK.
###27190 It's a procedure for producing output files from input files.
###27192 So you list a series of sources and dependencies.
###27194 And the build rule runs.
###27197 And you get the outputs.
###27199 You get one output.
###27200 That's the invariant of the system.
###27201 You can have at most one output from a build rule.
###27204 A build file contains a series of these rules.
###27207 And typically, it's called BUCK in all capitals, which is
###27210 great unless you're on a case-insensitive file system.
###27215 So we declare all the rules in that.
###27216 And if we want to have a dependency between two rules,
###27219 we use a label to get to the build rule, and call that a
###27223 build target.
###27225 OK?
###27225 So it's a string identifier for a build rule.
###27228 This is what a target looks like.
###27231 I like to read the slash slash as "from the root of the
###27234 repository." So from the top level, there is a directory
###27238 called java, com, Facebook, share.
###27240 Excellent, colon.
###27242 In which there is BUCK file, UI, with a
###27245 build rule called UI.
###27247 So this gives us a completely declarative path to the thing
###27252 that we're attempting to build, which is nice.
###27255 
###27258 By the way, if you've ever used the Selenium build
###27260 system, it uses exactly the same syntax as that.
###27263 It's called crazy-fun.
###27264 If you work for Twitter, pants uses, I think, exactly the
###27268 same syntax.
###27269 Is that right?
###27270 Yes, it is.
###27271 Brilliant.
###27272 Good.
###27274 I think it's because there is a sort of diaspora of
###27276 ex-Googlers who pine for the amazing build system that Ari
###27282 talked about.
###27283 [APPLAUSE]
###27288 SIMON STEWART: So yeah, what does a build file look like?
###27290 [LAUGHTER]
###27296 SIMON STEWART: It looks like that.
###27298 This is how we build our library for Android.
###27301 They're called UI, so the one that we had before.
###27304 We do a recursive glob over the directory structure
###27307 underneath, where this rule is declared.
###27310 So it's not over the entire tree.
###27311 It's just over the subtree beneath this.
###27314 We have a series of dependencies, which are
###27316 declared there.
###27317 And visibility.
###27318 So by default, no one else can see a build rule outside of
###27323 the build file you're declared in.
###27325 So you can have dependencies within a build file.
###27329 But if you step outside, you need to make it visible.
###27332 You can either make it public, anyone can use this thing, or
###27335 you can limit the visibility to certain subsets of rules.
###27339 In order to make it nice and easy to have a library that
###27344 you can depend on in the rest of your code without needing
###27345 to be aware of how that library is structured, with
###27348 the Java library, you can also export your dependencies.
###27350 So you can say, look, if you depend on me, then
###27353 transitively, you get all my dependencies as well.
###27356 Which is a nice way of composing everything.
###27358 
###27362 Who knows Python?
###27363 
###27366 What language does that look like?
###27368 It's a leading question.
###27370 It's Ruby.
###27371 No, hang on, it's Python.
###27374 Our build file is Python.
###27376 We interpret the build file using the Python interpreter.
###27380 We're moving to Jython because, you know, it would be
###27382 nice not to have to rely on Python being installed on the
###27385 local system.
###27387 But yes, so it's Python.
###27388 And that allows us to do some really, really nice things.
###27391 Like if we're missing the ability to build a certain
###27394 type of target, if a build rule should exist to build iOS
###27400 library, for example, we could add it to the system using a
###27403 glob of rather unpleasant Python and then just use an
###27407 iOS library in the rest of our build rules.
###27411 And then when we modify Buck, we can fix it.
###27414 And we can bake that into the platform.
###27415 And that's kind of nice.
###27418 So we've got this ability to modify the build system on the
###27421 fly in a Turing-complete language in a completely
###27424 declarative build system.
###27426 I'm not sure how I feel about that, but it is awfully
###27428 convenient.
###27429 
###27432 So what we do, you run your builds.
###27435 We build a directed acyclic graph.
###27437 I was really pleased when I started working on Buck
###27439 because it allowed me to use some of the computer science
###27441 that I struggled through all the way through university and
###27445 use terms like directed acyclic graph
###27447 with a straight face.
###27450 And what we do is we analyze that graph, and we build
###27453 sub-parts of the tree in parallel.
###27456 So we try and build everything as massively
###27458 parallel as we can.
###27460 And that enables our builds to be significantly faster.
###27464 And then because we know that if the inputs to one of the
###27468 previous steps haven't changed, the output won't have
###27470 changed, we can skip building that step.
###27473 We can just use the cached output.
###27475 And that allows our incremental builds
###27476 to be nice and fast.
###27479 How does IntelliJ feel about us monkeying around on a file
###27482 system like this?
###27484 Apparently, it likes it.
###27487 We run a command called Buck project.
###27489 And what that will do is it will scan through the entire
###27491 file system for BUCK files.
###27494 And it will generate the IntelliJ configs.
###27497 So what you do is you go, aaah, I haven't got an
###27499 IntelliJ config.
###27500 Buck projects points IntelliJ at it.
###27503 And suddenly, everything works out quite nicely.
###27506 That will also set up some exports for build rules-- for
###27509 test runners and things like that.
###27511 So that's nice.
###27515 And it's fast, guys.
###27516 This thing is quick.
###27518 Because if you want people to write tests, if you want them
###27520 to be using dependency injection, if you want them to
###27522 be doing all these things that we want to encourage people to
###27525 do, being slow doesn't help.
###27528 Again, [INAUDIBLE]
###27529 the developer who was sleeping,
###27531 going longer is better.
###27534 Longer isn't better, shorter is better.
###27536 Instant is best.
###27538 Actually, if it could somehow leap forward in time and give
###27541 you the results before you finish writing the code, that
###27543 would be better still.
###27544 But assuming we're constrained by the laws of physics,
###27547 instant is best.
###27550 So Buck, by default, spins up as many threads as it can,
###27554 1.25 times the number of calls in your machine, as reported
###27557 by Java Safe.
###27557 You've got hyper threading enabled.
###27559 On the modern laptop, that means you've got 10 parallel
###27562 builders running, four physical cores, H with hyper
###27566 threading, times 1.25, 10.
###27570 And we found that by doing this, we can
###27572 slash our build times.
###27573 Our build time, when we were running in single threaded,
###27576 used to take about 20 minutes.
###27580 And we ran things in parallel, and we dropped that down to
###27582 four minutes.
###27584 That's quite nice.
###27586 It's an incremental system.
###27587 So we only rebuild what's necessary.
###27590 There are going to be some changes that we're going to
###27591 make in the future, like at the moment, we need to scan
###27594 the file system every time we do a build to figure out
###27596 what's changed.
###27597 If we demonized something that watched the file system, as in
###27602 turned it into a demon rather than just told it it was bad
###27604 all the time, we could go faster.
###27608 And the other thing as well is it would be nice to be able to
###27612 do a distributed build, and if someone's built the thing you
###27614 need with the same signature of the inputs, you should be
###27618 able to get the same outputs.
###27619 You shouldn't need to do a build.
###27621 So in 2012, what happened was we flipped everyone from using
###27627 Ant to using Buck.
###27632 And I'm just going to hide that, pull
###27634 that up to the front.
###27635 Can we flip to the Mac, please?
###27639 Excellent.
###27641 So there are two interesting things here.
###27646 I've checked out the source code for Buck.
###27649 And we build Buck with Ant, because we're insane.
###27652 
###27655 You can see the activity monitor from OS
###27657 10 just down here.
###27659 CPU usage is a thing to look.
###27661 So what I'm going to do is I'm going to do--
###27665 let's do a clean.
###27667 I'm going to just time a clean build of Buck and then running
###27671 all its tests.
###27672 So it's doing the compilation, excellent.
###27676 Now it's running the test cases.
###27680 It's still running the test cases.
###27684 And it continues to run the test cases.
###27686 And I'm not going to wait, because it takes about a
###27688 minute and a bit to do everything
###27691 that it needs to do.
###27694 So now what I'll do is I'll use Buck to run every single
###27699 test in the file system, and to make it a fair comparison,
###27702 I'll do a Buck clean.
###27704 Because I'm actually in the directory that Buck is
###27706 installed from, we may see a bit of Ant output as it
###27709 bootstraps itself.
###27710 We should be fine.
###27711 But look at the CPU usage over here.
###27715 What it's doing now is it's parsing everything.
###27718 It's testing all the tests.
###27719 It doesn't do a meme.
###27722 And bam, in the time it took me to describe what was going
###27725 on, it's run every single test in the Buck system, and that
###27729 took significantly less than the minute it would've taken
###27732 if we were using Ant.
###27734 So that's pretty cool, right?
###27737 Can we go back to the slides, please?
###27738 
###27741 So at the time we did the switchover, it was quicker to
###27745 pop up a warning on the Ant build saying, why don't you go
###27748 and download it?
###27750 You could download Buck, install it on the system, and
###27752 do a complete build far more quickly than if you finished
###27757 your Any build, which is crazy.
###27760 And the good news is Buck is open source.
###27762 You can go and download it.
###27764 You can go and have a play with the build system that we
###27767 use at Facebook.
###27768 We accept Pull Requests.
###27770 Please send Pull Requests.
###27772 They'd be lovely.
###27774 It's pretty nice.
###27775 If you want to see the documentation, just head over
###27777 to the Facebook.gethub.com, and take a look at that URL.
###27782 It's under the Apache 2 license, so if you're working
###27784 in a bank, you're worried about having to suddenly make
###27786 all your source code available, because you use a
###27788 new build tool, relax.
###27789 It's OK.
###27791 It is written in JAVA.
###27792 I know it's not trendy, but it is a perfectly working like
###27795 language, and a small amount of Python, which makes the
###27798 Pythonistas happy.
###27800 And it works in OS 10 and Linux.
###27802 Now the reason it doesn't work on Windows is because nobody
###27805 builds on Windows.
###27808 AUDIENCE: We wish.
###27809 SIMON STEWART: Well none of our team
###27810 currently build on Windows.
###27811 I'm sure at some point, there'll be a need for it.
###27814 So I mean, that's a flippant comment.
###27816 And it was fine.
###27817 And of course, we build Buck with Ant.
###27822 So, yes, we've got this amazing
###27823 fast build time, right?
###27824 And that allows us to test.
###27828 Testing's good, right.
###27830 We get on developers to write the tests.
###27832 At Facebook, there is no SET, no SDET, no TE, no QAE, no
###27840 test department, and QA department.
###27844 We just have engineers.
###27846 Now some of the engineers have a passion for testing in the
###27848 same way that some engineers have a passion for databases,
###27851 some of them have a passion for security, and some of them
###27854 have a passion for finding pictures of kittens on the
###27856 internet and posting it to their timeline.
###27858 
###27861 But we get developers to write test.
###27863 Everyone who writes a line of code is expected to also be
###27866 writing test for that line of code, which is nice.
###27870 Seems to be working out all right for us so far, and I
###27874 quite like it.
###27876 I always find that companies that have a test team, the
###27878 test team tends to be looked down on and not treated with
###27881 the love and respect that they ought to be.
###27883 
###27890 I love you guys, it's OK.
###27891 
###27895 Yeah, I remember sort of getting interviews from people
###27897 going, he wasn't good enough to be a coder, but he might be
###27899 OK as a tester.
###27901 And it's like no, no, no, no, no, no,
###27902 you've got it all wrong.
###27903 They're not good enough to be a tester.
###27905 They might be all right as a coder.
###27909 And it wasn't appreciated in the way I thought it would be.
###27914 Funny, that really.
###27916 So what kind of test do we ask people to write?
###27919 We start with unit tests.
###27921 Unit tests run using JUnit.
###27924 Kent Beck works at Facebook.
###27926 We're not using TestNG.
###27927 Cedric doesn't work there.
###27929 Kent does.
###27931 For those of you who don't know, Kent Beck wrote JUnit.
###27934 Cedric wrote TestNG.
###27936 And we encourage people to write unit tests to run
###27938 locally on the JVM, because we appreciate fast.
###27941 Fast is really important, new fast break tests.
###27945 That isn't the Facebook mantra, but it almost is.
###27948 In order to enable people to move quickly, their using
###27950 dependency injection.
###27952 We can replace collaborators at test time using EasyMock.
###27955 That's one of the libraries that we use.
###27957 Mockito is another choice if you're looking to do things.
###27960 But EasyMock is what we settled on at Facebook.
###27963 But we're building an Android app.
###27966 And if you include the Android jar from the Android
###27970 development kit, and you run a test using it, what tends to
###27973 happen is any time you touch anything, included in that
###27976 jar,, you get an exception with Stub!
###27978 being the only message in that exception.
###27981 And that's because what they've done is they've
###27982 provided an ABI compatible jar with no implementations,
###27986 because the implementation runs a Dalvik on the device.
###27990 That makes writing tests incredibly difficult.
###27993 That's a bad thing.
###27996 We don't like that.
###27997 So what we do is we use a library called Roboletric.
###28000 Again, it's open source.
###28002 And what that does is it provides Stub!
###28005 Implementations or fake implementations of each of the
###28008 Android methods.
###28010 So what we can do is we can compile, and test and run in
###28013 the IDE on your desktop for a really fast
###28015 developer feedback cycle.
###28018 And that's nice, because there's no compilation to
###28021 Dalvik, no pushing apps in the machine, the device, or the
###28024 emulator, and you can get that nice fast cycle time.
###28027 We appreciate fast.
###28028 
###28030 But unit tests don't cut the mustard, right?
###28033 You will occasionally want to make sure that all the unit
###28036 tests function correctly, and the software when you plug
###28039 everything together doesn't fall over.
###28042 I was on a project once which have slightly over 2 and 1/2
###28044 thousand tests.
###28047 It was a dot net project.
###28048 The test ran in about two seconds.
###28050 It was amazing.
###28051 And the app would consistently not start up.
###28054 
###28060 And it's because they had forgotten to write integration
###28062 tests and larger tests, and they were just using mock
###28064 objects and going yeah, it'll return null here and throw an
###28067 exception here for exact same method.
###28070 No, guys, you need larger tests.
###28073 Larger tests, there are a handful of frameworks
###28075 that you can us.
###28078 UI Automator, which came in API level 16--
###28082 so basically Jelly Bean and above.
###28084 I think it's there in ICS, but Jelly Bean and above it,
###28086 starts becoming useful.
###28088 We use that quite a lot.
###28090 We're writing our own test framework to allow you to
###28092 write tests out of process and off
###28094 device, using UI Automator.
###28096 We call it Bully, because it pushes things around.
###28098 I may have to come up with a better name before we open
###28100 source it, or maybe not, who knows.
###28105 We also use Robolectric for the older devices, and there
###28108 are some tests using that.
###28109 We use MonkeyRunner.
###28111 We use a whole series of tools that come with the Android
###28114 development kit.
###28115 And they're all quite nice, but Robolectric, UI
###28116 Automator--
###28117 those are two of the key ones that we use.
###28120 By the way, we also run things like power tests, and on
###28123 device tests, and things like that.
###28125 But these are tests of the standard normal developers,
###28128 rather than crazy ones who really enjoy testing.
###28130 
###28133 You've got the code.
###28134 You've tested the code.
###28135 You kind of think it works, so you're ready.
###28137 You're going to push it into master.
###28140 So you remember way back in the black slide,
###28146 there was arc diff.
###28148 What does arc diff actually do?
###28150 Kicks off the code review process.
###28153 You write a description of what you do, you
###28155 write a test plan.
###28156 And if the test plan goes well I don't know or the written
###28159 equivalent, you tend to be told off and told to improve
###28163 your test plan.
###28165 And we send it up to a tool called Phabricator, which is
###28168 like a Swiss Army chainsaw of project management.
###28172 So it does tasks.
###28173 It does code reviews.
###28175 It does browsing of repositories.
###28178 It allows you to do all sorts of clever wonderful things,
###28181 and we like Phabricator at Facebook.
###28183 And this is what a code review looks like.
###28186 You can see here that the chap has submitted a reasonable
###28190 test pilot.
###28190 It has been greyed out, but it's in purple.
###28192 The reviewer has come back and asked him
###28194 to make some changes.
###28196 The developer has made some changes.
###28197 That's what the little icon second from the bottom does,
###28200 and then the reviewer's gone, this is good.
###28202 You can check it in.
###28204 
###28206 Now Phabricator has a killer feature, and I don't know if
###28211 you can tell what it is.
###28213 It's image macros.
###28215 In the middle of your code review, you can just type a
###28218 little line, and it will insert an image
###28220 into the code review.
###28222 This is American Obama, which is President Obama playing an
###28226 electric guitar shaped like a bald eagle while wearing an
###28229 American hat.
###28230 
###28233 I quite like that one.
###28234 I stare at it endlessly.
###28236 It's fascinating.
###28237 
###28239 And ship it.
###28240 It's like, it's all done.
###28241 Just ship it, land the code.
###28243 Do something interesting.
###28245 To land it, we use the command line tool,
###28248 Arc, short for Arcanist.
###28249 It's the command line counterpart to Phabricator.
###28253 And landing does two things.
###28255 It runs lint, which can be run separately.
###28257 And we use the Android linter with additional lint rules
###28260 that we've added to check for things like null pointer
###28263 exceptions.
###28264 So we use at nullible quite a lot from Guava, optional as
###28269 well, like Guava library--
###28271 fantastic.
###28271 If you're not using it, just download it now and use it.
###28273 It's one of the best things to come out of Google for
###28276 developers for a long, long time.
###28277 It's awesome.
###28278 We also make sure that all the APIs for the versions of
###28281 Android that we support are all present and other bits and
###28284 pieces, and we do an Arc land.
###28286 What Arc land does is it takes your changes in your local
###28288 branch, rebases them onto master and pushes your version
###28292 of master into the central one.
###28294 So if you take a look at the history of the project and get
###28296 a master, it's a single linear history.
###28299 We don't have weird branching.
###28300 It's just a straight down linear
###28301 history of logical changes.
###28305 So you've landed your code, you've tested it.
###28307 It's all wonderful, right?
###28309 No, hang on.
###28311 We also have a continuous build system.
###28313 If you haven't got a continuous build system yet,
###28315 just use one.
###28317 I don't care what you use--
###28317 CruiseControl, Go--
###28320 we use Buildbot.
###28321 And you can see here that most of the time,
###28323 things are pretty good.
###28325 One developer has caused the test to fail, and so we're not
###28328 going to move the stable branch.
###28330 But when these tests all go green, then we go, excellent.
###28333 And these are sort of longer running tests, so these are
###28335 integration tests, end to end tests, that we don't want a
###28338 developer to run on their local work station, because
###28340 there just isn't time in the day.
###28342 And if you're not breaking the continuous build server
###28345 periodically, you're probably not working hard enough.
###28349 It's what one of my friends used to say.
###28350 I think he's right, actually.
###28352 I think it's OK to break the build periodically, as long as
###28354 you fix it immediately afterwards, possibly by
###28357 yanking your change out, reworking it and
###28359 resubmitting it.
###28360 So Buildbot runs all these longer running tests, these
###28364 paratests, make sure there are no regressions in performance
###28366 or anything like that.
###28368 Now we're done, right?
###28369 Oh crap.
###28371 Sorry, [INAUDIBLE], you win the bet.
###28373 He betted that I wouldn't profane.
###28375 Does that count as profanity?
###28376 I don't know.
###28377 Shit, there we go, done it properly now.
###28381 So, yes, it's built.
###28383 We need to Dogfood this thing.
###28385 As I said before, when you get this application on your
###28388 phone, if it falls over, [INAUDIBLE] need
###28390 to download it again.
###28391 That would be an awful, awful thing to happen, so we Dogfood
###28394 extensively.
###28396 And one of the platforms that we make sure that we Dogfood
###28398 on is Gingerbread.
###28400 Problem is, at Facebook many of our developers are paid
###28405 well enough to be able to afford an ICS
###28407 or Jelly Bean device.
###28410 And we can ask for a Galaxy Nexus for testing
###28412 and things like that.
###28414 But Gingerbread is still incredibly popular.
###28416 They're still churning out devices with
###28418 Gingerbread on it.
###28419 And these are the latest numbers from the dashboard
###28423 that Android has on their website.
###28426 And you can see Gingerbread is about 40, 45% of the market.
###28431 And so what we do is we make sure that people are
###28434 voluntarily using Gingerbread as their primary device and
###28437 they're Dogfooding our applications.
###28439 So they installed the beta builds on their device, and
###28442 they keep on using that.
###28444 One of the key people using Gingerbread as their day to
###28446 day device is a release manager for Android.
###28450 He is not always the happiest person, but he often flags up
###28455 pretty nasty regressions that no one else has caught yet,
###28458 because they only show up as sort of outer memory
###28460 exceptions on Gingerbread, where the devices are
###28463 constrained.
###28466 So this is the PHP hammer, by the way.
###28469 I don't know if you've seen it.
###28473 It has nothing to do with the talk.
###28474 I just love the picture.
###28477 So you've downloaded the beta version of the app, you've
###28479 side loaded it.
###28480 What it does is it periodically--
###28482 at Facebook at least--
###28483 contacts the build services and goes, is there a new
###28486 version of the application?
###28487 And if there is, it nags people to update it.
###28490 So it downloads it in the background, and then goes,
###28492 would you like to install it?
###28493 Would you, would you, would you?
###28495 And you go, yeah, all right.
###28496 And so once you're on the testing track at Facebook, and
###28500 you always using the beta build, you're always using the
###28503 most recent beta build, which prevents sort of old bugs
###28506 being filed by people.
###28508 And finding bugs is incredibly easy, because what people do
###28512 is they take their device, and they shake it.
###28515 Now, we call that a reg shake, because you normally only
###28518 shake your device when you're going, it's not working.
###28521 Oh, hello, I can file a bug, excellent.
###28522 
###28525 And that's kind of a really nice feature.
###28527 So to get good instant bug reports from people, as
###28530 they're experiencing it, using the latest version of the
###28533 application, which allows us to do our releases.
###28538 Our releases--
###28539 never thought I'd get there, did you?
###28541 So you could pick two, when you're doing a release.
###28544 You can have features, quality, or regular schedule.
###28550 Wow, that's a kind of tough choice.
###28552 If there any project managers in the audience, features,
###28556 quality, schedule is not two, that's three.
###28559 
###28563 So we decided that we were going to do time based
###28567 releases which are high quality.
###28570 That means that occasionally, we ship without features that
###28572 we've been working on.
###28574 Now the advantage of a time based release--
###28576 and our releases are about four weeks long, so what we do
###28578 is we cut a branch, we do stability work for about three
###28582 weeks, we have a release candidate for about a week,
###28586 where we push it out to the beta testers and anyone in
###28589 Facebook who volunteers for it, and then we ship to the
###28592 Play Store.
###28593 So once a month, there's an update to the Facebook
###28595 application.
###28596 And it's really nice having that regularity, because it
###28598 means if you're working on a feature and you missed this
###28601 release, you know that you're not going to have to wait
###28603 forever before the next release.
###28607 it means that you can get the stuff as quickly as possible.
###28611 And it means you've got that consistency, that regularity.
###28614 You also know that your feature isn't going to be
###28616 blocked as somebody else frantically tries to finish
###28618 their thing.
###28619 That's nice.
###28620 So time based releases are hugely, hugely valuable to us.
###28625 And done isn't just hey, it compiles, and the tests pass,
###28628 and nobody's filed a bug with it yet on the release
###28634 candidates.
###28635 Done is things like, isn't the design work all finished?
###28639 We've see changes going into the release branch around the
###28642 design of a feature, that we know that the piece hasn't
###28644 been finished.
###28645 If the feature hasn't been finished, we
###28646 yank it from the release.
###28647 We either hide it behind a flag and strip it out using
###28650 Dex, ProGuard even, or we just remove the particular feature,
###28657 and we ask people to keep on working on it.
###28658 And logging--
###28660 how do we know when we release a feature that it isn't
###28662 causing a million crashes?
###28665 We get metrics, and feedback and information from the
###28668 versions of Facebook that you're running on your phone.
###28670 If something goes wrong, we get told about it somehow.
###28674 Sometimes it depends.
###28675 
###28677 And we can look at that data, and we can go oh, crikey,
###28679 there's being a sudden spike in crashes on this particular
###28681 kind of device.
###28682 Let's fix that.
###28683 So we get information from the world.
###28685 If you haven't put logging in, we can't get that information.
###28688 Sometimes there are certain side changes
###28689 that need to be made.
###28690 We still use WebViews in a few places.
###28693 So if you're pushing a new feature, we need to make sure
###28695 it works for the old and the new vision of the app.
###28698 And obviously, privacy and legal review are really,
###28701 really important.
###28702 Facebook cares about privacy.
###28705 We're a social network.
###28706 If people don't trust us with their data,
###28710 we're dead in the water.
###28711 So we need to really, really be concerned with privacy, and
###28713 we are, and legal review, just in case.
###28717 So they're just as important as a code review, and that's
###28719 what done means.
###28720 So that's basically how we bake quality into the Facebook
###28725 application.
###28726 We go all the way through.
###28727 We run tests consistently.
###28728 We encourage people to use design patterns for
###28730 testability.
###28731 We have defense in depth.
###28733 So there are unit tests, integration tests, the
###28735 continuous integration server.
###28736 We have people Dogfooding all the time.
###28739 We encourage people to use devices that aren't commonly
###28742 used by people who have got well paid jobs, but are used
###28746 widely in the real world, particularly in the small
###28750 markets, the emerging markets.
###28753 Great, so thank you very much for your time.
###28755 We've got time for some questions.
###28756 Thank you.
###28758 
###28764 TONY VOELLM: Thank you, thank you, Simon.
###28765 That was fantastic.
###28767 I really liked seeing the end to end.
###28768 We have a couple live questions.
###28771 So how about we go to the left first.
###28773 Go ahead and state your name, where you're from.
###28775 AUDIENCE: Hi, my name's Christian from Google.
###28777 I actually work on the Guava team.
###28780 SIMON STEWART: Awesome work.
###28780 AUDIENCE: Yeah, well, that's more my other teammates.
###28783 SIMON STEWART: The JDK5 backport--
###28785 fantastic.
###28787 AUDIENCE: Working on that today.
###28789 SIMON STEWART: Ship it.
###28791 AUDIENCE: So I want to thank you for some really innovative
###28794 work on build systems, and putting that out to the
###28800 community is a really awesome thing.
###28802 So I'm glad to see it.
###28803 I had a question about Buck, particularly because not all
###28808 companies have access to all the source code
###28810 they will ever build.
###28812 So how do you handle binary dependencies of things that
###28814 are third party libraries.
###28816 SIMON STEWART: Yep, there's a rule called pre-built jar,
###28819 where you can just check in.
###28821 So we've got third party dependencies.
###28823 We don't build Guava from source, for example.
###28825 We just checking in the jars.
###28827 AUDIENCE: OK, you check in jars.
###28828 SIMON STEWART: Yeah we check in the jars.
###28829 We have pre-built binary rules, and you
###28831 can depend on those.
###28833 The binary rules allow you to also attach source jars and
###28836 javadoc jars.
###28836 And if you do that when you run Buck Project, it will
###28840 actually hook in the sources, so that you can browse into
###28843 the source code while you're working on your project.
###28846 AUDIENCE: Very sweet, and obviously you have an Eclipse
###28848 plug-in coming soon, right?
###28850 SIMON STEWART: We accept pull requests.
###28852 AUDIENCE: All right, there you go.
###28854 TONY VOELLM: OK, it looks like we have time for one more
###28856 question, so we'll go over here.
###28858 AUDIENCE: I'm Dave.
###28858 I'm from Family Search.
###28860 So you mentioned that the codes in a single tree--
###28863 is that like all of the code at Facebook, or is it just the
###28866 code for Android?
###28867 And the other question the kind of goes along with it is
###28870 does that mean it's all in one get repo?
###28872 And how does that perform?
###28874 SIMON STEWART: So at the moment, the Android
###28876 code is in one repo.
###28877 The IOS code is in another, and dub, dub, dub, the website
###28880 is in the third repo.
###28883 I think Google have demonstrated, you can smoosh
###28888 everything together, and that works pretty well for Google.
###28891 I mean, we saw all the stats earlier, which were amazing,
###28894 just totally mind blowing.
###28896 So we could do it that way.
###28897 But at the moment, we have separate repos
###28900 for the various things.
###28901 But all the Android code lives in one tree.
###28905 Cool.
###28905 TONY VOELLM: OK, actually maybe we'll just grab one
###28907 more, and then I have some announcements about dinner and
###28910 things like that right after this, so go ahead, last
###28912 question, please.
###28913 AUDIENCE: Noah Sussman, I'm an independent consultant, but
###28915 formerly of Etsy, where I designed the CI system with
###28919 pre commit, because it worked so awesomely
###28921 for Google and Mozilla.
###28925 So why not?
###28927 Why no pre commit?
###28928 I'm fascinated.
###28930 SIMON STEWART: Just because we haven't had the need for it.
###28933 The other thing, as well, is sort of we're a relatively
###28936 small company.
###28937 I know 1400 engineers sounds like an awful lot, but That's
###28940 1400 engineers spread over the web, the IOS app. the Android
###28945 app, working on our internal tooling, working on stuff for
###28949 our data centers, just everything.
###28953 Facebook does more than just the news feed.
###28956 We've got messaging infrastructure.
###28957 We've got groups.
###28958 We've got all sorts of fun things.
###28960 So 1400 engineers isn't actually that many.
###28963 The team working on Buck--
###28966 there's about three consistent contributors, and then there
###28970 are other people who join the team for a month or two, and
###28973 then they roll back out again.
###28976 So there just isn't a huge amount of manpower.
###28979 And it turns out that if you run all the unit tests before
###28982 you check in, that catches most of the problems.
###28985 So that hasn't been this sort of pressing need to have a pre
###28987 submit thing.
###28988 When there is a neat, then I think we'll do it.
###28991 But YAGNE is a really good mantra.
###28994 If you've not heard of YAGNE, it comes
###28995 from the Agile community.
###28997 You Ain't Gonna Need It.
###28999 So don't write it, don't use it, until you actually have a
###29001 need for it.
###29002 And then put it in.
###29004 So that's why we don't do it.
###29007 TONY VOELLM: With that, thank you, Simon.
###29008 Hopefully you'll join us for dinner.
###29010 SIMON STEWART: Thanks very much, guys.
###29011 
###29020 TONY VOELLM: Wow, that was a incredible day.
###29023 There's a lot to digest, a lot of really fascinating things
###29027 we learned about, everything from how to verify set-top
###29031 boxes from YouView, not You-- the other one.
###29036 We learned from academia about how to use gaining and gaining
###29039 type systems to engage and create the next generation of
###29043 computer scientists, and even do some very interesting work.
###29047 There's just a lot to think about, so hopefully you'll
###29049 think about it.
###29050 And hopefully you'll share it on the stream and everything
###29053 that we have on G+ and Twitter.
###29056 We'd love to hear what you thought was
###29057 interesting as well.
###29059 For dinner, what we're going to do is everybody is invited
###29062 to dinner if you're up in the water tower, but because we're
###29064 going to go through behind closed doors areas, we're
###29069 going to have people meet us in the lobby.
###29071 And then we'll take shifts of moving everybody up to the
###29074 water tower cafeteria.
###29076 Please, no photos once you walk through the secure doors.
###29080 That would not be happy for you to do that.
###29083 So please don't take any photos, but definitely come
###29085 and enjoy dinner.
###29086 And I hope all the speakers are going to join us.
###29089 And you can go ask them further questions.
###29091 So with that, start meeting us out in the lobby, and then
###29093 we'll walk you up So thank you, thank you.
###29095 [APPLAUSE]
###29100 [MUSIC PLAYING]
